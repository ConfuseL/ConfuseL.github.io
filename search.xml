<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《STL源码剖析》之序列式容器vector]]></title>
    <url>%2F2019%2FMyLearn-STL-3%2F</url>
    <content type="text"><![CDATA[简介 研究数据的特定排列方式，以利于搜寻或排序或其它特殊目的，这一专门学科我们成为数据结构。 序列式容器 关联式容器 array(build-in) RB-tree vector set heap map priority-queue multiset list multimap slist hashtable deque hash_set stack hash_map queue hash_multiset hash_multmap 序列式容器 所谓序列式容器，其中的元素都可序(ordered)，但未必有序(sorted)。C++语言本身提供了一个序列式容器array，STL另外在提供vector，list,deque,stack,queue,priority-queue等等序列式容器。其中stack和queue由于只是将deque改头换面而成，技术上被归类为一种配接器，但我仍把它放在本章讨论。 Vector概述 vector的数据安排以及操作方式，与array非常相似，两者的唯一差别在于空间的运用的灵活性。array是静态控件，一旦配置了就不能改变；要换个大(或小)一点的房子，可以，一切琐细得由客户端自己来：首先配置一块新空间，然后将元素从旧址一一搬往新址，再把原来得空间释放给系统。vector是动态空间，随着元素得加入，它的内部机制会自行扩充以容纳新元素。 SGI的vector定义摘要​ 为了阅读方便，我把原文的代码中一些声明顺序按照被调用的顺序而调换了，不影响实际效果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189//首先是类模板的声明，除了存储的数据之外，还默认了空间配置器为STL提供的alloctemplate&lt;class T,class Alloc = alloc&gt;class vector&#123;public: typedef T value_type; typedef value_type* pointer; typedef value_type* iterator; typedef value_type&amp; reference; typedef size_t size_type; typedef ptrdiff_t difference_type; //在公共成员中，定义了几个嵌套型别，分别是值类型、 指针、 迭代器、 引用、计量单位、指针差。 protected: typedef simple_alloc&lt;value_type,Alloc&gt;data_allocator; //simple_alloc是SGI对所使用的空间配置器的再度封装，它提供了符合STL规格的接口。 iterator start; //指向数据头部的迭代器 iterator finish; //指向数据尾部的迭代器 iterator end_of_storage;//指向可用空间尾部的迭代器 //在原文中没有详细讲述这个函数的实现，这个函数的作用是在position后面申请一个空间，然后赋予元素x。 void insert_aux(iterator position,const T&amp; x); void deallocate()//释放空间函数 &#123; //如果首部迭代器不为空，代表已经存储至少一个数据 if(start) //调用空间配置器的内存释放函数，其中end_of_storage-start会在二级配置器中使用到，一级配置器会直接从start释放 //大于128字节使用一级，小于则二级 data_allocator::deallocate(start,end_of_storage-start); //可以回顾一下 http://confusel.tech/2019/MyLearn-STL-1/ &#125; //配置空间并填满内容 void allocate_and_fill(size_type n,const T&amp; x) &#123; iterator result=data_allocator::allocate(n); //STL内存处理函数，大致作用是：参数包括 : 一个迭代器，一个计数器以及一个值。该函数从迭代器指向的元素开始，将指定数量的元素设置为给定的值。 uninitialized_fill_n(result,n,x); return result; &#125; //填充式初始化，把容器元素变成n个value void fill_initialize(size_type n,const T&amp; value) &#123; //调用了上面那个函数 start=allocate_and_fill(n,value); //调整尾部迭代器 finish=start+n; end_of_storage=finish; &#125; public: /*********构造析构********/ //无参构造函数，初始化三个迭代器 vector():start(nullptr),end(nullptr),end_of_storage(nullptr) &#123; &#125; vector(size_type n,const T&amp; value) &#123; fill_initialize(n,value); &#125; vector(int n,const T&amp; value) &#123; fill_initialize(n,value); &#125; vector(long n,const T&amp; value) &#123; fill_initialize(n,value); &#125; explicit vector(size_type n) &#123; //调用T的构造函数返回一个默认值 fill_initialize(n,T()); &#125; ~vector() &#123; //这是STL的全局函数，从start到finish一一析构 destory(start,finish); //已在上面声明 deallocate(); &#125; /*********结束********/ iterator begin() &#123;return start;&#125; iterator end() &#123;return finish;&#125; //获得实际数据存储大小 size_type size() const &#123; return size_type(end()-begin()); &#125; //获得容器大小 size_type capacity() const &#123; return size_type(end_of_storage-begin()); &#125; //判断是否为空 bool empty() const &#123; return begin()==end(); &#125; //重写操作符[]，通过下标访问元素 //返回一个引用 reference operator[](size_type n) &#123; //指针加法+解引用 return *(begin()+n); &#125; //取第一个元素 reference front() &#123; return *begin(); &#125; //取最后一个元素 reference back() &#123; //end()永远指向空，即最后一个元素的下一个位置 return *(end()-1); &#125; //从后面插入一个元素 void push_back(const T&amp; x) &#123; //如果空间没满 if (finish != end_of_storage) &#123; //全局函数，内部实现主要是 //new(p) T1(value); //placement new,在指针p所指向的内存空间创建一个类型为T1的对象。 //也就是在finish处，生成一个x数据 construct(finish,x); //后移 ++finish; &#125; else insert_aux(end(),x); &#125; //将最尾端元素取出 void pop_back(const T&amp; x) &#123; //finish指向空，--才得到想要删除的元素迭代器 --finish; //全局函数 析构对象finish destroy(finish); &#125; //通过迭代器删除元素 iterator erase(iterator position) &#123; //如果不是最后一个有效元素 if(position+1!=end()) copy(position+1,finish,position); //copy也是STL算法，实现内部如下，也就是将position以后的元素逐一前移。 /*template&lt;class InputIterator, class OutputIterator&gt; OutputIterator copy (InputIterator first, InputIterator last, OutputIterator result) &#123; while (first!=last) &#123; *result = *first; ++result; ++first; &#125; return result; &#125;*/ //与pop_back()一致 --finish; destroy(finish); //这里返回的是原本position的下一个元素 return position; &#125; //重新设置大小 void resize(size_type new_size,const T&amp; x) &#123; //如果新容量小于当前，那么将多余部分删除 if(new_size&lt;size()) //std全局函数，删除两个迭代器之间的元素 erase(begin()+new_size,end()); else //否则插入部分 //std全局函数，在某个迭代器后面插入n个元素 insert(end(),new_size-size(),x); &#125; void resize(size_type new_size) &#123; resize(new_size,T()); &#125; //清空函数 void clear() &#123; //std全局函数，删除两个迭代器之间的元素 erase(begin(),end()); &#125;&#125;; ​ 可以看到，vector在构造函数和析构函数中调用了空间配置器，几乎所有成员函数如插入删除操作的实现，都是以迭代器为操作的基本单位而不是存储的元素本身。 ​ 而且，vector的迭代器类型竟然就是元素的原生指针。 vector的迭代器 vector维护的是一个连续线性空间，所以不论其元素型别为何，普通指针都可以作为vector的迭代器而满足所有必要条件，因为vector迭代器所需要的操作行为，如operator\*,operator\-&gt;,operator++,operator--,operator+,operator-,operator+=,operator\-=。普通指针天生就具备。所以,vector提供的是Random Access Iterators。 vector的成员函数insert_aux()​ 这个函数一般被调用于push_back()，也就是从后面插入新元素时，此时没有可用空间而触发。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152template&lt;class T,class Alloc&gt;void vector&lt;T,Alloc&gt;::insert_aux(iterator position,const T&amp;x)&#123; //如果还有剩余的可用空间 if (finish != end_of_storage) &#123; //在finish处申请一个空间并赋值*(finish-1) construct(finish,*(finish-1)); //因为多了一个元素，所以finish要向后移 ++finish; T x_copy=x; //STL算法，作用是把(position,finish-2)之间的元素移动到finish-1的前面 copy_backward(position,finish-2,finish-1); //让目的位置正确赋值 *position = x_copy; &#125; //没有可用空间 else &#123; const size_type old_size = size(); //如果当前空间为空，我们申请1个，否则我们申请原先的两倍 const size_type len = old_size != 0? 2*old_size:1; //利用空间配置器申请新空间 iterator new_start = data_allocator::allocate(len); iterator new_finish = new_start; try &#123; //STL内存处理工具函数之一，作用是把start到position的内容拷贝到new_start里，并返回末端。 new_finish = uninitialized_copy(start,position,new_start); //赋值 construct(new_finish,x); ++new_finish; new_finish = uninitialized_copy(position,finish,new_finish); &#125; catch(...) &#123; //析构新容器的所有元素 destroy(new_start,new_finish); //释放空间 data_allocator::deallocate()new_start,len; throw; &#125; //析构旧元素 destroy(begin(),end()); //释放 deallocate(); //吧新容器的迭代器赋值给当前容器的迭代器 start=new_start; finish=new_finish; end_of_storage = new_start + len; &#125;&#125; ​ 我们画几个图片方便理解。 ​ 以存储int数据类型的vector为例。 当前总容量为8，已经填充了5个元素 我们填满vector，此时我们想在元素为5的位置插入新元素9 调用insert_aux的过程，因为可用空间不足，申请了新的双倍的空间 最后把新的迭代器赋值给当前容器的迭代器并维护。旧内存将释放掉 vector的成员函数insert()​ 这个函数常用于在任意位置插入，与insert_ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071template&lt;class T,class Alloc&gt;void vector&lt;T,Alloc&gt;::insert(iterator position,size_type n,const T&amp; x)&#123; if (n != 0) &#123; if(size_type(end_of_storage-finish)&gt;= n) &#123; T x_copy =x; //当前插入点后面有多少 const size_type elems_after = finish - position; iterator old_finish = finish; if (elems_after &gt; n) &#123; //将当前尾迭代器的前n个元素移动到尾迭代器的后面 uninitialized_copy(finish - n,finish,finish) //维护尾迭代器 finish+=n; //再把插入点后面剩余的元素移动到尾迭代器前面 copy_backward(position,old_finish-n,old_finish); //以上步骤结束后，会在插入点后面剩出n个空位 //填充x_copy fill(position,position+n,x_copy); &#125; else &#123; //现在尾迭代器处填充n-elems_after个元素 uninitialized_fill_n(finish,n-elems_after,x_copy); finish += n-elems_after; //再把插入点到原来尾迭代器之间的所有元素移动到新的尾迭代器后面 uninitialized_copy(position,old_finish,finish); finish += elems_after; //插入点和旧尾迭代器填充之间的元素 fill(position,old_finish,x_copy); &#125; &#125; //如果备用空间不足，那么需要重新申请 else &#123; const size_type old_size = size(); //申请两倍或者更长(至少满足正好插入) const size_type len = old_size + max(old_size, n); //利用空间配置器申请len个空间 iterator new_start=data_allocator::allocate(len); iterator new_finish=new_start; //#define __STL_TRY try __STL_TRY &#123; //三部分逐一赋值给新空间，插入点之前，插入的n个元素，原来插入点之后的元素 new_finish = uninitiallzed_copy(start,position,new_start); new_finish = uninitiallzed_fill_n(new_finish,n,x); new_finish = uninitiallzed_copy(position,finish,new_finish); &#125; #ifdef __STL_USE_EXCEPTIONS catch(...) &#123; destory(new_start,new_finish); data_allocator::deallocate(new_start,len); throw; &#125; #endif //析构 destory(start,finish); //释放之前的空间 deallocate(); //维护三个迭代器 start=new_start; finish=new_finish; end_of_storage=new_start+len; &#125; &#125;&#125; 图解 当备用空间足够的时候: 我们想在其中插入2个元素。 可用空间剩余2，我们想插入2个，插入点之后有3和元素，明显3&gt;2 ​ 大致流程，是将原本的元素按两步移动，假设添加n个元素，那么首先移动插入点后的n个元素到尾迭代器后，然后再把剩余的前半段移动到尾迭代器的前面。 ​ 最后填充好中间的空闲元素。 可用空间剩余3，我们想插入3个，插入点之后有2个元素，明显2&lt;3。 ​ 大致流程，是将填充的元素按两步移动，假设添加n个元素，那么首先在尾迭代器后填充(可用空闲数量-n)个目标元素。 ​ 将要被替换的、插入点之后到原尾迭代器之间的元素移动到新尾迭代器后面。 ​ 最后填充好中间的空闲元素。 不解​ 为啥不直接把旧的元素移动完毕，再直接填充呢。 代码测试push_back的内存和构造析构变化看看下面的代码，猜猜会输出什么？ 1234567891011121314151617181920212223#include &lt;bits/stdc++.h&gt;using namespace std;struct role&#123; string name; role(const char* n) : name(n) &#123;&#125; ~role() &#123;cout&lt;&lt;name&lt;&lt;endl;&#125; &#125;; int main()&#123; role r1("小李"), r2("小强") ,r3("小狗"), r4("小明"); typedef std::vector&lt;role&gt; RoleVec; RoleVec rvec; rvec.push_back(r1); cout&lt;&lt;1&lt;&lt;endl; rvec.push_back(r2); cout&lt;&lt;1&lt;&lt;endl; rvec.push_back(r3); cout&lt;&lt;1&lt;&lt;endl; rvec.push_back(r4); cout&lt;&lt;1&lt;&lt;endl; rvec.erase(rvec.begin()); return 0;&#125; 答案1234567891011121314151617/*1小李1小李小强11小明小强小狗小明小明小狗小强小李*/ 我们结合代码来分析： 123456789101112131415161718192021222324252627282930313233343536373839404142role r1("小李"), r2("小强") ,r3("小狗"), r4("小明");//这四个，在栈上，顺序从上到下，从r1到r4typedef std::vector&lt;role&gt; RoleVec; RoleVec rvec; //rvec进入栈 在r4下rvec.push_back(r1);//空间为0，我们调用index_aux，申请了1的空间，将r1小李深拷贝进去cout&lt;&lt;1&lt;&lt;endl;//1rvec.push_back(r2);//空间为1，我们调用index_aux，申请了2的空间，将r1 r2深拷贝进去//原来的空间元素被析构 //小李cout&lt;&lt;1&lt;&lt;endl;//1rvec.push_back(r3);//空间为2，我们调用index_aux，申请了4的空间，将r1 r2 r3深拷贝进去//原来的空间元素被析构 //小李//小强cout&lt;&lt;1&lt;&lt;endl;rvec.push_back(r4);//空间足够cout&lt;&lt;1&lt;&lt;endl;rvec.erase(rvec.begin());//vector 中的 r2 r3 r4向前拷贝,原r4被析构//小明//这时候vector先被析构，因为栈高位向低位。/*小强小狗小明*///然后从下到上析构栈上的r4 r3 r2 r1/*小明小狗小强小李*/return 0; 不解 ​ 为啥Diana析构出现了两次，​ 前三次push_back已经确保容器空间为4了，用push_back插入尾部或者insert插入尾部都不会发成Diana析构。但是在中间insert就会出现 ，SGI的insert源码里，只有空间不足才会扩张，否则都是移动+填充，按理来说Diana应该直接命中，只是被拷贝了一次才对嘛。。。​ 即使出现扩张空间，交换新旧内存引发的析构，也是旧内存里的ABC一起析构才对啊。。 以后解决了补上。]]></content>
      <categories>
        <category>STL</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单了解Mono和IL2CPP]]></title>
    <url>%2F2019%2FMyLearn-Mono%26IL2CPP%2F</url>
    <content type="text"><![CDATA[.NET 应用程序是怎么运行的？​ 开篇先自问个问题，.NET 应用程序是怎么运行的？，在没有去探索这些知识点的时候，自己是一片空白的，因为自己完全是为了使用Unity3D而去学习的C#，却没有去了解这个语言的执行过程(又不是不能用)。 ​ 百度启动，我们发现.NET平台的实现有两大派系：曾今闭源的.Net Framework和开源的Mono，那么，我们首先得知道，执行.NET程序为何需要它们。 跨平台需求​ 跨平台是个好东西，我们写了一个程序，不需要多大精力就可以将它发布在多个平台上，那么我们如何实现这个过程呢？绞尽脑汁，想了想，“把源代码编译成不同平台对应的机器码？” ​ 咦，感觉八九不离十了，因为我们想到c/c++，每个平台都有对应的gcc，在linux上写的代码，大部分都可以在各个linux派生系统上直接编译运行，但是应该能马上意识到，linux和winodws有些api并不通用啊。 ​ 聪明的我们想到，宏定义判断平台，编码的时候写多个方式，通过makefile来自动选择编译的参数。 ​ 是的，我们开发是能这么做，我们也能体会到这样开发带来的成本很高，并且我们的角度只是以开发者的角度去思考这个问题，那么作为一个面向开发者的公司要如何思考呢。毕竟开发成本降低了，才能迎来更多的开发者，因此我们不应该让开发者去做这些繁重的事，我们需要实现一个东西，让开发者只需要按照某个规定/协议/规则编码，我们的东西识别这些符合定义的编码，将他们自动转换成各平台的机器码不就行了么。 ​ 因此，微软开发了一个称为通用语言架构（Shared Source Common Language Infrastructure，Shared Source CLI)；也就是上面提到的，让开发者遵守的一种技术规范，它定义了一个语言无关的跨体系结构的运行环境，这使得开发者可以用规范内定义的各种高级语言来开发软件，并且无需修正即可将软件运行在不同的计算机体系结构上。 CIL，公共中间语言（Common Intermediate Language）​ 我们遵守CLI规则，编译器会将我们编写的代码变成中间语言IL，我们还需要一个东西，专门负责翻译开发者的代码，变成对应的机器码。注意别把CLI和CIL弄混。 CLR，公共语言运行时（Common Language Runtime） 无论通过任何语言构建产品，都必须寄宿到一个平台中运行，这正如我们的软件运行在操作系统环境一样，操作系统为CLR提供了运行环境，使用.NET构建的程序又运行在CLR之上，CRL为.NET程序的运行提供了温床，CLR提供基本的类库和运行引擎，基本类库封装操作系统函数供开发者方便调用，运行引擎用于编译并运行我们开发的程序。CLR包含.NET运行引擎和符合CLI的类库。通过.NET平台构建的程序都基于CLR基础类库来实现，并且运行在CLR提供的运行引擎之上。 ​ 显然，这个CLR就是上文所需要的”东西“(是不是和java虚拟机差不多)，能把基于CLI规范的语言编写出来的IL代码翻译为机器代码运行，这是CLR最重要的功能。 ​ 那么CLR是如何对IL语言进行翻译的呢？CLR提供了JIT，即Just-in-time,动态(即时)编译，边运行边编译；AOT，Ahead Of Time，指运行前编译，两种程序的编译方式。 ​ JIT具体的做法是这样的:当载入一个类型时,CLR为该类型创建一个内部数据结构和相应的函数,当函数第一次被调用时,JIT将该函数编译成机器语言.当再次遇到该函数时则直接从cache中执行已编译好的机器语言。而AOT则是提前编译好所有代码。 C#的执行过程​ 经过上面的探讨，相信运行过程开始清晰起来了。C#是遵循CLI规范的高级语言，被先被各自的编译器编译成中间语言：IL（CIL），等到需要真正执行的时候，这些IL会被加载到运行时库CLR中，由CLR动态的编译成汇编代码（JIT）然后在执行。 ​ 可能加上才刚认识的英文专有词缩写，这么表述还是有一点绕，那么通俗来解释，我们写完C#代码，编译器开始编译操作，编译器将它变成了一种中间语言，运行的时候，操作系统会调用一个解释器对这些中间语言进行动态解释或者提前编译运行。 .Net Framework和Mono​ 上面那一块主要功能就包含在叫做.Net Framework的框架中，那么既然有了.Net Framework,为何还需要Mono呢？下面引用别人的博客内容，阐述了Mono出现的原因。 ​ 我想表达什么呢？其实我们现在在 Windows 平台下开发的 .NET 应用程序，是深深依赖于 .NET Framework（深深的那种），你的应用程序代码基本上都是在它之上完成的，而 .NET Framework 又是深深依赖于 Windows 平台下的 CLR（也是深深的那种），在这种情况下，根本就无法使你的应用程序跨平台，因为微软紧紧的抱住 Windows 平台，妄想 Windows 可以实现“大一统”，但现实是很残酷的，这次的 .NET 开源、跨平台，其实也是微软的无奈之举。但就是在这种背景下，Mono 出现了，并且在微软的各种“排挤”下坚持了下来，这是非常不容易的，其实实现 .NET 跨平台的三个关键是：编译器、CLR 和基础类库，而 Mono 实质上就是把他们三个进行跨平台实现了，一个很小团队完成了一个巨头需要完成的工作，而且还是在这个巨头的“排挤”下，其实这就是开源和社区的力量。 ​ 是的，.Net Framework没有真正意义上实现跨平台，它只能在不同windows版本上工作，这是Mono出现的原因。我们来看看百度百科的介绍。 Mono是一个由 Xamarin公司（先前是Novell,最早为Ximian）所主持的自由开放源代码项目。该项目的目标是创建一系列符合ECMA标准（Ecma- 334和Ecma-335）的.NET工具，包括C#编译器和通用语言架构。与微软的.NET Framework（共通语言运行平台）不同，Mono项目不仅可以运行于Windows系统上，还可以运行于 Linux，FreeBSD，Unix，OS X和Solaris，甚至一些游戏平台，例如：Playstation 3，Wii或XBox 360之上。 ​ Mono使得C#这门语言有了很好的跨平台能力。相对于微软的.Net Framework运行时库Mono使用自己的Mono VM作为运行时库。 加上C#本身快速友好的开发能力，最终使得Unity团队在创建之初就决定将Mono，C#作为其核心。 ​ 而Mono的执行方式和.Net Framework大致上差不多，只不过使用的改编后的CLR，使得在各平台上可以变成对应机器码。 Mono​ 现在我们抛开.Net Framework，因为Unity目前支持Mono和IL2CPP，IL2CPP是后来加上的(Unity2017.3 版本以后)，先来后到，我们先谈谈Mono。 Mono的组成 C#编译器最新的Momo版本（5.0+）c#编译器完全兼容c#4.0以上，unity 2018 使用的依旧是 Mono 2.0 版本，它的编译器(mcs)就不支持c#4.0以上。 Mono运行时CLR上面提到过，提供了JIT（即时编译器），AOT（提前编译器）两种编译器。 类库加载器。垃圾回收器(Unity使用的是贝姆垃圾回收器)。 基础类库（与.net框架兼容）+Mono类库 Mono的执行流程 Mono的优点 构建应用非常快 由于Mono的JIT(Just In Time compilation ) 机制, 所以支持更多托管类库 支持运行时代码执行(译者注: 由于JIT机制，所以能在运行的过程中执行新生成的或者动态加载的代码) Mono的缺点 ​ Mono VM在各个平台移植，维护非常耗时，有时甚至不可能完成。​ Mono的跨平台是通过Mono VM实现的，有几个平台，就要实现几个VM，像Unity这样支持多平台的引擎，Mono官方的VM肯定是不能满足需求的。所以针对不同的新平 台，Unity的项目组就要把VM给移植一遍，同时解决VM里面发现的bug。这非常耗时耗力。这些能移植的平台还好说，还有比如WebGL这样基于浏览器的平台。要让WebGL支持Mono的VM几乎是不可能的。 ​ 必须将代码发布成托管程序集(.dll 文件 , 由mono或者.net 生成 ) IL2CPP​ 从名字上看就很清楚了，IL to cpp 即IL翻译成cpp。根据Unity官方博客上的文章指出，使用.NET和Mono编译器对代码进行编译。 ​ 我们可以在Windows平台的Unity安装路径Editor\Data\il2cpp目录下找到。对于OSX平台，它位于Unity安装路径的Contents/Frameworks/il2cpp/build目录内。 il2cpp.exe这个工具是一个托管代码可执行文件，其完全由C#写成。在开发IL2CPP的过程中，我们同时使用.NET和Mono编译器对其进行编译。 ​ 而对于GC，官方是这么解释的： ​ 运行时的另外一个重要的部分，就是垃圾收集器。在Unity 5中，我们使用libgc垃圾收集器。它是一个典型的贝姆垃圾收集器（Boehm-Demers-Weiser garbage collector）。（译注：相对使用保守垃圾回收策略）。然而我们的libil2cpp被设计成可以方便使用其他垃圾回收器。因此我们现在也在研究集成微软开源的垃圾回收器（Microsoft GC）。对于垃圾回收器这一点，我们会在后续的一篇中专门的讨论，这里就不多说了。 以上翻译内容来自用Unity做游戏，你需要深入了解一下IL2CPP IL2CPP的组成 AOT编译器 il2cpp 接受来自Unity自带的或者由Mono编译器产生的托管程序集，将这些程序集转换成C++代码。这些转换出的C++代码最终由部署目标平台上的C++编译器进行编译。 一个支持虚拟机的运行时库 AOT编译器将由.NET 输出的中间语言(IL)代码生成为C++代码。运行时库则提供诸如垃圾回收，与平台无关的线程，IO以及内部调用（C++原生代码直接访问托管代码结构）这样的服务和抽象层。 IL2CPP的执行流程 IL2CPP的优点 相比Mono, 代码生成有很大的提高 可以调试生成的C ++代码 可以启用引擎代码剥离(Engine code stripping)来减少代码的大小 IL2CPP的缺点 相比Mono构建应用非常慢 只支持AOT(Ahead of Time)编译 可能产生的疑问 IL2CPP多了一次编译过程啊，从效率上来说为什么值得的使用呢？ ​ IL2CPP多了一次的编译过程是将IL转成CPP，执行的时候还需要C++编译器编译一次，而在Mono中没有，所以在IL2CPP的缺点中，构建应用的时间很长，但是，Mono的JIT只在运行的时候将IL执行成机器码，意味着每一次运行都需要动态加载一些代码，而IL2CPP已经预先编译好了，可以利用现成的在各个平台的C++编译器对代码执行编译期优化，这样可以进一步减小最终游戏的尺寸并提高游戏运行速度。 ​ 并且Cpp效率之快是大家都承认的。 CPP是静态的，那么还需要IL2CPP虚拟机干吗？ ​ 虽然通过IL2CPP以后代码变成了静态的C++，但是内存管理这块还是遵循C#的方式，这也是为什么最后还要有一个 IL2CPP VM的原因：它负责提供诸如GC管理，线程创建这类的服务性工作。但是由于去除了IL加载和动态解析的工作，使得IL2CPP VM可以做的很小，并且使得游戏载入时间缩短。 总结​ C#是一种高级语言，需要编译转换成中间语言，通过不同平台的CLR解释成机器码，才能运行。 ​ 现在在Unity3D中，我们可以选择Mono和IL2CPP两种编译方式，各有优缺点，而一般都在开发阶段选择Mono，在发布的时候选择IL2CPP。 ​ 不过呢，据说现在IL2CPP的成熟程度挺高，也有人推荐开发阶段使用。 Unite 2014上官方给出的性能测试截图（数字越小表示运行得越快） 参考文章用Unity做游戏，你需要深入了解一下IL2CPP Unity将来时：IL2CPP是什么？ https://www.cnblogs.com/lancidie/p/6258154.html) 魅力 .NET：从 Mono、.NET Core 说起]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《STL源码剖析》之迭代器相关]]></title>
    <url>%2F2019%2FMyLearn-STL-2%2F</url>
    <content type="text"><![CDATA[简介 ​ 不论是泛性思维或者STL的实际运用，迭代器都扮演者重要的角色。STL的中心思想在于：将数据容器和算法分开，彼此独立设计，最后再以一贴胶着剂将它们它们撮合在一起。容器和算法的反省话，从技术角度来看并不难，C++的class template 和 function templates 可分别达成目标，如何设计出两者之间的良好胶着剂，才是大难题。 ​ 这篇博客不讨论STL实现的迭代器的源码以及SGI中特定的traits技巧。 迭代器是一种类似指针的对象 迭代器是一种行为类似指针的对象，而指针的各种行为中最常见也最重要的便是内容提领和成员访问，因此迭代器最重要的编程工作就是对operator *和operator -&gt; 进行重载工作。 关于这一点，C++标准程序库有一个 auto_ptr可供我们参考,这是一个用来包装原生指针的对象，声名狼藉的内存漏洞(memory leak)问题可以因此获得解决。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;class Test&#123;public: string value; Test(string s):value(s) &#123; cout&lt;&lt;value&lt;&lt;"构造"&lt;&lt;endl; &#125; ~Test() &#123; cout&lt;&lt;value&lt;&lt;"析构"&lt;&lt;endl; &#125;&#125;;void funb()&#123; Test* ps(new Test("funb"));&#125;void func()&#123; auto_ptr&lt;Test&gt; ps(new Test("func"));&#125;int main()&#123; funb(); func(); return 0;&#125;/*输出结果为funb构造func构造func析构*/ ​ 我们看输出结果，可以看到 auto_ptr自动帮我们释放了内存和析构。 auto_ptr的简化实现12345678910111213141516171819202122232425262728293031323334353637383940#ifndef AUTOPTR_HPP_INCLUDED#define AUTOPTR_HPP_INCLUDEDtemplate&lt;class T&gt;class AutoPtr&#123;private: T *pointee;public: //explicit声明不可以隐式转换 explicit AutoPtr(T *p=nullptr):pointee(p)&#123;&#125; template&lt;class U&gt; AutoPtr(AutoPtr&lt;U&gt; &amp; rhs):pointee(rhs.release())&#123;&#125; ~AutoPtr() &#123; delete pointee; &#125; template&lt;class U&gt; AutoPtr&lt;T&gt;&amp; operator=(AutoPtr&lt;U&gt; &amp; rhs) &#123; if(this!=rhs) reset(rhs.release()); return *this; &#125; T* operator*() const &#123; return *pointee; &#125; T* operator-&gt;() const &#123; return *pointee; &#125; T* get() const &#123; return pointee; &#125;&#125;;#endif // AUTOPTR_HPP_INCLUDED ​ 不难看出，智能指针对模板对象进行了一层封装，并重载了operator*() 和operator-&gt;()等操作。同时保证在析构的时候释放内存。 自定义链表并实现迭代器​ 我的代码并没有和原文中的封装方法一致，因为我觉得原文中的实现方式很容易暴露一些相对使用者没什么必要的对象，实现过程中一直没有去看原文3.2节的最后几段话。后面去才看，发现作者之所以使用如此暴露的封装方法实现迭代器的原意便是想体现出容器和对应迭代器的强连接性。 为一种容器设计迭代器，需要暴露很多细节，既然无可避免，干脆把迭代器的开发工作交给List的设计者好了，如厕以来，所有实现细节反而得以封装起来不被使用者看到，这正是为什么每一种STL容器都提供专属迭代器的缘故。 存储元素12345678910111213141516171819202122template&lt;typename T&gt;class ListItem&#123;private: T value; ListItem *next;public: ListItem(T v):value(v),next(nullptr)&#123;&#125; T Value()const &#123; return value; &#125; ListItem *Next() const &#123; return next; &#125; //链接 自己添加的函数 void Insert(ListItem* nextValue) &#123; next=nextValue; &#125;&#125;; 迭代器12345678910111213141516171819202122232425262728293031323334353637383940template &lt;class Item&gt;struct ListIter&#123; Item* ptr; ListIter(Item *p =nullptr):ptr(p)&#123;&#125; Item&amp; operator*() const &#123; return *ptr; &#125; Item* operator-&gt;() const &#123; return ptr; &#125; Item&amp; operator=(const ) const &#123; return ptr; &#125; //前置式：累加然后取出 ListIter&amp; operator++( ) &#123; ptr=ptr-&gt;Next(); return *this; &#125; //后置式：取出然后累加 ListIter&amp; operator++(int ) &#123; ListIter tmp=*this; ++*this; return tmp; &#125; //对比的是迭代器封装的值 bool operator == (const ListIter&amp; i) const &#123; return ptr == i.ptr; &#125; bool operator != (const ListIter&amp; i) const &#123; return ptr != i.ptr; &#125;&#125;; 链表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364template&lt;typename T&gt;class List&#123;private: //头元素 ListItem&lt;T&gt;* front; //尾元素 ListItem&lt;T&gt;* last; //首部迭代器 原文不存在 ListIter&lt;ListItem&lt;T&gt; &gt;begin; //尾部迭代器 原文不存在 ListIter&lt;ListItem&lt;T&gt; &gt;end; long size;public: List():front(nullptr),last(nullptr)&#123;&#125; //从前插入 原文不实现 void InsertFront(T value) &#123; ListItem&lt;T&gt; * newValue = new ListItem&lt;T&gt;(value); if(front) &#123; newValue-&gt;Insert(front); &#125; front=newValue; begin.ptr=front; if(!last) last=front; ++size; &#125; //从后插入 原文不实现 void InsertEnd(T value) &#123; ListItem&lt;T&gt; * newValue = new ListItem&lt;T&gt;(value); if(last) &#123; last-&gt;Insert(newValue); &#125; last=newValue; end.ptr=last-&gt;Next(); if(!front) front=last; ++size; &#125; //输出链表 原文不实现 void display(std::ostream &amp;os = std::cout)const &#123; ListItem&lt;T&gt;*iter=front; while(iter!=nullptr) &#123; os&lt;&lt;iter-&gt;Value(); iter=iter-&gt;Next(); &#125; &#125; //取得尾部迭代器（空） 自己添加的函数 ListIter&lt;ListItem&lt;T&gt; &gt; End() const &#123; return end; &#125; //取得首部迭代器 自己添加的函数 ListIter&lt;ListItem&lt;T&gt; &gt; Begin() const &#123; return begin; &#125;&#125;; 测试123456789101112131415161718192021222324252627282930313233343536373839404142using namespace std;//find函数实现//首尾迭代器以及查找的目标值template&lt;class Iterator,class T&gt;Iterator Find(Iterator first,Iterator last,const T&amp; target)&#123; //因为在使用的时候，我们实际比较的是迭代器的值目标值，但是迭代器的值是一个封装的元素，所以还需要获得元素存储的值。 while(first!=last&amp;&amp; first-&gt;Value()!=target) ++first; return first;&#125;int main()&#123; //大写List，使用上面的自定义链表 List&lt;int&gt; myList; for(int i=1;i&lt;=5;++i) &#123; myList.InsertFront(i); myList.InsertEnd(i); &#125; myList.display();//5432112345 cout&lt;&lt;endl; /* 原文实例代码 ListIter&lt;ListItem&lt;int&gt; &gt;begin(mylist.front()); ListIter&lt;ListItem&lt;int&gt; &gt;end; ListIter&lt;ListItem&lt;int&gt; &gt;iter; iter=find(begin,end,3) */ //因为自己将迭代器封装到了容器中，直接调用即可 if(Find(myList.Begin(),myList.End(),4)!=myList.End()) cout&lt;&lt;"存在4"&lt;&lt;endl; else cout&lt;&lt;"不存在4"&lt;&lt;endl; //存在4 if(Find(myList.Begin(),myList.End(),6)!=myList.End()) cout&lt;&lt;"存在6"&lt;&lt;endl; else cout&lt;&lt;"不存在6"&lt;&lt;endl; //不存在6 return 0;&#125; ​ 在原文的示例代码中，作者故意没有将迭代器和List一起封装，因此在main()中，特地声明了多个迭代器，去指向链表的front和end以及结果，而我误打误撞的避免了这种情况:sweat_smile: 迭代器相应型别 ​ 上述的ListIter提供了一个迭代器雉形。如果将思想拉得更高远一些，我们便会发现，在算法中运用迭代器时，很可能会用到其相应型别(associated type)。什么是相应型别？迭代器所指之物的型别就是其一。假设算法中有必要声明一个变量，以“迭代器所指对象的型别”为型别，如何是好？毕竟C++值支持sizeof()，并未支持typeof(),即便动用RTTI性质中的typeid(),获得的也只是型别名称，不能拿来做变量声明只用。 ​ 在上面的代码中，我们自己实现的Find()函数，只能应用与这个特定的List中，因为first-&gt;Value()!=target这段代码，并不是所有模板类对象拥有Value()这个方法来获取成员变量，(代码中的Iterator拥有)，因此我们很可能需要在函数模板中，判断参数的实际类型，甚至直接操作这些类型，比如需要生成这个类型的对象等，那么我们需要怎么做呢？ ​ 书中给了答案： 解决办法是：利用 function template 的参数推导机制。 1234567891011121314151617template &lt;class I,class T&gt; void func_imp1(I iter,T t)&#123; T target;//我们这里是不是已经获取到了数据类型T，虽然这样看起来，它只是一个模板类T，但是在编译期后，它就是int了。&#125;template&lt;class I&gt;inline void func(I iter)&#123; func_imp1(iter,*iter); //这里的I是指针，所以还要调用一次。&#125;int main()&#123; int i; func(&amp;i);&#125; ​ 函数模板的参数推导实在调用函数时 &lt;类型&gt; 缺省的情况下编译器去推导的，我们可以借用这个方式去获得对应的类型，如果只是获得类型的画，其实也可以用auto。 关于auto和函数模板的相关知识可以看一下别人的博客类型推导：函数模板与auto，总结的很好。 Traits 编程技法–STL源代码门钥通过内嵌型别，来返回对应的类型​ 虽然我们可以通过函数模板的参数机制来推导类型，但是也只能限制在参数上，如果我们必须要用于返回值，就束手无策了。 ​ 原文演示了内嵌型别的方法。 1234567891011121314151617181920212223template &lt;class T&gt; struct MyIter&#123; typedef T value_type; T* ptr; MyIter(T *p=nullptr):ptr(p)&#123;&#125; T&amp; operator*()const &#123; return *ptr; &#125; ...&#125;;template &lt;class I&gt; typename I::value_typefunc(I ite)&#123; return *ite;&#125;//一MyIter&lt;int&gt; ite(new int(8));//二std::cout&lt;&lt;fun(ite);//8 ​ 我们来捋一捋这段代码，在结构体MyIter中，声明了一个类型别名value_type，这也使得typename I::value_type对于程序来说，是已知的。我们在一中初始化迭代器ite，将一个指向存储类型为int内容为8的地址给迭代器的ptr，在二中调用方法fun()，将ptr的解引用返回，这个时候，因为我们规定了fun()的返回值类型为传参类I中的value_type，而value_type在MyIter&lt;int&gt;中就是int的别名，所以返回的值类型就是int。 ​ 看起来不错。但是有个隐晦的陷阱并不是所有迭代器都是class type，原生指针就不是！如果不是class type，就无法为它定义内嵌型别。但STL(以及整个泛型思维)绝对必须接受原生指针作为一种迭代器，所以上面这样还不够，有没有办法可以让上述的一般化概念针对特定情况做特殊化处理呢？ Partial Specialization 偏特化Partial Specialization 的 含义 大致的意义是：如果class template 拥有一个以上的 template参数，我们可以针对其中某个(或数个，但非全部) template参数进行特化工作。换句话说，我们可以在泛化设计中提供一个特化版本(也就是将泛化版本中的某些template参数赋予明确的指定)。 简单特性萃取iterator_traits实现1234567891011121314151617181920212223242526//特征萃取，萃取类I中的value_typetemplate&lt;class I&gt; struct iterator_traits &#123; typedef typename I::value_type value_type; &#125;;//pointertemplate&lt;class T&gt; struct iterator_traits&lt;T*&gt; &#123; typedef T value_type; &#125;;//pointer to const template&lt;class T&gt; struct iterator_traits&lt;const T*&gt; &#123; typedef T value_type; &#125;;//直白来看，只是比上面的代码多了一层封装,但是通过这层封装，我们能更准确的在不同复杂理性中萃取到真正的类型template &lt;class I&gt; typename iterator_traits&lt;I&gt;::value_typefunc(I ite)&#123; return *ite;&#125; 五个常用迭代器相应型别迭代器相应型别之一：value_type 所谓value_type，是指迭代器所指对象的型别，任何一个打算与STL算法有完美搭配的class，都应该定义自己的value_type内嵌型类别，做法就像上节所述。 迭代器相应型别之二：different_type different_type用来表示两个迭代器之间的距离，因此它也可以用来表示一个容器的最大容量，因为对于连续空间的容器而言，头尾之间的距离就是器最大容量。 1234567891011121314151617181920212223242526//pointertemplate&lt;class I&gt; struct iterator_traits&lt;T*&gt; &#123; //用ptrdiff_t 来保存两个指针相减的结果 typedef ptrdiff_t different_type; &#125;;//pointer to const template&lt;class I&gt; struct iterator_traits&lt;const T*&gt; &#123; typedef ptrdiff_t different_type; &#125;;template&lt;class I,class T&gt; //写明返回的类型 typename iterator_traits&lt;I&gt;::different_type count(I first,I last,const T&amp; value) &#123; typename iterator_traits&lt;I&gt;::different_type n=0; for(;first!=last;++first) //这个函数的作用是统计在连续容器中，value出现了多少次 if(*first==value) n++; return n; &#125; 迭代器相应型别之三：reference_type 从“迭代器所指之物的内容是否允许改变”的角度观之，迭代器分为两种： 不允许改变“所指对象之内容”，成为constant iterators，例如 const int * pic 允许改变“所指对象之内容”，成为mustable iterators，例如 int * pic 当我们对一个mustable iterators进行提领操作时，获得的不应该是一个右值，而是一个左值，因为右值不允许赋值操作，左值才允许。 1234int *pi = new int(5);const int *pci = new int(9);*pi=7;*pci=1;//错误，pic是右值 在C++中，函数如果要传回左值，都是以by reference的方式进行，所以当p是一个mustable iterators时，如果其value_type是T，那么*p的型别不应该是T，应该是T&amp;，当p是一个constant iterators时，如果其value_type是T，那么*p的型别不应该是const T，应该是const T&amp;，这里所讨论的-[]写别，即所谓的reference type，实现细节将在下一小节一并展示。 迭代器相应型别之四：pointer_type pointer和references在C++中有非常密切的挂变脸，如果”传回一个左值,令它代表p所指之物”是可能的，那么”传回一个左值,令它代表p所指之物的地址”也一定可以，也就是说，我们能够传回一个pointer，指向迭代器所指之物。 1234567891011121314151617181920template&lt;class I&gt; struct iterator_traits &#123; typedef typename I::pointer pointer; typedef typename I::reference reference; &#125;;//pointertemplate&lt;class I&gt; struct iterator_traits&lt;T*&gt; &#123; typedef T* pointer; typedef T&amp; reference; &#125;;//pointer to const template&lt;class I&gt; struct iterator_traits&lt;const T*&gt; &#123; typedef const T* pointer; typedef const T&amp; reference; &#125;; ​ 和上面的简单特性萃取实现区分开来，那里只是指值，这里是专门指引用和指针。 迭代器相应型别之五：iterator_category五类迭代器 根据移动特性与施行操作，迭代器被分为五类： input iterator:这种迭代器所指的对象，不允许被外界改变。只读。 output iterator:只写。 Forward iterator:允许”写入型”算法在这种迭代器形成的区间上进行读写操作。 Bidrectional iterator:可双向移动，某些算法需要逆向走访某个迭代器区间(例如逆向拷贝某范围内的元素)，可以使用Bidrectional iterator Random Accesson iterator：前四种迭代器都只供应一部分指针算数能力(前三种支持operator ++，第四种加上operator--)，第五种则覆盖所有指针算数能力，包括p+n,p-n,p[n],p1-p2,pq&lt;p2; ​ 它们之间可以用继承关系表示： graph TB input_iterator-->Forward_iterator output_iterator-->Forward_iterator Forward_iterator-->Bidrectional_iterator Bidrectional_iterator-->Random_Access_Iterator ​ 在设计算法的时候，应该尽力为每个迭代器提供一个明确定义，以保证提供最大的效率，因为它们是继承关系，所有派生类对象是可以向上转换成基类对象的，意味着派生类对象可以使用针对基类对象的算法，但是这个算法对于派生类对象来说可能不是最佳的，虽然能用。 ​ 以原文提到的advanced()为例。 1234567891011121314151617181920212223242526272829303132template&lt;class InputIterator,class Distance&gt;inline void advance_II(InputIterator&amp; i,Distance n)&#123; while(n--)++i;&#125;//可以双向移动，所以要考虑n为负数template&lt;class BidirectuibIterator,class Distance&gt;inline void advance_BI(BidirectuibIterator&amp; i,Distance n)&#123; if(n&gt;=0) while(n--)++i; else while(n++)--i;&#125;//因为随机访问迭代器支持指针算术，所以直接+=template&lt;class RandomAccessonIterator,class Distance&gt;inline void advance_RAI(BidirectuibIterator&amp; i,Distance n)&#123; i+=n;&#125;template&lt;class Inputerator,class Distance&gt;inline void advance(InputIterator &amp; i,Distance n)&#123; //判断是否是某种迭代器而去调用 if(is_random_accesson_iterator(i)) advance_RAI(I,n); else if(is_bidirectuib_iterator(i)) advance_BI(I,n); else advance_II(I,n);&#125; ​ 相信刚接触迭代器设计思想时，应该也会写出上面的代码，或者说时习惯性写法，不过在接触更多的更棒的源码之后，就会感受到这样写的不足了，每一次调用advance()都会判断几次，效率太低了。 利用重载函数和萃取器特性以及继承性提高效率​ 我们定义五个类/结构体，利用继承的特性把它们定义一下。 123456//仅仅拿来做一个标识，不去实现内部成员。struct input_iterator_tag&#123;&#125;;struct output_iterator_tag&#123;&#125;;struct forward_iterator_tag:input_iterator_tag&#123;&#125;;struct bidirectional_iterator_tag:forward_iterator_tag&#123;&#125;;struct random_access_iterator_tag:bidirectional_iterator_tag&#123;&#125;; ​ 我们通过同参数数量，不同参数类型的方式重载__advance()函数。这里除了新添加的第三个参数，其余和上面原先的advance()函数差不多。 123456789101112131415161718192021222324252627template&lt;class InputIterator,class Distance&gt;inline void __advance(InputIterator&amp; i,Distance n,input_iterator_tag)//不需要用到实参，我们可以不接受&#123; while(n--)++i;&#125;template&lt;class ForwardIterator,class Distance&gt;inline void __advance(InputIterator&amp; i,Distance n,forward_iterator_tag)&#123; __advance(i,n,input_iterator_tag());&#125;//可以双向移动，所以要考虑n为负数template&lt;class BidirectuibIterator,class Distance&gt;inline void __advance(BidirectuibIterator&amp; i,Distance n,bidirectional_iterator_tag)&#123; if(n&gt;=0) while(n--)++i; else while(n++)--i;&#125;//因为随机访问迭代器支持指针算术，所以直接+=template&lt;class RandomAccessonIterator,class Distance&gt;inline void __advance(BidirectuibIterator&amp; i,Distance n,random_access_iterator_tag)&#123; i+=n;&#125; ​ 我们再针对上面的信息，在特征萃取器中添加一个起到迭代器类型别名作用的成员iterator_category。 123456789101112131415161718192021222324//特征萃取，萃取iterator_category template&lt;class I&gt; struct iterator_traits &#123; //原有部分 ... //添加部分 typedef typename I::iterator_category iterator_category; &#125;;//以随机访问迭代器 iterator_category 为例子的偏特化中，添加别名，template&lt;class T&gt; struct iterator_traits&lt;T*&gt; &#123; ... //这样，当取iterator_category的时候，实际上得到的就是random_access_iterator_tag typedef random_access_iterator_tag iterator_category; &#125;;template&lt;class T&gt; struct iterator_traits&lt;const T*&gt; &#123; ... typedef random_access_iterator_tag iterator_category; &#125;; ​ 再写一个获得临时类型的复制函数。 1234567891011121314template&lt;class I&gt;inline typename iterator_traits&lt;I&gt;::iterator_categoryiterator_category(const I&amp;)&#123; typename iterator_traits&lt;I&gt;::iterator_category category; return category();&#125;//参数名取InputIterator的原因是STL算分的一个命名规则：以算法所能接受的最低阶迭代器类型，来为迭代器型别参数命名。//这个也很好理解，因为每个作用于基类对象的函数都可以被派生类使用。template&lt;class Inputerator,class Distance&gt;inline void advance(InputIterator &amp; i,Distance n)&#123; __advance(i,n,iterator_traits&lt;InputIterator&gt;::iterator_category());&#125; ​ 这样我们是不是就不需要每次调用advance时进行判断了，因为在编译期，我们就已经获得了每个声过的迭代器的类型iterator_category。 stl::iterator的保证 为了符合规范，任何迭代器都应该提供五个内嵌相应型别，以利于traits萃取，否则便是自别于整个STL架构，可能无法与其它STL组件顺利搭配，然而写代码难免挂一漏万，谁也不能保证不会有粗心大意的时候，如果能够将事情简化，就好多了。 STL提供了一个iterators class如下，如果每个新设计的迭代器都能继承自它，就可保证符合STL所需规范： 123456789101112template&lt;class Category, class T, class Distance = ptrdiff_t, class Pointer = T*, class Refernce = T&amp;&gt; struct iterator&#123; typedef Category iterator_category; typedef T value_type; typedef Distance distance_type; typedef Pointer pointer; typedef Refernce refernce;&#125;; iterators class不含任何成员，纯粹只是型别定义，所以继承它并不会招致任何额外负担，由于后三个参数皆有默认值，故新的迭代器只需提供两个参数即可。 ​ 因此，在前文提到自己实现的链表迭代器，可以直接这样实现： 123456789101112struct input_iterator_tag&#123;&#125;;...struct forward_iterator_tag:input_iterator_tag&#123;&#125;;... //继承与std提供的迭代器型别template &lt;class Item&gt;struct ListIter:public std::iterator&lt;std::forward_iterator_tag,Item&gt;&#123;...&#125; 总结 符合STL标准的迭代器，需要具有获取自身型别、 元素、指针差、 元素指针以及引用。 可以利用继承性与函数模板的重载优化对不同迭代器的同种函数操作。 设置适当的迭代器型别，是迭代器的责任，设计适当的迭代器，是容器的责任。 函数模板参数推导机制可以实现迭代器所存储的数据类型的获取。 traits的编程技巧之巧妙，需要好好研究。]]></content>
      <categories>
        <category>STL</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《STL源码剖析》之空间配置器]]></title>
    <url>%2F2019%2FMyLearn-STL-1%2F</url>
    <content type="text"><![CDATA[简介 ​ Allocator是C++语言标准库中最神秘的部分之一。它们很少被显式使用，标准也没有明确出它们应该在什么时候被使用。 ​ 今天的allocator与最初的STL建议非常不同，在此过程中还存在着另外两个设计－－这两个都依赖于语言的一些特性，而直到最近才在很少的几个编译器上可用。对allocator的功能，标准似乎在一些方面追加了承诺，而在另外一些方面撤销了承诺。 空间配置器的标准接口 如果我们要实现自己的空间配置器，要遵守这些标准接口。 12345678910111213141516171819allocator::value_type//值类型allocator::pointer//指针allocator::const_pointerallocator::reference//引用allocator::const_referenceallocator::size_typeallocator::difference_typeallocator::rebindallocator::allocator()//默认构造函数allocator::allocator(const allocator&amp;)//拷贝构造函数template allocator::alloctor(const alloctor &amp;)//泛化的拷贝构造allocator::~allocator()//析构函数pointer allocator::address(reference x) const //返回某个对象的地址const_pointer allocator::address(const_reference x) const //返回某个const对象的地址pointer allocator::allocate(size_type n,const void*=0)//配置空间，存储n个T对象。第二个参数是提示，可忽略void allocator::deallocate(pointer p,size_type n)//归还先前配置的空间size_type allocator::max_size() const //返回可配置的最大量void allocator::construct(pointer p,const T&amp;)//构造T对象void allocator::destroy(pointer p)//对象T的析构 rebind rebind需要详细解释一下。 rebind允许一个类型的对象的allocator分配其它类型的对象的存储。 假如有一个容器类MyVector, 它用的是Allocator_A&lt;int&gt;内存分配器，这个容器类很有可能需要double类型的分配器，而且要求对int和double类型的内存分配策略是一样的，这是rebind的意义就体现出来了。总之一句话，rebind实现了对不同类型使用同一种内存分配策略的要求。 自定义简单的空间适配器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#ifndef LQALLOC_H_INCLUDED#define LQALLOC_H_INCLUDED#include&lt;new&gt;#include&lt;cstddef&gt;//定义了一些标准宏及类型。#include&lt;cstdlib&gt;//常用函数库#include&lt;climits&gt;//定义数据类型的最大最小值#include&lt;iostream&gt;//输入输出流namespace LQ&#123; //配置模板类空间的函数，传入数据大小，申请内存 template&lt;class T&gt; inline T* _allocate(ptrdiff_t size,T*) //ptrdiff_t是C/C++标准库中定义的一个与机器相关的数据类型。ptrdiff_t类型变量通常用来保存两个指针减法操作的结果。 &#123; std::set_new_handler(nullptr); //set_new_handler(0)主要是为了卸载目前的内存分配异常处理函数，这样一来一旦分配内存失败的话，C++就会强制性抛出std:bad_alloc异常，而不是跑到处理某个异常处理函数去处理 T *tmp=(T*)(::operator new((size_t)(size *sizeof(T)))); //::operator new()这是一个重载函数，完成的操作一般只是分配内存，事实上系统默认的全局::operator new(size_t size)也只是调用malloc分配内存，并且返回一个void*指针。而构造函数的调用(如果需要)是在new运算符中完成的。 if(tmp==nullptr) &#123; std::cerr&lt;&lt;"内存超出"&lt;&lt;std::endl; exit(1); &#125; return tmp; &#125; //归还先前配置的空间 template&lt;class T&gt; inline void _deallocate(T* buffer) &#123; ::operator delete(buffer); //::operator delete()与operator new相反，释放内存。 &#125; //通过传递目标地址，和目的内容，构造出目标对象。 template&lt;class T1,class T2&gt; inline void _construct(T1 *p,const T2&amp; value) &#123; new(p) T1(value); //placement new,在指针p所指向的内存空间创建一个类型为T1的对象。 &#125; //摧毁：调用析构函数 template&lt;class T&gt; inline void _destroy(T* ptr) &#123; ptr-&gt;~T(); &#125; template&lt;class T&gt; class allocator &#123; public: typedef T value_type; typedef T* pointer; typedef const T* const_pointer; typedef T&amp; reference; typedef const T&amp; const_reference; typedef size_t size_type; typedef ptrdiff_t difference_type; template&lt;class U&gt; struct rebind &#123; //T这个类里，可以存储着U类对象 typedef allocator&lt;U&gt; other; &#125;; //申请内存 pointer allocate(size_type n,const void* hint =0) &#123; return _allocate((difference_type)n,(pointer)0); &#125; //释放内存 void deallocate(pointer p,size_type n) &#123; _deallocate(p); &#125; //调用析构函数 void destroy(pointer p) &#123; _destroy(p); &#125; //返回对象的地址 pointer address(reference x) &#123; return (pointer)&amp;x; &#125; //返回常量指针 const_pointer const_address(const_reference x) &#123; return (const_pointer)&amp;x; &#125; //返回能计算机能存储类对象的大小 size_type max_size() const &#123; return size_type(UINT_MAX/sizeof(T)); &#125; &#125;;&#125;#endif // LQALLOC_H_INCLUDED ​ 我们可以看到，这个配置器实现了最基本的四大功能，空间分配和释放，对象的构造和析构。 测试代码： 12345678910111213141516#include &lt;iostream&gt;#include &lt;vector&gt;#include"lqalloc.h"using namespace std;int main()&#123; int ia[5]=&#123;0,1,2,3,4&#125;; unsigned int i; //声明vector时，显示调用我们的自定义空间配置器。 vector&lt;int,LQ::allocator&lt;int&gt;&gt;iv&#123;ia,ia+5&#125;; for(i=0;i&lt;iv.size();i++) cout&lt;&lt;iv[i]&lt;&lt;' ';//0 1 2 3 4 cout&lt;&lt;endl; return 0;&#125; 这只是一个简单的自定义allocator，并不能使用与STL中所有容器。 根据书上介绍，在PJ STL中，由于PJ供应的许多容器都需要一个非标准的空间配置器接口,allocator::_Charalloc()。 在RW STL中,许多供应容器运用了缓冲区。 在SGI STL中，使用了专属的、 带有层次配置能力的特殊配置器。 关于STL版本，可以看一下STL版本介绍：HP STL、SGI STL、STL Port、PJ STL、RW STL SGI 的特殊空间配置器 std::alloc SGI STL是开源软件，源码可读性甚高。在《STL源码剖析》中作者极力推荐阅读，也将它当作目标源码进行剖析。 在SGI中，提供了两种空间配置器： 一种是标准的alloctor，但是只是HP默认空间配置器，SGI进行了一层很薄的封装，没有任何效率上的强化。 另一种时非标准的alloc,就是上面提到的待用层次配置能力，效率优越的特殊配置器。 我们先来分析一下，常用的类声明，对象定义，释放对象的过程。 12345678910class Foo&#123; ...&#125;;Foo* p = new Foo;//new 的时候，我们先调用了::operator new 配置内存//调用Foo的构造函数delete p;//我们先调用Foo的析构函数//最后才是::operator delete 释放内存 上面的过程还是非常容易理解的，而在标准的allocator中,规定将new和delete操作分开，由alloc:allocate负责内存的配置，alloc::deallocate负责释放内存。由::construct负责对象的构造，::destroy负责析构对象。 我们查看··头文件，可以看到包含了下面两个头文件 12#include&lt;stl_alloc.h&gt;//负责内存的配置和释放#include&lt;stl_construct.h&gt;//负责对象的构造和析构 构造和析构的工具construct和destroygraph LR destory["destory()"]--泛化forwardIt_Last_and_first-->_destroy["_destory()"] _destroy["_destory()"]-->has_trivial_destructor? has_trivial_destructor?--false_type-->for["foreach_destroy"] has_trivial_destructor?--true_type-->1["no-op"] destory["destory()"]--特化char*-->2["no-op"] destory["destory()"]--特化wchar*-->3["no-op"] destory["destory()"]--特化pointer-->pointer["pointer->~T()"] ​ 在STL中空间配置时候destory（）函数会判断要释放的迭代器的指向的对象有没有 trivial destructor（STL中有一个 has_trivial_destructor函数，很容易实现检测）放，如果有trivial destructor则什么都不做，如果没有即需要执行一些操作，则执行真正的destory函数。 ​ destory（）有两个版本，第一个版本接受一个指针，准备将该指针所指之物析构掉，第二个版本接受first和last两个迭代器，准备将[first，last]范围内的所有对象析构掉。 ​ 我们不知道这个范围有多大，万一很大，而每个对象的析构函数都无关痛痒，那么一次次调用这些析构函数，对效率是一种伤害，因此这里首先利用value_type()获得迭代器所指对象的类别，再利用_type_traits&lt;T&gt;判断该型别的析构函数是否无关痛痒，若是(_true_type)，则什么也不做就结束，若否(_false_type),这才以循环的方式巡访整个范围，并在循环中每经历一个对象就调用第一个版本的destory()。 后面补充value_type()和_type_traits&lt;T&gt;的实现~ 空间的配置和释放stl_allocSGI的设计哲学 向堆要求空间 考虑多线程状态 考虑内存不足时的应变措施 考虑内存碎片问题 SGI的双层级配置器 考虑到小型区块可能造成的内存破碎问题，SGI设计了双层级配置器。 在第一级的配置器中，直接使用malloc()和free()。在第二层的配置器中。当配置区块超过128字节时，认为内存足够大，直接调用一级配置器。反之，认为内存过小，采用内存池memory pool的整理方式。 配置器的开放级别，取决与__USE_MALLOC是否被定义。在SGI STL中并未定义。 ​ 绘制流程图来分析，编译器通过__USE_MALLOC是否定义，来决定配置器的默认级别。 123456graph LR judge&#123;__USE_MALLOC?&#125;--yes--&gt;1[将alloc定义为第一级配置器] judge--ne--&gt;2[将alloc定义为第二级配置器] 1---11[&quot;typedef __malloc_alloc_template&lt;0&gt; malloc_alloc&quot;] 11---111[&quot;typedef malloc_alloc alloc&quot;] 2---22[&quot;typedef __deault_alloc_template&lt;0,0&gt; alloc&quot;] ​ 我们可以观察到，第一级配置器，实际上是__malloc_alloc_template&lt;0&gt;类型的别名，而第二级配置器，实际上是__defualt_alloc_template&lt;0&gt;类型的别名，我们接下来实时剖析这两种类型的实现以及作用吧。 SGI 一级配置器__malloc_alloc_template源码以及个人分析注解： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#if 0# include &lt;new&gt;# define __THROW_BAD_ALLOC throw bad_alloc#elif !defined(__THROW_BAD_ALLOC)# include &lt;iostream&gt;# include &lt;stdlib.h&gt;#define __THROW_BAD_ALLOC std::cerr&lt;&lt;"out of memory"&lt;&lt;std::endl; exit(1)#endif//第一级空间配置器template&lt;int inst&gt;class __malloc_alloc_template&#123;private: //处理内存不足的情况 //oom: out of memory //当内存不足时，申请内存 static void *oom_malloc(size_t); //当内存不足时，重新规划内存 static void *oom_realloc(void *, size_t); //oom下尝试释放内存的例程 static void (* __malloc_alloc_oom_handler)();public: //配置内存 static void * allocate(size_t n) &#123; //直接调用malloc void *result = malloc(n); //第一级配置器直接使用malloc() //无法满足需求时，直接使用oom_malloc() if(0 == result) result = oom_malloc(n); return result; &#125; //释放内存 static void deallocate(void *p, size_t ) &#123; //这里直接调用free free(p); &#125; //重新规划内存 static void *reallocate(void *p, size_t , size_t new_sz) &#123; //直接调用realloc void * result = realloc(p, new_sz); //无法满足需求时，直接使用oom_realloc() if(0 == result) result = oom_realloc(p, new_sz); return result; &#125; //模仿std::set_new_handler();可以在这里定义自己oom句柄 static void (*set_malloc_handler(void (*f)()))()//函数返回值为函数指针，参数是void (*f)(),即函数指针 &#123; void (*old)() = __malloc_alloc_oom_handler; __malloc_alloc_oom_handler = f; return (old); &#125;&#125;;//malloc_alloc out_of_memory handling//将指针指向的地址为0template&lt;int inst&gt;void (*__malloc_alloc_template&lt;inst&gt;::__malloc_alloc_oom_handler)() = 0;//oom下申请内存template &lt;int inst&gt;void *__malloc_alloc_template&lt;inst&gt;::oom_malloc(size_t n)&#123; void (*my_malloc_handler)(); void *result; //不断尝试释放,配置,再释放,再配置 for(;;) &#123; my_malloc_handler = __malloc_alloc_oom_handler; if(0 == my_malloc_handler) &#123; __THROW_BAD_ALLOC; &#125; (*my_malloc_handler)();//企图释放内存 result = malloc(n); if(result) return result; &#125;&#125;//oom下重新规划内存template&lt;int inst&gt;void * __malloc_alloc_template&lt;inst&gt;::oom_realloc(void *p, size_t n)&#123; void (*my_malloc_handler)(); void *result; //与oom_malloc类似，不断尝试释放,配置,再释放,再配置 for(;;) &#123; my_malloc_handler == __malloc_alloc_oom_handler; if(0 == my_malloc_handler) &#123; __THROW_BAD_ALLOC; &#125; (*my_malloc_handler)();//企图释放内存 result = realloc(p, n); if(result) return result; &#125;&#125;//这里直接将inst指定为0了typedef __malloc_alloc_template&lt;0&gt; malloc_alloc; ​ 我们可以看到，SGI一级配置器在oom情况下，进行malloc和realloc时，会循环调用例程__malloc_alloc_oom_handler，如果例程没有被开发者设定，那么就直接cerr，或exit(1)退出。 ​ 因此书上也表明： 记住，设计“内存不足处理例程”时客户的责任，设定“内存不足处理例程”也是客端的责任。 SGI 二级配置器__default_alloc_template​ 上文提到，为了避免太多小额区块造成的内存碎片，制定了二级配置器，一般来说，小额区块越小，额外负担的比例也就越大，越显得浪费。在系统中，每索取一块内存，这块内存中都会有一部分是属于系统预留用来记住内存大小的。 ​ 我们知道。当区块小于128字节时，二级配置器会采用内存池来管理，而书中解释道，这里指的内存池管理，指配置一大块内存时，维护一个自由链表，为了方便管理，将自由链表存储的内存大小规定为8的倍数。 ​ 二级配置器维护着16个自由链表，他们维护的内存大小分别是8,16,24到128，即8*n，n∈[1,16]。 ​ 其结构如下，是一个共用体： 12345union obj&#123; union obj* free_list_link; char client_data[1];&#125;; ​ 可以看到设计者的聪明之处，使用了共用体，巧妙地避免了维护链表所必须的指针而造成内存的另一种浪费。 部分源码以及注解： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182template &lt;bool threads, int inst&gt;class __default_alloc_template &#123;private://区块上调枚举#if ! (defined(__SUNPRO_CC) || defined(__GNUC__)) enum &#123;_ALIGN = 8&#125;; enum &#123;_MAX_BYTES = 128&#125;; enum &#123;_NFREELISTS = 16&#125;; // _MAX_BYTES/_ALIGN# endifprivate://区块上调函数，接收到申请的大小，我们向上取8的倍数 static size_t ROUND_UP(size_t __bytes) &#123; return (((__bytes) + (size_t) _ALIGN-1) &amp; ~((size_t) _ALIGN - 1)); &#125;private://链表节点联合体 union _Obj &#123; union _Obj* _M_free_list_link; char _M_client_data[1]; /* The client sees this.*/ &#125;; private:# if defined(__SUNPRO_CC) || defined(__GNUC__) || defined(__HP_aCC) static _Obj* __STL_VOLATILE _S_free_list[]; # else //16个 free-list static _Obj* __STL_VOLATILE _S_free_list[_NFREELISTS]; # endif //根据申请的大小，确定出在自由链表的下标 static size_t FREELIST_INDEX(size_t __bytes) &#123; return (((__bytes) + (size_t)_ALIGN-1)/(size_t)_ALIGN - 1); &#125; //返回大小为__n的对象 static void* refill(size_t __n); //配置一大块空间，可以容纳__nobjs大小个__size的区块 //可能会随着内存不足，而降低__nobjs数量 static char* chunk_alloc(size_t __size, int&amp; __nobjs); static char* start_free; //内存池起始 static char* end_free; //内存池结束 static size_t heap_size; //区块数 public: /* __n must be &gt; 0 */ static void* allocate(size_t __n) &#123; ... &#125;; /* __p may not be 0 */ static void deallocate(void* __p, size_t __n) &#123; ... &#125; static void* reallocate(void* __p, size_t __old_sz, size_t __new_sz);&#125;;//这四个函数是静态数据成员的定义与初始设定//__threads是线程设定，书中不讨论template &lt;bool __threads, int __inst&gt;char* __default_alloc_template&lt;__threads, __inst&gt;::_S_start_free = 0;template &lt;bool __threads, int __inst&gt;char* __default_alloc_template&lt;__threads, __inst&gt;::_S_end_free = 0;template &lt;bool __threads, int __inst&gt;size_t __default_alloc_template&lt;__threads, __inst&gt;::_S_heap_size = 0;template &lt;bool __threads, int __inst&gt;typename __default_alloc_template&lt;__threads, __inst&gt;::_Obj* __STL_VOLATILE__default_alloc_template&lt;__threads, __inst&gt; ::_S_free_list[# if defined(__SUNPRO_CC) || defined(__GNUC__) || defined(__HP_aCC) _NFREELISTS# else __default_alloc_template&lt;__threads, __inst&gt;::_NFREELISTS# endif] = &#123;0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, &#125;;&#125;; ​ 看着大部分有些难以理解，但是依然能看出，定义了16个自由链表，可以申请也可以查找。 空间配置函数allocate() ​ 作为一个空间配置器，自然拥有配置器的标准接口函数allocate()，此函数首先判断区块大小，大于128字节就调用一级配置器，小于128字节就检查对应的自由链表，如果对应链表可用，那么久拿来用，反之，将区块大小上调至8倍数边界，然后调用refill()，重新填充空间。 1234567891011121314151617181920212223static void * allocate(size_t n)&#123; obj *volatile * my_free_list; obj *result; //如果申请大小n大于128，直接调用一级配置器 if(n&gt;(size_t)__MAX_BYTES) &#123; //调用一级配置器的空间配置函数。 return (malloc_alloc::allocate(n)); &#125; //通过大小确定自由链表的对应下标 my_free_list=free_list+FREELIST_INDEX(n); result=*my_free_list; //如果返回为空 if(result==0) &#123; void *r =refill(ROUND_UP(n)); return r; &#125; //对自由链表进行调整 *my_free_list=result-&gt;free_list_link; return (result);&#125; 空间释放函数deallocate() 作为一个空间配置器，自然拥有配置器的标准接口函数deallocate()，此函数首先判断区块大小，大于128字节就调用一级配置器，小于128字节就检查对应的自由链表,回收空间。 123456789101112131415161718static void * deallocate(void *p,size_t n)&#123; obj *q=(obj *)p; obj * volatile * my_free_list; //如果申请大小n大于128，直接调用一级配置器 if(n&gt;(size_t)__MAX_BYTES) &#123; //调用一级配置器的空间配置函数。 malloc_alloc::deallocate(p,n); return ; &#125; //通过大小确定自由链表的对应下标 my_free_list=free_list+FREELIST_INDEX(n); //回收 q-&gt;free_list_link=*my_free_list; *my_free_list=q;&#125; 空间填充函数refill() 回头讨论先前说过的allocate()。当它发现自由链表中没有可用区块时，会调用refill。缺省取得20个新区块，如果内存池空间不足，获得区块数可能小于20. 1234567891011121314151617181920212223242526272829303132333435363738394041template &lt;bool threads,int inst&gt;void * __default_alloc_template&lt;threads,inst&gt;::refill(size_t n)&#123; int nobjs=20; //调用chunk_alloc(),尝试取得nobjs个区块作为自由链表的新节点。 //传参nobjs是个引用 char *chunk=chunk_alloc(n,nobjs); //自由链表 obj *volatile * my_free_list; obj *result; //用于连接的前后节点 obj * current_obj,*next_obj; int i; //如果当前需求只有一个，我们直接返回给调用者，不用添加到自由链表里 if(nobjs==1) return (chunk); //取得目的自由链表 my_free_list=free_list+FREELIST_INDEX(n); //显示转换，将result指向新的来的区块头部，后面返回给调用者 result=(obj *)chunk; //chunk+n 是指chunk后移n位，就是下一块区块 *my_free_list=next_obj=(obj *)(chunk +n); for(i =1;;i++) &#123; current_obj=next_obj; //取得下一区块 next_obj=(obj*)((char *)next_obj+n); //当连接数量满足时，跳出 if(nobjs-1==i) &#123; //把尾部指向0/nullptr current_obj-&gt;free_list_link=0; break; &#125; else &#123; current_onj-&gt;free_list_link=next_obj; &#125; &#125; return(result);&#125; ​ 看完代码，就很好理解refill()的作用了,通过chunk_alloc()申请到新的区块，然后如同正常连接链表般把几个区块转换成共用体obj，再连接起来。在此之前让对应的自由链表指向第二块区块(第一块要给调用者)。 ​ 那么唯一不明白的就是chunk_alloc()时如何工作的。 空间分块函数chunk_alloc()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677template &lt;bool threads,int inst&gt;char * __default_alloc_template&lt;threads,inst&gt;::chunk_alloc(size_t size,int &amp; nobjs)&#123; char * result; //需求的内存大小 size_t total_bytes=size*nobjs; //计算内存剩余空间 size_t bytes_left=end_free-start_free; //容量足够 if(bytes_left &gt;= total_bytes) &#123; result=start_free; //将剩余的开始位置偏移调整 start_free+=total_bytes; return(result); &#125; //容量不足以全部产出，但是还可以‘挤’出几块块 else if (bytes_left &gt;= size) &#123; //计算还可以‘挤’出几块 nobjs=bytes_left/size; //新的需求大小 total_bytes=size*nobjs; result=start_free; //将剩余的开始位置偏移调整 start_free+=total_bytes; return(result); &#125; //一块也‘挤’不出 else &#123; //这里获得要使用malloc申请的内存大小，建议申请的大小是当前需求的两倍加上ROUND_UP(heap_size&gt;&gt;4)，不过目前无法理解右移4位的意思 size_t bytes_to_get=2*total_bytes+ROUND_UP(heap_size&gt;&gt;4); //如果剩余一丁点内存 if(bytes_left&gt;0) &#123; //用剩余内存大小去找到对应的自由链表 obj * volatile * my_free_list=free_list+FREELIST_INDEX(bytes_left); //数组对应自由链表头-&gt;剩余内存大小的块-&gt;原本的自由链表 ((obj *)start_free)-&gt;free_list_link=*my_free_list; *my_free_list=(obj*)start_free; &#125; //使用malloc申请大小 start_free=(char *)malloc(bytes_to_get); //申请失败 if(start_free==0) &#123; int i; obj * volatile * my_free_list,*p; //每次i+8 for (i = size;i &lt;= (size_t) __MAX_BYTES;i += (size_t) __ALIGN) &#123; //从下标0到15，检索所有自由链表 my_free_list = free_list + FREELIST_INDEX(i); p = *my_free_list; //如果某个链表还有区块 if (0 != p) &#123; //我们取一块区块出来 *my_free_list = p -&gt; free_list_link; //把这块当作新的内存池可用空间 start_free = (char*)p; end_free = start_free + i; //再调用自身，看看这个区块的内存是否足够 return(chunk_alloc(size, nobjs)); &#125; &#125; end_free = 0; //调用一级配置器，看看oom下是否可以尽力完成 start_free = (char*)malloc_alloc::allocate(bytes_to_get); &#125; heap_size += bytes_to_get; end_free = start_free + bytes_to_get; //递归自己，修正nobjs？ return(chunk_alloc(size, nobjs)); &#125; &#125;&#125; ​ 不难看出，chunk_alloc()的作用是尽力分配内存池给目标自由链表，当内存池足够时，返回需求的对应区块，不够就能产多少产多少，当一块区块都产不出的时候，开始遍历所有自由链表，尝试把它们的区块收纳，然后交给对应自由链表。 ​ 如果真的无法挤出内存了，就调用一级配置器，而一级配置器是直接使用malloc()申请内存的，因为内存已经没了，必定调用oom_malloc()，不断由例程释放内存，申请内存。 例子 假设程序一开始，客端就调用chunk_alloc(32,20),对应的free_list[3]空空如也，此时内存池为空，于是malloc()配置40个32字节的区块。并把第一个交给调用者，剩下19个交给free_list[3]维护，剩下20个交给内存池。 客端接着调用chunk_alloc(64,20),对应的free_list[7]空空如也，内存池是20*32字节大小的连续内存，可以分成10块64字节大小的区块，把第一块返回给调用者，剩下9块加入到对应的自由链表free_list[7]，此时内存池为空。 总结空间配置器的作用 在容器中，负责申请内存空间、 释放空间，对存储的对象进行构造和析构。 在析构的时候，会智能的判断，避免不重要的多次析构。 SGI一级配置器 直接调用malloc()和free()对内存进行操作。 内存不足时，进入oom(out of memory)状态，此时操作内存时，会调用留给客端实现的内存释放例程，一直释放、 申请，直到满足条件或者报错。 SGI二级配置器 二级配置器时为了尽量避免小额区块产生的内存碎片。 在SGI中，很多配置器都被缺省为二级配置器，例如sample_alloc。 如果申请内存空间时，大小大于128字节，则直接调用一级配置器。 维护16个自由链表，每个自由链表维护n个8倍数的内存区块共用体，它们之间通过指针相连。 对应自由链表没有区块时，会调用refill()以及chunk_alloc()，前者作用时将后者产出的区块维护成链表，交给对应的自由链表，后者负责操作内存，如果内存池不为空，那么利用内存池分块，将区块产出，如果内存是为空，那么调用malloc()，申请两倍的区块所需大小的内存，一半给自由链表，一半给内存池。 如果内存为0，调用一级配置器，尝试通过oom机制释放内存。]]></content>
      <categories>
        <category>STL</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆排序]]></title>
    <url>%2F2019%2FMyAlgorithm-heapSort%2F</url>
    <content type="text"><![CDATA[理论堆概述 这里的堆指的是数据结构的堆,不是操作系统中内存的堆。 堆是一种特殊的完全二叉树,特殊之处在于它的每一个点都比自身的子节点的值更大或者更小(区别于搜索树,搜索树是左子节点比右子节点更大或更小)。 而我们常说的小根堆和大根堆,指的就是上述中每个点都比自身的子节点值更大(最大堆)/更小(最小堆)。 堆排序 简单的了解了一下什么是堆之后,我们来了解一下什么是堆排序。 堆的存储方式 我们知道二叉树的存储方式可以是连续式的数组array,和连接式的树tree。 不过对于堆排序,通常都是用数组来存储数据,因为我们可以随机访问数据,并且进行快速交换。 对于下标从0开始的数组中,我们有以下三种性质: 索引为i的左孩子的索引是 (2*i+1); 索引为i的左孩子的索引是 (2*i+2); 索引为i的父结点的索引是 ((i-1)/2); 数组上面的箭头代表右节点,下面的箭头代表左节点 堆排序的思想 我们先把需要排序的数据进行初始化堆的操作,也就是把它们变成最大堆或者最小堆的形式。 每一次我们让根节点值[0]和最后一层的最右节点[n]的值交换,之后最右子节点的值[n]绝对是当前最大或者最小的。因为性质决定根节点的值是最大或者最小。 重新对0到n-1进行初始化堆操作。 重新2操作,3操作,直到0&gt;n-1。 一些可能出现的疑问1.初始化的时候就是最大/小堆了,为何不能直接输出呢? 因为根堆只能保证节点比子节点大或者小,但是不能保证子节点两个的大小顺序。 2.堆排序的使用时机 需要找到最大/小的k个元素,如果用插入排序也是需要遍历一整边,时间复杂度更大。而快排在大量数据中仅找到数个最大最小时,所用的空间复杂度更大。 代码初始化堆 如上方堆的存储方式中所述,由数组存储的第三个性质得,根堆中相对最后的节点下标为(n-1)/2,因此我们需要从该节点开始,对每一个结点和它的子节点进行对比和替换。 把当前点和子节点对比,如果子节点有更大的,那么进行替换。同样的,还要把自身比较孙子节点,进行同样的操作,因为无法保证当前节点的值比子节点小/大多少。 1234567891011121314151617181920212223242526272829303132//最大堆的初始化//a:数组指针//_begin:开始下标//_end:结束下标void InitHeapMax(vector&lt;int&gt; &amp;a,int _begin,int _end)&#123; //确定开始下标 int start=_begin; //当前最大子节点 int maxChild; //当前节点的值,用来对比 int value=a[start]; //我们从当前节点的左子节点开始,即2*i+1 //如果发现子节点比当前节点还要大/小,那么我们还要对这个子节点以及它的子节点进行一次比较 for(maxChild=2*start+1;maxChild&lt;_end;start=maxChild,maxChild=2*maxChild+1) &#123; //如果右子节点的值比左子节点的还大,那么就选右子节点,最小堆则改成大于即可 if(maxChild&lt;_end-1 &amp;&amp; a[maxChild]&lt;a[maxChild+1]) maxChild++; //如果当前节点的值比子节点的所有值都大,那么说明这一个小堆(相对来说)不需要初始化了 if(value&gt;=a[maxChild])//最小堆则改成小于等于即可 break; //否则,替换 else &#123; a[start]=a[maxChild]; a[maxChild]=value; &#125; &#125;&#125; 排序 我们替换第一个节点和最后一层的右边叶子节点,这时最后一层的右边叶子节点就是最大/最小的,然后把这个节点提取出去,将剩下的再初始化一次,继续这个操作,我们就可以依次提取出最大/小的值放在最后。 1234567891011121314151617181920212223242526//排序//a:数组指针//length:需要排序的长度(第几大/小)void HeapSort(vector&lt;int&gt; &amp;a,vector&lt;int&gt; &amp;b,int length)&#123; int _size=a.size(); int value; //从最后一个非子节点开始初始化 for(int i=(_size-2)/2;i&gt;=0;i--) InitHeapMax(a,i,_size); //提取length个增序或者降序的元素 //for(int i=_size-1;i&gt;=_size-length;i--) for(int i=_size-1;i&gt;=0;i--) &#123; //替换操作，让a[i]为当前极值 value=a[0]; a[0]=a[i]; a[i]=value; //将第 _size-i 大/小的元素加入b //b.push_back(value); //重新对剩下的排序 InitHeapMax(a,0,i); &#125;&#125; 如果初始化堆的操作是最大堆，那么最后这个数组排序的结果为增序，第一个值为最小值。 如果是最小堆，那么为降序，第一个值是最大值。 如果是为了取n个从最小值增序、最大值 降序的元素，应该反过来，在排序的过程中提取，会减少不少时间。 比如第一个值是最小值的增序序列： ​ 使用最小堆的初始化，排序的时候每次都会取到当前最小的值，添加到新数组中即可，取到一定数量就可以结束了，不需要将剩下的排序。 ​ 如果使用最大堆的初始化，那么我们需要整个排序一边，才会得到一个从小到大的序列，再取前面的n个元素达到要求。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>算法学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《图解TCP/IP》之IP协议]]></title>
    <url>%2F2019%2FMyLearn-ComputerNetwork-3%2F</url>
    <content type="text"><![CDATA[IP协议网络层的作用 IP协议运作于网络层，它的底层是数据链路层。数据链路层的作用是在两个物理设备之间传输数据，而IP协议就是两台主机之间通信，期间可能会经过很多台物理设备的转发。 书上用旅游的例子来说明： ​ 去异国旅游，我们去旅行社购买一整套的服务，旅行社说，需要先坐飞机到外国，然后坐火车到某个城市，再坐公交到具体的目的地。 仔细去揣摩，坐飞机、坐火车、坐公交都某个区间内的移动方式，坐飞机需要的飞机票、坐火车的火车票和公交车的票(当作有)。这些票据上面都注明了目的地和源地点(从x到y)，联想到数据链路层的作用，即在上层的数据中加上自己的首部数据：源和目的MAC地址。 可以发现，数据链路层都是将整个旅行路线分成一小块，从而执行一小块的任务。 那么这整个旅行路线(行程表)就是网络层的作用。 计算机网络中需要数据链路层和网络层这个分层才能实现向最终目的地址的通信。 IP基础知识面向无连接的ip协议 ip协议不是面向连接的，它不需要两个主机之间建立网络连接。 为何是面向无连接？ 为了简化，如果每一次调用ip协议都需要建立连接实在太繁琐了。 为了提速，建立连接必然造成处理速度的下降。 大家都知道，面向无连接是不可靠且不安全的，如果有需要，就得需要上一层的实现(TCP协议)。 路由控制 数据链路层会将数据发给下一个物理设备，但是ip首部数据只有ip地址，数据链路层的首部数据只有目的物理设备的mac地址做为参照，那么数据到达下一个物理设备的时候，谁告诉它相对下一个物理设备在哪呢。 这就需要路由控制去解决了。 路由器(物理设备)中的内存存储着路由表，它记录着到达目的地需要转跳的下一个物理设备的位置信息（拓扑结构）。 数据包到达路由器的时候，路由器分析IP地址，然后找到一条最佳的数据链路，将数据包发过去。 IP地址 ip地址属于网络层地址，在数据链路层传输数据的过程中不需要重新设置ip地址，只需要将ip地址转换成比特流或者对帧数据进行转发即可。 ip地址的定义 ipv4地址由32位01整数来表示。然后每8位为一组。通常每组以10进程的形式表示。如常见的本机局域网地址：192.168.1.1。 2^32很大，所以最多允许2的32次方个计算机连接到网络。当然实际上不会有那么多计算机同时联网。 ip地址的组成 一个ip地址其实是由网络标识和主机标识组成，简单来说，在同一个网络端下拥有多个主机，这里面的每一个主机的网络标识都是一样的，知识主机标识不一样，在这里通过主机标识区分。 例如局域网，都是192.168.1.x。x则是主机标识。 那么用什么来区分一个ip地址的哪一部分是网络标识和主机标识呢。 子网掩码 子网掩码的格式和ip地址的格式一样，都是32位01整数组成，将子网掩码与ip地址与运算节能得到这个ip地址的网段。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++的虚函数表知识总结]]></title>
    <url>%2F2019%2FMyLearn-VirtualCpp%2F</url>
    <content type="text"><![CDATA[为VS中的CPP属性添加一行代码 我们在VS2017中新建一个CPP工程，并新建一个源文件。 在这个工程中，我们右键属性，在C++那一项的命令行子项中添加以下代码。 1/d1 reportAllClassLayout 加上这行代码，可以在编译时，在输出窗口输出内存分布的信息。 有虚函数的类与无虚函数的类对比 我们新建两个类，分别为A和B，他们其中一个类拥有虚函数。 每一个类中有两个整形成员。 代码12345678910111213141516171819202122232425class A&#123;private: int a; int b;public: A(); ~A();private:&#125;;class B&#123;private: int a; int b;public: B(); virtual ~B(); virtual void fun();private:&#125;; 其中B类拥有虚析构函数以及一个普通虚函数。我们生成解决方案，查看输出窗口。 解释 从图上往下解释： A这个类占用内存中的8个字节。其中有两个成员ab分别占了4个字节，他们的首地址偏移量为0和4。 B这个类占用内存中的12个字节。其中发现了一个叫vfptr的成员(即虚函数表的指针)占用了4个字节。随后是两个成员ab分别占了4个字节，他们的首地址偏移量为4和8。 B:: vftavle ，即B作用域中的虚函数表，在这个表中标记了两个虚函数，分别是dtor(destructor析构函数的缩写)，以及fun。 ​ 其中，在虚函数表中左边的编号不是占用的字节，而是函数的编号。 分析 从内存分布来看，成员函数无论是否是virtual的，都不在类中，而成员变量则在。(类的非静态成员变量信息在栈上，函数在代码区里) 当类中存在虚函数的时候，系统会给它分配一个虚函数表，里面记录了这个类拥有的虚函数的指针。 当类中存在虚函数的时候，系统会给它分配一个虚函数表指针，用来指向2中的虚函数表，而这个虚函数表指针位于其内存的首位。(偏移量为0) 有虚函数类的单继承：重写与不重写 我们定一个基类A，拥有两个整形成员ab，以及虚析构函数和普通虚函数fun。 定义两个派生类SA1和SA2，它们各自拥有一个新整形成员c，其中SA2重写了基类A中的fun以及自己的析构函数。 1234567891011121314151617181920212223class A&#123;private: int a; int b;public: virtual ~A()&#123;&#125; virtual void fun()&#123;&#125;&#125;;class SA1 :public A&#123;private : int c;&#125;;class SA2 :public A&#123;private: int c;public: virtual ~SA2()&#123;&#125; virtual void fun()&#123;&#125;&#125;; 查看输出窗口 解释 从图上往下解释： SA1这个类占用内存中的16个字节。其中先排布了基类A的成员信息，与上面第一张图一样，分别是虚函数表指针、成员a、b，分别占用4字节。随后是排布SA1自己的整形成员c，占用字节4。 随后是SA1的虚函数表，可以看到，虚函数表中的fun函数作用域是基类A。而析构函数是SA1本身。(C++中的类会默认帮你生成四个默认函数：构造、析构、浅拷贝、赋值(返回浅拷贝)，如果你自己实现了，则不会再生成) SA2这个类占用内存中的16个字节。内容排版和SA1一样。 随后是SA1的虚函数表，可以看到，虚函数表中的函数作用域都是是SA2本身。 因为我们重写了基类的虚函数。 分析 派生类在内存的分布上，首先排布自己的基类成员信息，包含基类的虚函数表指针。基类成员信息的排版顺序和基类自身的一致。 ​ 随后才是自己的成员信息。 内存会为拥有虚函数的基类的派生类再生成一个虚函数表，里面指名了虚函数，如果重写了虚函数，则会被覆盖。 内存中存储基类信息中的虚函数指针不再指向基类的虚函数表，而是自己的虚函数表。 有虚函数基类的多重继承 多重继承就是爷爷-&gt;爸爸-&gt;儿子。简单理解为一条从上到下的线性继承。 我们定义三个类，也有这样的继承关系：A-&gt;B&gt;C。 其中A有虚函数fun和fun1。 B有虚函数fun2并重写虚函数fun1。 C重写虚函数fun、fun1、fun2. 1234567891011121314151617181920212223242526class A&#123;private: int a;public: virtual void fun()&#123;&#125; virtual void fun1()&#123;&#125;&#125;;class B :public A&#123;private: int b;public: virtual void fun1()&#123;&#125; virtual void fun2()&#123;&#125;&#125;;class C :public B&#123;private: int c;public: virtual void fun()&#123;&#125; virtual void fun2()&#123;&#125;&#125;; 因为输出窗口截图太长了，所以直接赋值上来了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849501&gt;class A size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | a1&gt; +---1&gt;1&gt;A::$vftable@:1&gt; | &amp;A_meta1&gt; | 01&gt; 0 | &amp;A::fun1&gt; 1 | &amp;A::fun1...1&gt;class B size(12):1&gt; +---1&gt; 0 | +--- (base class A)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | a1&gt; | +---1&gt; 8 | b1&gt; +---1&gt;1&gt;B::$vftable@:1&gt; | &amp;B_meta1&gt; | 01&gt; 0 | &amp;A::fun1&gt; 1 | &amp;B::fun11&gt; 2 | &amp;B::fun2...1&gt;class C size(16):1&gt; +---1&gt; 0 | +--- (base class B)1&gt; 0 | | +--- (base class A)1&gt; 0 | | | &#123;vfptr&#125;1&gt; 4 | | | a1&gt; | | +---1&gt; 8 | | b1&gt; | +---1&gt;12 | c1&gt; +---1&gt;1&gt;C::$vftable@:1&gt; | &amp;C_meta1&gt; | 01&gt; 0 | &amp;C::fun1&gt; 1 | &amp;B::fun11&gt; 2 | &amp;C::fun2 解释 基类A占用8个字节，分别是虚函数表指针和成员a。 ​ 在虚函数表中，函数fun和fun1作用域都属于自己。 派生类B占用12个字节，分别是基类A的虚函数表指针和成员a。加上自己的成员b。其中虚函数表指针指向自己的虚函数表而不是基类A。 ​ 在虚函数表中，因为重写了虚函数fun1，并且新增一个虚函数fun2，基类A的虚函数fun的作用域属于A。 派生类C占用16个字节，分别是基类A的虚函数表指针和成员a。和基类B的成员b，加上自己的成员c。其中虚函数表指针指向自己的虚函数表而不是基类B。 ​ 在虚函数表中，因为重写了基类的所有的虚函数fun、2，作用域都是自己。保留未重写的虚函数fun1。因为fun1来自基类B，而B重写了来自基类A的虚函数fun1，所以在C中，fun1依然属于B类。 分析 虚函数表中只会记录基类的虚函数地址(或被重写的)，以及自己的新虚函数地址。 可以理解虚函数表中记录的虚函数地址都是相对于当前类最新的虚函数(即只要被重写的虚函数，都会替代)。 多继承与虚继承多继承的二义性 JAVA中没有多继承，为何？因为多继承容易造成二义性。 我们来看看下面的代码。 创建了三个基类ABC，其中ABC都有相同名字的虚函数fun以及相同名字的char类型成员x。 12345678910111213141516171819202122232425262728293031323334353637class A&#123;public: char x = 'A'; virtual void fun() &#123; cout &lt;&lt; "来自A的fun" &lt;&lt; endl; &#125; virtual void funA() &#123;&#125;&#125;;class B&#123;public: char x = 'B'; virtual void fun() &#123; cout &lt;&lt; "来自B的fun" &lt;&lt; endl; &#125; virtual void funB() &#123;&#125;&#125;;class C&#123;public: char x = 'C'; virtual void fun() &#123; cout &lt;&lt; "来自C的fun" &lt;&lt; endl; &#125; virtual void funC() &#123;&#125;&#125;;class Son : A, B, C&#123; virtual void funSon()&#123;&#125;&#125;; 我们再创建了一个派生类Son，多继承于A,B,C。 这个时候我们通过Son对象去访问fun函数和x成员会发生什么？ 不说编译器，就算是写出代码的我们，也不知道这个Son到底是指谁。 那我们向上转换呢，结果是当然，因为我们告诉了编译器，我们想要谁的函数和成员。 向上转换后不再报错 正确输出结果 好，我们已经领略到多继承因同名而引发的二义性。这个时候我们看看这段代码在内存中的分布如何。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879801&gt;class A size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | x1&gt; | &lt;alignment member&gt; (size=3)1&gt; +---1&gt;1&gt;A::$vftable@:1&gt; | &amp;A_meta1&gt; | 01&gt; 0 | &amp;A::fun1&gt; 1 | &amp;A::funA...1&gt;class B size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | x1&gt; | &lt;alignment member&gt; (size=3)1&gt; +---1&gt;1&gt;B::$vftable@:1&gt; | &amp;B_meta1&gt; | 01&gt; 0 | &amp;B::fun1&gt; 1 | &amp;B::funB...1&gt;class C size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | x1&gt; | &lt;alignment member&gt; (size=3)1&gt; +---1&gt;1&gt;C::$vftable@:1&gt; | &amp;C_meta1&gt; | 01&gt; 0 | &amp;C::fun1&gt; 1 | &amp;C::funC...1&gt;class Son size(24):1&gt; +---1&gt; 0 | +--- (base class A)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | x1&gt; | | &lt;alignment member&gt; (size=3)1&gt; | +---1&gt; 8 | +--- (base class B)1&gt; 8 | | &#123;vfptr&#125;1&gt;12 | | x1&gt; | | &lt;alignment member&gt; (size=3)1&gt; | +---1&gt;16 | +--- (base class C)1&gt;16 | | &#123;vfptr&#125;1&gt;20 | | x1&gt; | | &lt;alignment member&gt; (size=3)1&gt; | +---1&gt; +---1&gt;1&gt;Son::$vftable@A@:1&gt; | &amp;Son_meta1&gt; | 01&gt; 0 | &amp;A::fun1&gt; 1 | &amp;A::funA1&gt; 2 | &amp;Son::funSon1&gt;1&gt;Son::$vftable@B@:1&gt; | -81&gt; 0 | &amp;B::fun1&gt; 1 | &amp;B::funB1&gt;1&gt;Son::$vftable@C@:1&gt; | -161&gt; 0 | &amp;C::fun1&gt; 1 | &amp;C::funC 解释 基类ABC不再多解释。 我们直接看派生类Son，在内存中，基类的信息按照多继承时的左到右的顺序排序，也就是A-&gt;B-&gt;C。 每一个基类成员中，都包含有指向对应虚函数表的指针以及一个char成员x。 然后有一段 (size=3) 的代码。在这里解释一下，是补充了3个字节的意思。 (为什么是三个字节，因为在整个基类成员中，占位最大的是虚函数表指针，即4个字节，那么我们就需要按照它去对齐，所以在占有一个字节的char后面补充了三个字节，这是内存对齐的知识点) 随后是三张虚函数表，偏移量从0到-8再到-16。三张表中的虚函数地址都指对应自己类中的虚函数。 在第一个虚函数表中，多出了派生类的新虚函数。 分析 在派生类对象调用相同名字的虚函数时，会产生二义性，编译器无法知道我们到底想调用哪一个虚函数表指针的虚函数。而向上转换后，明确的告诉编译器我们调用的虚函数指针是哪个基类成员中的，这样就能正确调用那个基类的虚函数。 派生类新增虚函数，放在声明的第一个基类的虚函数表中 重写多继承中的虚函数 我们将上面的代码改成这样：重写Son中对ABC的虚函数fun 1234567class Son : A, B, C&#123; virtual void fun() &#123; cout &lt;&lt; &quot;来自Son的fun&quot; &lt;&lt; endl; &#125;&#125;; 查看内存分布： 我们发现，派生类中对应基类A的虚表（虚函数表）的fun已经改变，作用域为Son。 而虚表B、C中的fun虚函数指针已经了一个goto语句，即将内存偏移x位到达虚表A，从A中读取fun函数。(编译器多聪明，不需要另建指针)。 虚继承 虚继承就是在继承时候在基类名字前加上 virtual 关键字。 没有虚函数的虚继承多重继承(包含单继承)12345678910111213class A&#123;public: int x;&#125;;class B :virtual A&#123; int y;&#125;;class C :virtual B&#123; int z;&#125;; 12345678910111213141516171819202122232425262728293031323334353637383940414243441&gt;class A size(4):1&gt; +---1&gt; 0 | x1&gt; +---1&gt;1&gt;class B size(12):1&gt; +---1&gt; 0 | &#123;vbptr&#125;1&gt; 4 | y1&gt; +---1&gt; +--- (virtual base A)1&gt; 8 | x1&gt; +---1&gt;1&gt;B::$vbtable@:1&gt; 0 | 01&gt; 1 | 8 (Bd(B+0)A)1&gt;vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; A 8 0 4 01&gt;1&gt;class C size(20):1&gt; +---1&gt; 0 | &#123;vbptr&#125;1&gt; 4 | z1&gt; +---1&gt; +--- (virtual base A)1&gt; 8 | x1&gt; +---1&gt; +--- (virtual base B)1&gt;12 | &#123;vbptr&#125;1&gt;16 | y1&gt; +---1&gt;1&gt;C::$vbtable@C@:1&gt; 0 | 01&gt; 1 | 8 (Cd(C+0)A)1&gt; 2 | 12 (Cd(C+0)B)1&gt;1&gt;C::$vbtable@B@:1&gt; 0 | 01&gt; 1 | -4 (Cd(B+0)A)1&gt;vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; A 8 0 4 01&gt; B 12 0 8 0 解释 基类A占四个字节，即自身成员x。 派生类B占8个字节，多了一个vbptr(虚基表指针)的指针，随后是自己的成员y，才到A类中的成员x。 vbtable字段中的值代表访问某个虚基表的内存偏移量。 vbi字段： class ：虚基表的类名 offset：内存偏移量 vbptr：虚基表指针位置 vbte：母鸡0 0 fvtorDisp: 下面引用于关于vtordisp知多少？ MSDN给出的解释是：虚继承中派生类重写了基类的虚函数，并且在构造函数或者析构函数中使用指向基类的指针调用了该函数，编译器会为虚基类添fVtorDisp域。 然而，经过VS2010的测试，我们发现上述示例代码便会产生vtordisp字段！条件是。 派生类重写了虚基类的虚函数。 派生类定义了构造函数或者析构函数。 分析 我们看到，只要虚继承于一个基类，就会为其创建一个虚基表，并且在内存首部生成一个虚基表指针。 而且，派生类的成员变量内存分布永远在前面(在虚基表指针的后面)，其次是基类的基类成员(如果有)，再到基类的成员。 下面引用于C++ 继承之虚继承与普通继承的内存分布 普通继承情况下，先父类元素后子类元素，若父类元素本身也是从某个爷爷类继承而来：父类是虚继承而来，则先父后子再爷爷（其实这个分布是满足规则2的）,即爷爷放在最后；父类是普通继承而来，先爷爷后父再子，即爷爷放在前面。 虚继承情况下，先子类元素后父类元素，如果父类元素本身也是从某个爷爷类继承（不论是虚继承还是普通继承）而来，则父类由类的深到浅依次分布（先爷爷后父，爷爷在子和父之间）。 有虚函数的虚继承多重继承(包含单继承) 新建三个基类ABC，每个基类拥有自己不同名的成员变量。每个基类都有自己的虚函数。 ABC父子关系为A-&gt;B-&gt;C。 其中BC重写A的虚函数fun。 派生类D重写所有虚函数。 123456789101112131415161718192021222324252627282930class A&#123;public: int a; virtual void fun() &#123;&#125; virtual void funA()&#123;&#125;;&#125;;class B :virtual A&#123;public: int b; virtual void fun() &#123;&#125; virtual void funB() &#123;&#125;;&#125;;class C :virtual B&#123;public: int c; virtual void fun() &#123;&#125; virtual void funC() &#123;&#125;;&#125;;class D :virtual C&#123;public: int d; virtual void fun() &#123;&#125; virtual void funA() &#123;&#125; virtual void funB() &#123;&#125; virtual void funC() &#123;&#125;;&#125;; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351&gt;class A size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | a1&gt; +---1&gt;1&gt;A::$vftable@:1&gt; | &amp;A_meta1&gt; | 01&gt; 0 | &amp;A::fun1&gt; 1 | &amp;A::funA1&gt;1&gt;class B size(20):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | &#123;vbptr&#125;1&gt; 8 | b1&gt; +---1&gt; +--- (virtual base A)1&gt;12 | &#123;vfptr&#125;1&gt;16 | a1&gt; +---1&gt;1&gt;B::$vftable@B@:1&gt; | &amp;B_meta1&gt; | 01&gt; 0 | &amp;B::funB1&gt;1&gt;B::$vbtable@:1&gt; 0 | -41&gt; 1 | 8 (Bd(B+4)A)1&gt;1&gt;B::$vftable@A@:1&gt; | -121&gt; 0 | &amp;B::fun1&gt; 1 | &amp;A::funA1&gt;1&gt;vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; A 12 4 4 01&gt;1&gt;class C size(32):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | &#123;vbptr&#125;1&gt; 8 | c1&gt; +---1&gt; +--- (virtual base A)1&gt;12 | &#123;vfptr&#125;1&gt;16 | a1&gt; +---1&gt; +--- (virtual base B)1&gt;20 | &#123;vfptr&#125;1&gt;24 | &#123;vbptr&#125;1&gt;28 | b1&gt; +---1&gt;1&gt;C::$vftable@:1&gt; | &amp;C_meta1&gt; | 01&gt; 0 | &amp;C::funC1&gt;1&gt;C::$vbtable@C@:1&gt; 0 | -41&gt; 1 | 8 (Cd(C+4)A)1&gt; 2 | 16 (Cd(C+4)B)1&gt;1&gt;C::$vftable@A@:1&gt; | -121&gt; 0 | &amp;C::fun1&gt; 1 | &amp;A::funA1&gt;1&gt;C::$vftable@B@:1&gt; | -201&gt; 0 | &amp;B::funB1&gt;1&gt;C::$vbtable@B@:1&gt; 0 | -41&gt; 1 | -12 (Cd(B+4)A)1&gt;1&gt;vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; A 12 4 4 01&gt; B 20 4 8 01&gt;1&gt;class D size(40):1&gt; +---1&gt; 0 | &#123;vbptr&#125;1&gt; 4 | d1&gt; +---1&gt; +--- (virtual base A)1&gt; 8 | &#123;vfptr&#125;1&gt;12 | a1&gt; +---1&gt; +--- (virtual base B)1&gt;16 | &#123;vfptr&#125;1&gt;20 | &#123;vbptr&#125;1&gt;24 | b1&gt; +---1&gt; +--- (virtual base C)1&gt;28 | &#123;vfptr&#125;1&gt;32 | &#123;vbptr&#125;1&gt;36 | c1&gt; +---1&gt;1&gt;D::$vbtable@:1&gt; 0 | 01&gt; 1 | 8 (Dd(D+0)A)1&gt; 2 | 16 (Dd(D+0)B)1&gt; 3 | 28 (Dd(D+0)C)1&gt;1&gt;D::$vftable@A@:1&gt; | -81&gt; 0 | &amp;D::fun1&gt; 1 | &amp;D::funA1&gt;1&gt;D::$vftable@B@:1&gt; | -161&gt; 0 | &amp;D::funB1&gt;1&gt;D::$vbtable@B@:1&gt; 0 | -41&gt; 1 | -12 (Dd(B+4)A)1&gt;1&gt;D::$vftable@:1&gt; | -281&gt; 0 | &amp;D::funC1&gt;1&gt;D::$vbtable@C@:1&gt; 0 | -41&gt; 1 | -24 (Dd(C+4)A)1&gt; 2 | -16 (Dd(C+4)B)1&gt;1&gt;vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; A 8 0 4 01&gt; B 16 0 8 01&gt; C 28 0 12 0 解释 A因为没有虚继承，有虚函数，所以拥有一个虚函数表指针以及虚函数表， B因为虚继承于A，拥有虚基表以及虚基表、虚函数表指针以及基类成员，因为是虚继承且有新的虚函数，所以拥有一个自己虚函数表以及指针。 ​ 其中基类的虚函数表记录从基类继承的虚函数地址，即使以被自己重写。 ​ 自己的虚函数表仅记录自己的新增虚函数地址。 C因为虚继承于B，拥有虚基表以及虚基表、虚函数表指针以及基类成员，因为是虚继承且有新的虚函数，所以拥有一个自己虚函数表以及指针。 ​ 因为B也是虚继承于A，所以在派生类C的内存中B的成员信息中拥有对应的虚基表指针。 ​ 其中基类的虚函数表记录从基类继承的虚函数地址，即使以被自己重写。 ​ 自己的虚函数表仅记录自己的新增虚函数地址。 疑问 D也如此，但是在VS输出的信息中，D却拥有了自己的虚函数表地址，并且有一个虚函数地址是指向基类C的函数funC。。 (上述的 D::\$vftable@: ， 不应该是 D::\$vftable@c@:么) 但是通过VS断点去查看局部变量的地址，发现D是没有自己的虚函数地址的，而D中C类成员的虚函数表指针可以看到funC。所以可能是VS抽风了？ 分析 不难看出，虚继承很智能的把虚函数的起源分开了，也就是很智能的将虚函数指针放在第一个提出某个虚函数的基类虚函数表中。 虚基表的作用：菱形继承问题 有下面的代码 123456789101112131415161718192021class A&#123;public: int a;&#125;;class B : public A&#123;public: int b;&#125;;class C : public A&#123;public: int c;&#125;;class D :public B, public C&#123;&#125;; 如果我们尝试访问D类的对象中的a成员，会发生什么事情呢。 很显然产生了二义性，因为B和C都继承有A的成员a，我们多继承于BC，那么这两个a，编译器不知道到底选谁。 让我们看看内存排布： 1234567891011121314151617181920212223242526272829303132333435361&gt;class A size(4):1&gt; +---1&gt; 0 | a1&gt; +---1&gt;1&gt;class B size(8):1&gt; +---1&gt; 0 | +--- (base class A)1&gt; 0 | | a1&gt; | +---1&gt; 4 | b1&gt; +---1&gt;1&gt;class C size(8):1&gt; +---1&gt; 0 | +--- (base class A)1&gt; 0 | | a1&gt; | +---1&gt; 4 | c1&gt; +---1&gt;1&gt;class D size(16):1&gt; +---1&gt; 0 | +--- (base class B)1&gt; 0 | | +--- (base class A)1&gt; 0 | | | a1&gt; | | +---1&gt; 4 | | b1&gt; | +---1&gt; 8 | +--- (base class C)1&gt; 8 | | +--- (base class A)1&gt; 8 | | | a1&gt; | | +---1&gt;12 | | c1&gt; | +---1&gt; +--- 解释 我们可以看到D类的内存分布，出现了两个a成员，分别来源于B-&gt;A和C-&gt;A。 使用虚继承的虚基表解决问题 改成下面的代码： 1234567891011121314151617181920class A&#123;public: int a;&#125;;class B : virtual public A&#123;public: int b;&#125;;class C : virtual public A&#123;public: int c;&#125;;class D :public B, public C&#123;&#125;; 不再报错 查看内存分布 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758591&gt;class A size(4):1&gt; +---1&gt; 0 | a1&gt; +---1&gt;1&gt;class B size(12):1&gt; +---1&gt; 0 | &#123;vbptr&#125;1&gt; 4 | b1&gt; +---1&gt; +--- (virtual base A)1&gt; 8 | a1&gt; +---1&gt;1&gt;B::$vbtable@:1&gt; 0 | 01&gt; 1 | 8 (Bd(B+0)A)1&gt;vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; A 8 0 4 01&gt;1&gt;class C size(12):1&gt; +---1&gt; 0 | &#123;vbptr&#125;1&gt; 4 | c1&gt; +---1&gt; +--- (virtual base A)1&gt; 8 | a1&gt; +---1&gt;1&gt;C::$vbtable@:1&gt; 0 | 01&gt; 1 | 8 (Cd(C+0)A)1&gt;vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; A 8 0 4 01&gt;1&gt;class D size(20):1&gt; +---1&gt; 0 | +--- (base class B)1&gt; 0 | | &#123;vbptr&#125;1&gt; 4 | | b1&gt; | +---1&gt; 8 | +--- (base class C)1&gt; 8 | | &#123;vbptr&#125;1&gt;12 | | c1&gt; | +---1&gt; +---1&gt; +--- (virtual base A)1&gt;16 | a1&gt; +---1&gt;1&gt;D::$vbtable@B@:1&gt; 0 | 01&gt; 1 | 16 (Dd(B+0)A)1&gt;1&gt;D::$vbtable@C@:1&gt; 0 | 01&gt; 1 | 8 (Dd(C+0)A)1&gt;vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; A 16 0 4 0 解释 1&gt;class D size(20): 1&gt; +--- 1&gt; 0 | +--- (base class B) 1&gt; 0 | | {vbptr}//起始偏移量地址为0 1&gt; 4 | | b 1&gt; | +--- 1&gt; 8 | +--- (base class C) 1&gt; 8 | | {vbptr}//起始偏移量为8 1&gt;12 | | c 1&gt; | +--- 1&gt; +--- 1&gt; +--- (virtual base A) //这里存储了A类成员信息 1&gt;16 | a//我们想要访问的成员 它在内存的偏移量为16 1&gt; +--- 1&gt; 1&gt;D::$vbtable@B@://D中的B虚基表，它记录了访问虚继承基类A的成员信息的内存偏移量 1&gt; 0 | 0 1&gt; 1 | 16 (Dd(B+0)A)//偏移16 1&gt; 1&gt;D::$vbtable@C@://D中的C虚基表，它记录了访问虚继承基类A的成员信息的内存偏移量 1&gt; 0 | 0 1&gt; 1 | 8 (Dd(C+0)A)//偏移16 我们看到B的虚基表指针的偏移量为0，而它要访问的虚基表显示偏移量为16。0+16=16。 C的虚基表指针的偏移量为8，而它要访问的虚基表显示偏移量为8。8+8=16。 显然他们都指向同一个内存偏移量为16的内容，即A类中的a成员。 分析 虚基表保存了虚继承基类成员的内存偏移量，访问的时候通过偏移访问，保证都是访问同一个数据。 总结 无虚继承 存在新的虚函数时，会创建一个虚函数表和虚函数表指针。 在多重继承中，最后的派生类只有一个虚函数表和指针。 在多继承中，有多少个虚继承的基类，就有多少个对应的虚函数表和虚函数表指针。自己的新虚函数地址存放在最左边的基类的虚函数表中。 虚继承多 重继承中，有多少个虚继承的基类，就有多少个对应的虚函数表和虚函数表指针。同时如果自己拥有新的虚函数，那么将存在一个自己的虚函数表和虚函数指针。 内存的排版为先子类成员后父类成员，即当前派生类的成员变量最先，然后按照基类的祖父类成员再到基类成员排序。 派生类重写了父类的虚函数时，对应的虚函数表中的虚函数地址以及作用域会被更改为当前派生类。 在内存排版中的同一个类的作用域中，虚函数表指针vfptr永远在虚基表指针vbptr的前面，虚基表指针永远在其他成员变量前面。 虚基表保存了虚继承基类成员的内存偏移量，访问的时候通过偏移访问，保证都是访问同一个数据。 虚函数真乱啊。。。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同步、通信与死锁]]></title>
    <url>%2F2019%2FMyLearn-OS-3%2F</url>
    <content type="text"><![CDATA[进程互斥与同步进程互斥 即进程需要互斥使用共享资源。进程具有独立性和异步性，而计算机中的资源是有限的，如果让多个进程使用同一个资源，很容易发生资源当前状态不确定的情况。 或者说，如果是多个单进程/线程顺序对资源进行访问，那么这个资源的情况我们是可以确定的，即可复现。 但是多进程/线程多同个资源进行交叉访问，如果处理不当，我们无法确定资源的情况，即不可复现。 为了避免这种问题，需要实现进程互斥。 进程同步 为了完成共同任务的进程，并发时需安排好先后执行顺序或给予某个条件来协调活动。 与互斥的区别是，同步是基于互斥的，只不过同步需要规定需要访问资源的进程/线程的访问顺序，而互斥并不关心访问顺序，只关心资源是不是只被一个进程/线程访问。 所以同步是一种更为复杂的互斥，而互斥是一种特殊的同步。 临界资源 一次只能供一个进程访问的资源。 解决进程同步问题临界区 用来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。 互斥量 互斥量可以认为是一种标记或者是一把锁，它只有两种状态，可用和不可用(锁住和开锁)。每一个访问这个资源的进程/线程都要对这个资源的互斥量进行判断。 如果是不可用的，那么我们无法读取资源进行操作。 如果可用，我们的这个进程/线程将可以获得资源的使用权利，同时将资源锁住，即互斥量变为不可用，将其他想要访问资源的进程/线程隔绝开。当使用完毕时，再将互斥量解锁。 信号量 可以理解为复杂的互斥量。 互斥量可以用0和1代表两种状态，而信号量则是0~n来代表可用和不可用。它更像是一种资源计数器，能允许多个进程/线程对资源进行访问。 但是在信号量里，很容易产生疑问，信号量允许多个进程/线程访问资源不是违背了进程互斥么？ 在百度了文章后，将原因简单概括一下： 信号量控制的资源，不一定是要被锁住的资源，而是需要规定流程去使用的资源。 比如用信号量去控制一个停车场(共享资源)里的多个停车位，每个车子(进程/线程)可以占用一个停车位，如果还有停车位，即信号量大于0，车子可以进去，否则等待。 车子进去以后停车，占用了一个停车位，所以信号量减1。车子出停车场时，停车位会空掉，所以信号量加1。 PV操作 PV操作就是对信号量(包含互斥量)的操作。 P即通过的意思，会对信号量进行减操作。 V即释放的意思，会对信号量进行加操作。 进程通信方式(仅做了解)管道 管道分为匿名管道和有名管道。 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。 管道是单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。 匿名管道(pipe) 因为匿名，只有fork出来的子进程才会拥有它的控制权。 因此匿名管道只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）。 有名管道(fifo) 因为有名(标识)，所有进程可以通过名字(标识)去访问这个管道。 因此有名管道可用于任意进程之间（非亲缘关系的进程）。 消息队列 消息队列就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。 一个队列和有名管道一样拥有自己的标识符。 消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 共享内存+信号量 就是上文所述，将资源位于共享的内存片段中成为临界资源，通过信号量的方式实现进程/线程同步，让他们根据临界资源来通信。 信号(signal) 信号是Linux系统中用于进程之间通信或操作的一种机制，信号可以在任何时候发送给某一进程，而无须知道该进程的状态。 比如在命令行界面，对任意前台进程执行ctrl+c操作，会导致进程终止。 这个就是利用了信号机制。linux对信号提供了默认操作，我们也可以在代码中通过绑定自己写的方法来替代linux默认的操作。 死锁概述 如果一个进程集合中的每一个进程都在等待只能由此集合中的其他进程才能引发的时间，而无限期陷入僵持的局面成为死锁。 产生的必要条件 互斥条件。 占有和等待条件：当进程请求不到资源时进行等待，但不释放自己以占有的资源。 不剥夺(抢占)条件：拥有资源的进程只能自愿释放资源而不是被其他进程剥夺。 循环等待条件：每一个进程都在等待下一个进程持有的资源，而下一个进程也在等待其他进程持有的资源。 其中，条件4是条件123的产生结果。 只要破坏掉任意一个条件就可以解决死锁问题。 条件破坏 条件一无法破坏。 条件二 静态分配资源：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。优点：简单易实施且安全。缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。从而使进程经常发生饥饿现象。 解决方案：进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿问题。 条件三 一旦进程无法获取资源，那么久释放它以获得的资源，以解决其他进程无法获得资源的问题。 优点：可以让其他进程得以继续。 缺点：释放已经保持的资源很有可能会导致进程之前的工作实效等，反复的申请和释放资源会导致进程的执行被无限的推迟，这不仅会延长进程的周转周期，还会影响系统的吞吐量。 条件四 采用层次分配策略，让系统把资源分层次，一个进程只可以持有某层次的资源，只可以申请比该层次更高一层的资源。 这样只有一个方向的流动，不会产生最高层和最底层的互动。(参考链表和循环链表)。 优点：不会产生循环等待。 缺点：资源利用率大大降低。 死锁避免 只介绍银行家算法。 银行家算法 假设当前系统拥有部分可用资源。 我们需要提前知道有那些进程需要判断，并且知道进程当前持有的资源以及所需资源。 然后通过计算安全序列，只要存在任意一种安全序列，就可以认为这些进程不会产生死锁。 样例 有一下5个进程。系统中有ABC三种资源。 进程 已有资源 正常工作时所需资源 A-B-C A-B-C P0 0-1-0 7-5-3 P1 2-0-0 3-2-2 P2 3-0-2 9-0-2 P3 2-1-1 2-2-2 P4 0-0-2 4-3-3 A B C 系统可用资源 3 3 2 第一步，我们先遍历所有进程的申请资源 进程 申请资源=正常工作时所需资源-持有资源 A-B-C P0 7-4-2 P1 1-2-2 P2 6-0-0 P3 0-1-1 P4 4-3-1 当前系统可用的资源为3-3-2 ，从上表可以得知，满足条件的有P1和P3，假设我们让P1先进行。 此时P1拿到了资源，它拥有的资源为3-2-2，当前系统还剩资源为2-1-0。 P1执行完毕，释放资源，此时系统则有5-3-2的资源。 我们再看上表，满足条件的有P3。我们让P3持有资源，执行完毕在释放。 释放后系统资源为7-4-3，我们再对照上表进行判断，发现P2、P4都可以运行，我们随意选择一项，假设P4。 P4释放资源后，系统可用资源为7-4-5。再让P2持资源和释放，系统资源为10-4-7。 此时只剩下进程P0，发现申请的资源都小于系统可用资源，所以最后一个进程也可以运行。 得到安全序列1-3-4-2-0 因为存在安全序列，所以这些进程不会产生死锁。 死锁恢复 解锁所有进程的执行，然后重启操作系统。 撤销死锁的所有进程。 逐个撤销死锁的进程，释放资源直到不死锁。 剥夺死锁中某进程的资源，但是不撤销该进程，直到死锁解除再归还。 SL大发，死锁发生时让进程回退直保存点。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《图解TCP/IP》之TCP/IP基础知识]]></title>
    <url>%2F2019%2FMyLearn-ComputerNetwork-2%2F</url>
    <content type="text"><![CDATA[TCP/IP基础知识TCP/IP的具体含义 根据不同的使用范围，可以分为两种含义。 仅TCP和IP两种协议。 利用IP进行通信时所必须用到的协议群的统称。如IP/ICMP、 TCP/UDP、 TELNET/FTP等等。 TCP/IP协议分层模型 书本第一章介绍了OSI参考模型（博客也记录了），而TCP/IP也有一个对应的参考模型。 可以简单的理解为，TCP/IP参考模型将OSI参考模型的顶上三层，即应用层、 表示层、 会话层概括为应用层，其余层不变。也就从原来的7层变为5层模型。 这里不多介绍数据链路层和物理层了，直接从网络层的协议讲起。 网络层 让主机与主机之间通信。 IP协议 IP是跨越网络传输数据包，使整个互联网都能收到数据的协议。IP协议使数据能够发送到对方，在发送的期间，以IP地址作为主机的标识符。 IP包含数据链路层的功能，通过IP可以经过任意的底层数据链路去实现通信。 IP是分组交换的一种协议，但是不具有重发机制，所以是非可靠性传输协议。 ICMP协议 ICMP用于在IP数据包发送异常时，向发送端发送一个err，可以用来诊断网络的健康状况。 ARP协议 可以从IP地址 解析出MAC地址。 传输层 让应用和应用之间通信。 TCP协议 面向连接的传输层协议。 可靠的传输，能保证两个主机之间的通信可达。 能够正确处理传输过程的丢包、 传输顺序错乱的异常情况。 可以有效利用带宽，缓解网络拥堵。 为了实现可靠性，定义了很多规范，因此在传输上的数据量就不是很大，因此不适合一些数据量大且频繁传输，例如视频通话。 UDP协议 面向无连接的传输层协议。 不可靠的传输，它不会关心对方是否能收到数据。 如果需要检查，只能在应用中实现而不是协议中。 性质与TCP大部分相反，因此它适合用于多播、 广播以及视频通信。 应用层 如上面所述，TCP/IP将OSI中的表示层、 会话层、 应用层一起概括为应用层，所以在TCP/IP的应用层中，它要实现OSI三层的功能。 传输层的 UDP 报文和 TCP 报文段的数据部分就是应用层交付的数据。 网络管理(SNMP)在这里不介绍，因为本人不是很了解。 WWW功能 即万维网，简称web。一般由web客户端(如浏览器)和web服务器组成。而它们之间传输的数据格式主要是HTML，即超文本标记语言，通信使用的协议是HTTP协议，即超文本传输协议。 注意：HTTP属于OSI应用层协议，HTML属于表示层协议。 电子邮件功能(E-Mail) 就是发送电子邮件，使用到的协议叫做STMP，即简单邮件传输协议，在上一篇博客举例中提到过。 原来只可以发送文本格式的邮件，在MIME协议出现后，允许发送音频、图像等。甚至能对邮件的文字格式进行更改。 STMP是传输邮件的协议(还有POP3)，而MIME是邮件格式的协议，不用弄混了。 文件传输功能(FTP) 允许两个计算机之间相互传输文件，可以选择传输过程是二进制还是文本方式。 在传输过程中，需要创建两个TCP连接，分别是发出传输请求的控制连接，以及实际的数据连接。 远程登录功能(TELNET|SSH) 远程登录的作用就不多介绍了，其中telnet是明文发送的数据，而ssh支持加密，所以普遍来说ssh更安全。 TCP/IP分层模型与通信示例 跟着书上的内容，在这里介绍应用层到物理媒介的数据处理流程。 如上图，我们从下往上看，传输层在上层包装好的数据中添加了自己的TCP首部信息，传递给下一层网络层，网络层也添加了自己的IP首部。 如同在上一篇博客的发邮件例子的过程中，发送方的邮件数据从表示层开始每一层都为数据添加一个首部信息，代表了它们在这一层的操作规定。 我们在这里依然和书上一样，使用发邮件的例子介绍它们的封装流程。 邮件样例 当发送方输入好内容，点击发送的时候。 TCP/IP的应用层开始对邮件进行编码处理，将它变成网络的通用码。(这一步在OSI中是表示层的功能)。邮件开始发送的那一刻，开始建立TCP连接，即从应用层将数据发给下一层传输层的TCP中。 TCP为了实现可靠性传输的功能，在应用层数据的前端加上了一个TCP首部，上面记录了源端口号和目的端口号，以及数据的序列号和校验和，处理好这些，它将数据发到网络层的IP中。 ​ 上图的数据即应用层数据。 网络层接受到了数据，对于网络层，它把接受到的数据当作一个整体处理，它直接在这些数据的头部上加入IP首部，上面注明了源地址和目的地址。 ​ 上图的数据部分即(应用层数据加上TCP头部信息)的数据。 这个时候，开始把数据发送给数据链路层(如路由器)，这时候我们需要知道接受方的MAC地址(如网卡地址)，我们可以通过ARP协议解析出MAC地址。 书上的图，该图对包首做了简化 数据包接收处理 数据链路层 接收到数据之后，数据链路层先查看接收端MAC地址是不是自己，如果不是则丢弃。 确定是自己的包以后，开始查找以太网包首部的类型域，以确定传过来的数据类型。当前的例子是IP包，所以我们会把数据传输给网络层的IP模块中，如果是ARP则给ARP。 网络层 例子中的网络层的IP模块接受到下一层(数据链路层)的数据，首先判断目的ip地址是不是自己，如果不是则丢弃。 确定是自己的包以后，开始查找IP包首部的协议，如果是TCP则给传输层的TCP模块，如果是UDP则给传输层的UDP模块。 传输层 例子中的传输层TCP模块接受到下一层(网络层)的数据，这个时候已经确定信息就是发送给自己了，因此不需要再确认。但是需要检验一下校验和，避免数据错误，之后查看端口号，将数据传给对应端口号的进程。同时发送一个ACK，代表接受到数据。 如果校验和不对，也会向发送方要求重发一次数据，或者是没有向发送方发送ACK，发送方也会反复发送。 应用层 我们接受到了传输层的数据，这个时候开始解析(对应OSI的表示层)数据，如果数据正常，并且磁盘有空间能正常保存，那么会发送一个处理正常的信息给发送方。 否则： 如果数据实际上并不是指向接受方，比如邮件的收件人地址并不是接受方，那么会发送一个err给发送方。 如果接收到了，但是无法正常存储，也会发送一个err。 最后接受方打开邮件，看到了发送方发来的信息。 总结 书上第二章主要就是介绍TCP/IP参考模型以及几个层中相对重要的协议，依然通过发送邮件的例子让读者了解在TCP/IP参考模型中的数据传输流程。 在发送过程中，传输层，网络层，数据链路层都会在应用层的数据包上加上一层对应的首包，分别标记端口、ip地址、mac地址。 而接收过程，则逆序解析，一一对正，只要不符合就丢弃。 最后的解析出原本的数据在应用层上被正确的使用，在这个过程中还回确保信息无误，与发送方确认。 书上第三章是数据链路层，个人仅去了解，不会专门总结一篇知识，所以下一次会跳到网络层的ip协议。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[处理器调度]]></title>
    <url>%2F2019%2FMyLearn-OS-2%2F</url>
    <content type="text"><![CDATA[处理器调度层次 本篇基于进程和线程，进程和线程的相关知识可以参考另一篇文章。 1.高级调度作用 可称为作业调度、长程调度 ，简单来说，就是从后备作业(可以理解为待安排的程序)中按照一定的调度策略选择若干个作业进入内存，开始为他们创建进程和分配资源。 同时在作业完成时做好善后工作，比如回收资源。 调用时机 当CPU空闲时间超过一定阀值，此时系统便调用高级调度，开始安排新作业。 2.中级调度作用 可称为平衡调度、中程调度，简单来说会把暂时不能运行的进程挂起，将它占用的资源释放，当资源充足的时候，解除这个进程的挂起状态，为它恢复资源。 调用时机 当内存吃紧时调用中级调度。 3.低级调度作用 可称为进程调度、线程调度、短程调度，简单来说，它会根据某种原则决定在内存中所有进程使用cpu的顺序，可以说它是操作系统最核心的调度，几乎每时每刻都在被执行。 调用时机 当cpu空闲时，说明这个时候cpu还可以被利用。 如果有某个进程的优先级别比当前使用cpu的进程还高，而且调度算法允许被抢占时，优先的那个进程将会抢占cpu。 调度性能指标资源利用率公式​ CPU利用率=CPU有效工作时间/CPU总的运行时间​ CPU总的运行时间=CPU有效工作时间+CPU空闲等待时间​ 即CPU利用率=CPU有效工作时间/(CPU有效工作时间+CPU空闲等待时间) 吞吐率 单位时间内cpu处理作业的个数。 如果处理的作业中，长作业比较多，那么相对来说，单位时间内它能处理的作业就很少，因为长作业一直做不完。此时吞吐率低。 如果处理的作业中，短作业比较多，那么相对来说，单位时间内它能处理的作业就很多，因为短作业很容易做完。此时吞吐率高。 作业长短指的是执行这个作业的必要时间的长短。 是批处理系统的重要衡量指标之一。 公平性 确保每个进程都能得到合理的CPU份额和资源份额。否则会产生进程饥饿。 进程饥饿：某个进程从创建开始到某个时间，就一直没有使用cpu的权限，那么这个进程是没有存在的意义，也就是进程饥饿。 响应时间 从交互式进程提交一个请求到获得响应之间的时间间隔。 是分时、实时系统的重要衡量指标之一。 周转时间 从系统提交作业开始到作业完成为止的时间间隔。 公式 第i个作业的周转时间ti=作业i的完成时刻f-作业的提交时刻s。 ti=tf-ts; 平均周转时间T=所有作业的周转时间相加之合/作业个数n。 T=($\sum_{i=1}^N$ti)/n 第i个作业的带权周转时间wi=第i个作业的周转时间ti/第i个作业的必要消耗时间tk wi=ti/tk 平均带权周转时间W=所有作业的带权周转时间相加之合/作业个数n。 W=($\sum_{i=1}^N$wi)/n 作业调度和低级调度算法先来先服务算法(FCFS)概述 字如其名，谁先到谁先服务，也类似数据结构中的队列，不按权值，先进先出。 非抢占式。 案例 如下标，有三个作业按1 2 3的顺序进入后备作业，这个时候因为作业1先来，所以运行它，随后是2和3。 作业名 所需CPU时间/ms 作业1 28 作业2 9 作业3 3 0-28s 28-37s 37-40s 作业1 作业2 作业3 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120/*!*************************************************** * @file: FCFS.cpp * @brief: 博客-操作系统调度算法-先来先服务 * @author: ConfuseL * @date: 3,31,2019 * @note: ****************************************************/#include &lt;bits/stdc++.h&gt;using namespace std;//所有作业提交到系统的时间const double beginTime=0;//系统时间double systemTime=0;class Job&#123; private: //作业号 int id; //所需CPU的时间 double workTime; //获得CPU运作权限的时间 double getCount; //结束时间 double finishTime; //进入内存的时间 double pushTime; //到达系统的时间 double arrival; public: Job()&#123;&#125;; Job(int id,double wT) &#123; this-&gt;id=id; workTime=wT; getCount=0; finishTime=0; pushTime=0; arrival=0; &#125; friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Job &amp;j) &#123; j.setFinishTime(systemTime); out&lt;&lt;"作业"&lt;&lt;j.id&lt;&lt;": 所需CPU时间："&lt;&lt;j.workTime&lt;&lt;"ms，进入时间："&lt;&lt;j.pushTime&lt;&lt;"ms，周转时间："&lt;&lt;j.finishTime-j.arrival&lt;&lt;endl; return out; &#125; //是否以完成 bool isDone() &#123; //当获取CPU运作权限时间大于等于工作所需要的时间，即完成。 return getCount&gt;=workTime; &#125; //设置结束时间 void setFinishTime(double finishTime) &#123; this-&gt;finishTime=finishTime; &#125; //获得CPU运作时间，一次1ms void getCPUTime(double&amp; systemTime) &#123; getCount+=1.0; systemTime+=1.0; finishTime+=1.0; &#125; //设置进入内存时间 void setPushTime(double pushTime) &#123; this-&gt;pushTime=pushTime; //结束时间从进入内存时间开始累加 finishTime=pushTime; &#125; //获得结束时间 double getFinishTime() &#123; return finishTime; &#125; //获得工作时间 double getWorkTime() &#123; return workTime; &#125; //获得提交时间 double getArrivalTime() &#123; return arrival; &#125;&#125;;int main()&#123; //平均周转和平均带权周转 double T=0,W=0; //后备作业个数个数 int jobNum=3; //后备作业队列 queue&lt;Job&gt; JobPool; //当前运行的作业 Job curJob; //测试，后备作业中有以下几个作业 JobPool.push(*(new Job(1,28))); JobPool.push(*(new Job(2,9))); JobPool.push(*(new Job(3,3))); //开始取作业，按照先进先出(队列特性) while(!JobPool.empty()) &#123; curJob=JobPool.front(); JobPool.pop(); curJob.setPushTime(systemTime); //如果作业没有完成 while(!curJob.isDone()) &#123; //给它一次运行时间(1ms) curJob.getCPUTime(systemTime); &#125; cout&lt;&lt;curJob; T+=(curJob.getFinishTime()-curJob.getArrivalTime())/jobNum; W+=((curJob.getFinishTime()-curJob.getArrivalTime())/curJob.getWorkTime())/jobNum; &#125; cout&lt;&lt;"平均周转时间："&lt;&lt;T&lt;&lt;"ms,"&lt;&lt;"平均带权周转时间："&lt;&lt;W&lt;&lt;"ms"&lt;&lt;endl; return 0;&#125; 最短作业优先算法概述 每次取所需时间最短的作业，当系统彻底空闲的时候取第一个，随后在第一个执行完毕后，检索等待的作业中所需CPU时间最短的作业，然后执行它。 非抢占式。 会造成进程饥饿，所需时间越多的就需要等待越久。 案例 如下标，有四个作业，它们同时进入后备作业，此时由于作业2所需时间最短，所以先运行作业2。 其次是作业4，1，3。 作业名 所需CPU时间/ms 作业1 9 作业2 4 作业3 10 作业4 8 0-4s 4-12s 12-21s 21-31s 作业2 作业4 作业1 作业3 代码 直接把上面FCFS的队列改成最小优先队列就好了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122/*!*************************************************** * @file: SJF.cpp * @brief: 博客-操作系统调度算法-最短作业有限 * @author: ConfuseL * @date: 3,31,2019 * @note: ****************************************************/#include &lt;bits/stdc++.h&gt;using namespace std;//系统时间double systemTime=0;class Job&#123; private: //作业号 int id; //所需CPU的时间 double workTime; //获得CPU运作权限的时间 double getCount; //结束时间 double finishTime; //进入内存的时间 double pushTime; //到达系统的时间 double arrival; public: Job()&#123;&#125;; Job(int id,double wT) &#123; this-&gt;id=id; workTime=wT; getCount=0; finishTime=0; pushTime=0; arrival=0; &#125; friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Job &amp;j) &#123; j.setFinishTime(systemTime); out&lt;&lt;"作业"&lt;&lt;j.id&lt;&lt;": 所需CPU时间："&lt;&lt;j.workTime&lt;&lt;"ms，进入时间："&lt;&lt;j.pushTime&lt;&lt;"ms，周转时间："&lt;&lt;j.finishTime-j.arrival&lt;&lt;endl; return out; &#125; //重载小于操作符 让时间小的优先 friend bool operator &lt; (const Job &amp; a,const Job &amp;b) &#123; return a.workTime&gt;b.workTime; &#125; //是否以完成 bool isDone() &#123; //当获取CPU运作权限时间大于等于工作所需要的时间，即完成。 return getCount&gt;=workTime; &#125; //获得CPU运作时间，一次1ms void getCPUTime(double&amp; systemTime) &#123; getCount+=1.0; systemTime+=1.0; &#125; //设置进入内存时间 void setPushTime(double pushTime) &#123; this-&gt;pushTime=pushTime; &#125; //设置结束时间 double setFinishTime(double finishTime) &#123; this-&gt;finishTime=finishTime; &#125; //获得结束时间 double getFinishTime() &#123; return finishTime; &#125; //获得工作时间 double getWorkTime() &#123; return workTime; &#125; //获得提交时间 double getArrivalTime() &#123; return arrival; &#125;&#125;;int main()&#123; //平均周转和平均带权周转 double T=0,W=0; //后备作业个数个数 int jobNum=4; //后备作业队列 priority_queue&lt;Job&gt; JobPool; //当前运行的作业 Job curJob; //测试，后备作业中有以下几个作业 JobPool.push(*(new Job(1,9))); JobPool.push(*(new Job(2,4))); JobPool.push(*(new Job(3,10))); JobPool.push(*(new Job(4,8))); //开始取作业，按照先进先出(队列特性) while(!JobPool.empty()) &#123; curJob=JobPool.top(); JobPool.pop(); curJob.setPushTime(systemTime); //如果作业没有完成 while(!curJob.isDone()) &#123; //给它一次运行时间(1ms) curJob.getCPUTime(systemTime); &#125; cout&lt;&lt;curJob; T+=(curJob.getFinishTime()-curJob.getArrivalTime())/jobNum; W+=((curJob.getFinishTime()-curJob.getArrivalTime())/curJob.getWorkTime())/jobNum; &#125; cout&lt;&lt;"平均周转时间："&lt;&lt;T&lt;&lt;"ms,"&lt;&lt;"平均带权周转时间："&lt;&lt;W&lt;&lt;"ms"&lt;&lt;endl; return 0;&#125; 最短剩余时间优先算法概述 这个算法其实是上面最短作业优先算法的抢占版，最短优先算法规定了每一次执行最短需求的作业，直到它完毕，但是在最短剩余时间优先算法中，每当一个新作业进入到后备内存时，就得比较当前执行的作业和后备作业中谁的需求时间最短了。 案例 如下表，四个作业分时到达。作业1最先到达，执行了1ms，随后被到来的作业2抢占，因为作业2只需要4ms，而作业1还需要7ms。 以此类推。 作业名 到达系统时间 所需CPU时间/ms 作业1 0 8 作业2 1 4 作业3 2 9 作业4 3 5 0-1MS 1-5MS 5-10MS 10-17MS 17-26MS 作业1 作业2 作业4 作业1 作业3 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177/*!*************************************************** * @file: SRTF.cpp * @brief: 博客-操作系统调度算法-最短剩余时间优先 * @author: ConfuseL * @date: 4,1,2019 * @note: ****************************************************/#include &lt;bits/stdc++.h&gt;using namespace std;//系统时间double systemTime=0;class Job&#123; private: //作业号 int id; //所需CPU的时间 double workTime; //获得CPU运作权限的时间 double getCount; //结束时间 double finishTime; //第一次进入内存的时间 double pushTime; //到达系统的时间 double arrival; public: Job()&#123;&#125;; Job(int id,double ar,double wT) &#123; this-&gt;id=id; workTime=wT; arrival=ar; getCount=0; finishTime=0; pushTime=-1; &#125; friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Job &amp;j) &#123; //当它结束的时候输出，这时候设置结束时间。 j.setFinishTime(systemTime); out&lt;&lt;"作业"&lt;&lt;j.id&lt;&lt;": 提交时间："&lt;&lt;j.arrival&lt;&lt;"ms, 所需CPU时间："&lt;&lt;j.workTime&lt;&lt;"ms，进入内存时间："&lt;&lt;j.pushTime&lt;&lt;"ms，周转时间："&lt;&lt;systemTime-j.arrival&lt;&lt;endl; return out; &#125; //重载小于操作符 让剩余时间小的优先 friend bool operator &lt; (const Job &amp; a,const Job &amp;b) &#123; return a.getSurplusTime()&gt;b.getSurplusTime(); &#125; //是否以完成 bool isDone() &#123; //当获取CPU运作权限时间大于等于工作所需要的时间，即完成。 return getCount&gt;=workTime; &#125; //设置结束时间 void setFinishTime(double finishTime) &#123; this-&gt;finishTime=finishTime; &#125; //获得CPU运作时间，一次1ms void getCPUTime(double&amp; systemTime) &#123; getCount+=1.0; systemTime+=1.0; &#125; //设置第一次进入内存时间 void setPushTime(double pushTime) &#123; //如果小于0代表第一次进 if(this-&gt;pushTime&lt;0) this-&gt;pushTime=pushTime; &#125; //获得进入内存时间 double getPushTime() &#123; return pushTime; &#125; //获得结束时间 double getFinishTime() &#123; return finishTime; &#125; //获得提交时间 double getArrivalTime() &#123; return arrival; &#125; //获得工作时间 double getWorkTime() &#123; return workTime; &#125; //获得剩余工作时间 double getSurplusTime() const &#123; return workTime-getCount; &#125;&#125;;//当前运行的作业，在这里用静态指针的原因是因为我们需要对每一次进来的作业和当前的作业进行对比甚至替换，如果在传参中声明并不能更改原来的地址，而引用做为传参却无法指向引用(队列top返回的是引用)。Job *curJob=NULL;void judge(priority_queue&lt;Job&gt; &amp;jobPool,Job &amp;newJob)&#123; //如果为空并且当前没有作业 代表第一个作业 不用推入队列 直接变成当前作业 if(jobPool.empty()&amp;&amp;curJob==NULL) &#123; curJob=&amp;newJob; if(curJob-&gt;getPushTime()&lt;1e8) curJob-&gt;setPushTime(systemTime); return; &#125; //否则推入 else jobPool.push(newJob); //判断当前和队列头部的那个剩余时间最少，然后替换 if(jobPool.top().getSurplusTime()&lt;curJob-&gt;getSurplusTime()) &#123; jobPool.push(*curJob); *(curJob)=jobPool.top(); jobPool.pop(); if(curJob-&gt;getPushTime()&lt;1e8) curJob-&gt;setPushTime(systemTime); &#125;&#125;int main()&#123; //平均周转和平均带权周转 double T=0,W=0; //后备作业个数个数 int jobNum=4; //后备作业队列 priority_queue&lt;Job&gt; JobPool; //开始取作业，按照先进先出(队列特性) do &#123; //因为知道是四个作业 所以直接打表了 如果作业很多 就要另写了 switch((int)systemTime) &#123; case 0: judge(JobPool,*(new Job(1,0,8))); break; case 1: judge(JobPool,*(new Job(2,1,4))); break; case 2: judge(JobPool,*(new Job(3,2,9))); break; case 3: judge(JobPool,*(new Job(4,3,5))); break; &#125; //给它一次运行时间(1ms) curJob-&gt;getCPUTime(systemTime); //如果作业完成 if(curJob-&gt;isDone()) &#123; //输出相关信息 cout&lt;&lt;*curJob; T+=(curJob-&gt;getFinishTime()-curJob-&gt;getArrivalTime())/jobNum; W+=((curJob-&gt;getFinishTime()-curJob-&gt;getArrivalTime())/curJob-&gt;getWorkTime())/jobNum; //读取新作业 if(!JobPool.empty()) &#123; *(curJob)=JobPool.top(); JobPool.pop(); curJob-&gt;setPushTime(systemTime); &#125; &#125; &#125; while(!curJob-&gt;isDone()||!JobPool.empty()); cout&lt;&lt;"平均周转时间："&lt;&lt;T&lt;&lt;"ms,"&lt;&lt;"平均带权周转时间："&lt;&lt;W&lt;&lt;"ms"&lt;&lt;endl; return 0;&#125; 最高响应比优先算法概述 一种即考虑作业等待时间，又考虑作业处理时间的非抢占式调度算法。 以响应比为因素，决定作业的优先情况。 响应比=作业周转时间/作业处理时间 ​ =(作业等待时间+作业处理时间)/作业处理时间 ​ =1+作业等待时间/作业处理时间 在代码中，这个1往往可以忽略掉。 案例 如下表，四个作业分时到达。作业1最先到达，执行了20ms。 在这个期间，作业234全部到达系统，位于后备作业中。 当1结束，作业2的等待时间为15ms，作业3的等待时间为10ms，作业4为5ms。 各自除以各自的所需时间，得响应比为：作业2：1，作业3：2，作业4：0.5。 因此选中作业3直到执行完毕。 以此类推。 作业名 到达系统时间 所需CPU时间/ms 作业1 0 20 作业2 5 15 作业3 10 5 作业4 15 10 0-20MS 20-25MS 25-40MS 40-50MS 作业1 作业3 作业2 作业4 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152/*!*************************************************** * @file: HRRF.cpp * @brief: 博客-操作系统调度算法-最高响应比优先 * @author: ConfuseL * @date: 4,3,2019 * @note: ****************************************************/#include &lt;bits/stdc++.h&gt;using namespace std;//系统时间double systemTime=0;const double dbMin=0.0000001;class Job&#123; private: //作业号 int id; //以获得的工作时间 double workTime; //获得CPU运作权限的时间 double getCount; //结束时间 double finishTime; //进入内存的时间 double pushTime; //到达系统的时间 double arrival; //等待时间 double await; public: Job()&#123;&#125;; Job(int id,double ar,double wT) &#123; this-&gt;id=id; workTime=wT; arrival=ar; getCount=0; finishTime=0; pushTime=-1; &#125; friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Job &amp;j) &#123; j.setFinishTime(systemTime); out&lt;&lt;"作业"&lt;&lt;j.id&lt;&lt;": 所需CPU时间："&lt;&lt;j.workTime&lt;&lt;"ms，进入时间："&lt;&lt;j.pushTime&lt;&lt;"ms，周转时间："&lt;&lt;j.finishTime-j.arrival&lt;&lt;endl; return out; &#125; //重载小于操作符 让响应比大的优先 friend bool operator &lt; (const Job &amp; a,const Job &amp;b) &#123; return a.getAwait()/a.getWorkTime()-b.getAwait()/b.getWorkTime()&gt;dbMin; &#125; //是否以完成 bool isDone() &#123; //当获取CPU运作权限时间大于等于工作所需要的时间，即完成。 return getCount&gt;=workTime; &#125; //获得CPU运作时间，一次1ms void getCPUTime(double&amp; systemTime) &#123; getCount+=1.0; systemTime+=1.0; &#125; //设置进入内存时间 void setPushTime(double pushTime) &#123; this-&gt;pushTime=pushTime; &#125; //设置等待时间 void setAwaitTime(double awaitTime) &#123; this-&gt;await=awaitTime; &#125; //设置结束时间 void setFinishTime(double finishTime) &#123; this-&gt;finishTime=finishTime; &#125; //获得结束时间 double getFinishTime() &#123; return finishTime; &#125; //获得工作时间 double getWorkTime()const &#123; return workTime; &#125; //获得提交时间 double getArrivalTime() &#123; return arrival; &#125; double getAwait()const &#123; return await; &#125;&#125;;int main()&#123; //平均周转和平均带权周转 double T=0,W=0; //后备作业个数个数 int jobNum=4; //后备作业向量 这里不用队列的原因是为了方便每一次的响应比计算 vector&lt;Job&gt; JobPool; //当前运行的作业 Job curJob=*(new Job(1,0,20)); curJob.setPushTime(systemTime); //开始取作业，按照先进先出(队列特性) do &#123; //因为知道是四个作业 所以直接打表了 如果作业很多 就要另写了 switch((int)systemTime) &#123; case 5: JobPool.push_back(*(new Job(2,5,15))); break; case 10: JobPool.push_back(*(new Job(3,10,5))); break; case 15: JobPool.push_back(*(new Job(4,15,10))); break;; &#125; curJob.getCPUTime(systemTime); if(curJob.isDone()) &#123; cout&lt;&lt;curJob; T+=(curJob.getFinishTime()-curJob.getArrivalTime())/jobNum; W+=((curJob.getFinishTime()-curJob.getArrivalTime())/curJob.getWorkTime())/jobNum; //为每一个作业刷新等待时间 for(int i=0;i&lt;JobPool.size();i++) &#123; JobPool[i].setAwaitTime(curJob.getFinishTime()-JobPool[i].getArrivalTime()); &#125; //排序 取首个 也就是响应比最大的那个 if(!JobPool.empty()) &#123; sort(JobPool.begin(),JobPool.end()); curJob=JobPool[0]; curJob.setPushTime(systemTime); JobPool.erase(JobPool.begin()); &#125; &#125; &#125; while(!curJob.isDone()||!JobPool.empty()); cout&lt;&lt;"平均周转时间："&lt;&lt;T&lt;&lt;"ms,"&lt;&lt;"平均带权周转时间："&lt;&lt;W&lt;&lt;"ms"&lt;&lt;endl; return 0;&#125;]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《图解TCP/IP》之网络基础知识]]></title>
    <url>%2F2019%2FMyLearn-ComputerNetwork-1%2F</url>
    <content type="text"><![CDATA[计算机中的协议什么是协议 简单来说，协议就是计算机与计算机之间通过网络实现通信时事先达成的一种约定。 书中有一段例子，即： 人们沟通用的语言当作“协议” 聊天当作“通信” 说话的内容当作“数据” 但是计算机并没有人类那么智能 ，人类在聊天(通信)时不需要特别注意就能自然的吐字、发音(写数据)和听懂对方的语言(数据解析)。但是计算机不会，因此需要我们提前指定好这个协议。让计算机根据这个协议，去正确的读取和发送数据。 协议的作用 让不同的设备、CPU以及不同的操作系统组成的计算机之间遵循相同的协议以能够实现通信。可以理解为通信时，两个计算机的语言，只有语言相同，两个计算机太能听懂(此语言只是举例，不指编程语言)。 分组交换技术 分组交换是指把大数据分割成多个小的包裹(packet)，随后再进行传输。 就类似于邮局发货，对于每一个包，都需要标识好发送人的信息和接受人的信息（源地址和目的地址），这样才能保证货物能够在正确的路线上传递。 原文中翻译为分组交换协议，感觉称为技术更合适，因为觉得这个 协议 两字有一点容易让人把后面学习的TCP/IP协议的 协议 混淆，因为TCP/IP使用的正是分组交换技术，所以在这里改为技术。 协议分层与OSI参考模型协议分层 国际标准化组织，根据通信协议中必要的功能分层了7个层次，而这个7个层次组成了一个模型。即OSI模型。 在这个模型中，每一层次都要接受它下一层提供的服务，同时为自己上一层提供服务。 不同层次交互时遵行的约定叫做“接口”，相同层次交互式的约定叫做“协议”。 OSI参考模型 如上所述，国际标准化组织将协议分为了7个层次，从底层到上层，为别是： 物理层-&gt;数据链路层-&gt;网络层层-&gt;传输层-&gt;会话层-&gt;表示层-&gt;应用层。 其中七层的作用如下图。 发送方调用的顺序是从上到下，接受方则相反，从下到上。 以发送邮件简单举例，发送方A想对接受方B发送一封信，那么发送方在写完信，在邮箱网页上点击了发送按钮的那一刻，我们的信件便进入了应用层。 应用层：我们的应用层知道这是一封电子邮件，选择一个适合的应用层协议:SMTP协议(先不用管它，知道它是一个发送邮件的协议就好了)，然后把这封电子邮件变成一个包裹，包的首部写了邮件的信息以及收件人。随后开始调用下一层的接口。 表示层：接受到应用层的调用，表示层先将包裹分析一边，为了保证数据格式一致性，把邮件中的信息转换为网络通用的标准数据格式，同时加上一段首部信息，标识这个数据原来的格式。转换好之后，调用下一层的接口。 会话层：会话层拿到包裹后，开始决定采用哪一种链接方式，对多个邮件是连续发呢还是一次性发完呢。在首部也添加了该层的信息：数据传输的顺序。随后调用下一层的接口。 传输层：这应该就是这本书的重点啦，这一层有TCP和UDP协议，如果选择了TCP协议，我们将建立起双方的可靠链接，反之UDP将不面向连接。此外还要进行传输前的错误检测和流控。随后数据开始经过网络层。 网络层：网络层的主要功能即是提供路由，即选择到达目标主机的最佳路径，并沿该路径传送数据包。除此之外，网络层还要能够消除网络拥挤，具有流量控制和拥挤控制的能力。选择了最佳的线路之后，开始进入数据链路层。 数据链路层：该层的数据传输单位是帧，将经过上面五层操作后的邮件的数据组合成一帧一帧的数据，开始传递给物理层。 物理层：这是最低的一层了，在这里我们把帧数据编程0101的比特，然后经过光纤啊、电缆啊、wifi啊等物理设施传输到对方对应的物理设施中。 在发送方A点击发送后的几秒内，以上操作很可能已经完成了，而接受方B的物理层也开始接受到0101的比特数据，然后从下层到上层逐个分析，在传输层使用了对应的TCP/UDP接受数据，在会话层按顺序排序数据，在表示层解码数据，在应用层把邮件放到接受方B的邮箱中，如果邮箱满了，这时候我们又会发送一条错误给发送方A，这个时候又类似发送了一封邮件，只不过发送者不再是A而是B了。 传输方式的种类面向连接与面向无连接面向连接 即双方的通信要建立在连接上。比如打电话，需要向对方拨号，而对方也必须在接通之后，两个人才能通话，这个过程就是建立连接。如果两个人其中一个人挂了电话，那么就无法在通讯，也就是连接被切断了。 TCP协议就是面向链接。 面向无连接 双方的通信不需要连接。比如寄快递，我只需要将货物给邮寄公司，填写好对方信息就好了，当包裹到对方地址的时候，对方去查收就好。 UDP协议就是面向无连接。 电路交换与分组交换电路交换 从名字上很容易理解，也就是发送方和接受方通过一条电路传递数据，如果停止传递，那么电路断开（不要和上面的面向连接搞混了，这里的电路是单独的物理通路)。 及时通信电路空闲，其他用户无法使用。 举个例子，看过一些记录背景为上时代的电影，会有过打电话的不少镜头，主角打电话给某人，然后某中继接通了电话，主角说，帮我接通B，然后中继将线路搭给了B，这时候两个人才能通话。 分组交换 上面介绍过分组交换，这里不再介绍，在此说一下它的好处。 电路交换缺点很明显，两个人只要通信就占用一条物理道路，多不方便啊。但是分组交换的话，让每个人的通信数据变成一段一段的，大家一起使用一条或者多条物理道路(分组流水线)，这样道路的利用率就大大提高了。 单播，广播，多播，任播单播 一对一的通信，就如上面的固定电话。 广播 一对多的通信，比如电视观看节目，信号源向各家各户发送。 多播 和广播类似，但是接受方是指定的，不是广播距离的看电视一样，想看就能看，在多播中，是被规定好接受方的。比如群内视频，是由群里的成员可以加入。 任播 一台发送方主机从台接受方主机中选择接送方。与多播不同的是，它只能选择一个而不是多个。 看似一对多，其实还是一对一，只不过拥有了选择的对象。 就像老师(发送方)叫同学们(多个主机)回答问题，一般选择睡觉(指定的接受方)的那个。。。 域名解析就是任播，我们解析域名，从ip表中找到它真正对应的ip地址。 地址什么是地址 地址当然是记录某个事物当前处于的位置啦，在通信传输中，地址是具有唯一性的，一个地址只能指明一个事物，这其实和变成里的指针一个性质。 但是指名的事物并不代表只是一个个体，也有可能是一个团体，就像C++中某个指针指向了一个类的对象，而这个对象中又有各个成员变量。这个指针指向了一个对象，尽管这个对象中有多个成员，但这个对象依然是唯一的。 如下图，书上举了一个老师点名的例子。虽然地址指向的都可能是个群体，但是这些群体依然是唯一的。 地址的分类 这里的分类不是编程中的int指针、char指针，而是不同协议的使用的地址。 MAC地址 简单理解为电脑里网卡的唯一标识符。 IP地址 一个网络对应一台主机的地址，一个ip对应一个主机。各运营商有各自的ip范围。 端口号 你的电脑分配给某个进程的通信号，其他电脑可以通过端口号，与你电脑中对应的进程进行通信。 总结 第一章主要是介绍了通信的协议、还有数据传输的几种类型以及地址。 其实还有网关和中继器、交换机等一些偏物理的知识，只不过我就不总结了，因为做软件比较偏向传输层以上，这里仅仅看过当作了解。 这一章只是进入计网世界的预热。下一章的内容是TCP/IP的基础知识，即将进入这本书的正题。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程、 协程、 进程的简单理解]]></title>
    <url>%2F2019%2FMyLearn-ProcessAndThreadAndCoroutine%2F</url>
    <content type="text"><![CDATA[理论 ​ 在了解协程之前，我们先了解一下操作系统中的堆、 栈。 ​ 再谈谈进程和线程。其中暂不介绍上下文。 栈 ​ 在数据结构中，栈具有先进后出的特性，也就是说，将1,2,3按顺序添加到栈结构中，再依次取出数据时，数据顺序是这样的：3,2,1。 ​ 而在操作系统中，它是内存分配的一种方式，即动态分配内存。它由编译器自动分配和释放，主要用于存放函数的参数值，局部变量等等，而它的性质也遵循先进后出。 ​ 栈存放在一级缓存中，在被调用结束后会被立即释放。 堆 ​ 在数据结构中，是一种树形结构，即完全二叉树，它的特性是某节点的值都不会比父节点的值大或者小，所以常常用来实现优先队列。 ​ 而在操作系统中，它和栈一样是动态分配内存，不同的是，它由我们分配和释放，如果我们没有主动释放，会在程序结束时被回收。 ​ 重点来了，它与数据结构的堆并不具有同种特性，它的性质更接近于链表。 ​ 堆存放在二级缓存中，调用完毕并不会被系统直接回收。 进程 ​ 进程即可并发执行的程序在某个数据集合上的一切计算活动。 ​ 可以简单的认为，在电脑上打开了一个软件，运行了一款游戏，就是开启了一个进程。 进程性质 有生命周期 拥有系统资源的基本单位 进程之间可以对等的，也可以是父子结构。 进程属性 动态性：拥有生命周期 共享性：多个进程可以执行同个程序 独立性：每个进程都是OS中的一个操作实体，拥有自己的独立栈、 堆 制约性：共享资源的制约关系 并发性：单处理器可并发执行，多处理器可并行执行 进程结构 控制块：英文缩写PCB，每一个进程捆绑一个，用来存储进程的标识、 现场、 控制信息 ，同进程创建、 回收。 程序块：即进程执行的程序 核心栈： 进程在内核模式下运行时使用的堆栈， 中断或系统过程使用； 数据块：进程处理的数据空间， 包括数据、 处理函数的用户栈（用户态）和可修改的程序； 进程的创建过程 ​ 在进程列表中增加一项，然后从PCB池里申请一个空闲的PCB然后为新进程分配唯一的标识符，同时分配地址空间等等各种资源。随后初始化PCB，如标识符、 进程优先级等，然后设置就绪态，加入就绪队列。 进程的撤销过程 ​ 可分为正常和非正常撤销，也就是类似进程运行结束、 执行非法命令、 被中断等 ​ 根据被撤销进程的标识符从相应的队列中查找并移除，并把资源归还给上一级（父进程或者是OS），如果这个进程拥有子进程，那么先对子进程同样的操作，最后将PCB回收。 进程拥有的进程状态三态 七态 线程 ​ 上面介绍了进程，可以看出进程的功能十分强大，那么为什么还需要线程呢？ ​ 首先需要明确一个概念，Linux系统中甚至没有真正的线程。不过，可以认为Linux是系统的线程是内核线程，所以调度是基于线程的。 引入线程的原因 进程切换开销大 进程通信代价大 进程间的并发性力度较粗，并发度不高，并发的本质是在时间上重叠的多个逻辑流，也就是说同时运行的多个逻辑流。并发编程要解决的一个很重要的问题就是对资源的并发访问的问题，也就是共享资源的问题。而两个进程恰恰很难在逻辑上表示共享资源。 不适应并行计算和分部并行的计算需求 不适合C/S计算的要求 线程性质 在引入线程这个概念之后，线程成为了CPU调度和分配的最小单位。 线程是进程的组成部分，是能够并发的实体。 线程不是拥有资源的单位，所以挂起状态对于线程没有任何意义。因此挂起操作不是线程级而是进程级状态。 线程可以创建另一个线程。但都是对等结构不是父子结构。 线程结构 线程控制块：英文缩写TCB，与进程的控制块相似，但是由进程操控。 线程用户栈 线程核心栈 线程与进程的关系 ​ 可以理解为线程是进程的一部分。一个线程只能属于一个进程，而一个进程可以有多个线程。线程是进程的一部分，所以线程有的时候被称为是轻权进程或者轻量级进程。 ​ 线程可以分为两部分：资源集合和线程集合。进程要支持线程的运行，并为线程提供虚拟地址空间和各种资源。 线程与进程的区别 进程之间的通信，只能通过管道、 信号的方式通信。而线程使用的资源来源于进程的共享，通信起来并没有进程这么麻烦。 一个线程只能属于一个进程，但是一个进程可以拥有多个线程。多线程处理就是允许一个进程中在同一时刻执行多个任务。 进程有自己的不共享堆，不共享栈，线程有自己的不共享栈和共享堆。 进程是拥有资源的单位，线程是调度和分配的最小单位。 多线程容易引发的问题线程安全 ​ 我们都知道线程共享使用的是来自进程的资源，那么在多个线程同时访问资源时，同时对某个资源进行操作，就会发生一些错误。 ​ 比如买票，就剩最后一张票了，两个线程同时买票，都发现了最后一张，都买掉了它，那么这个时候，系统还剩-1张票。 ​ 显然这不是我们想看到的情况。 ​ 为了解决这种问题，出现了互斥锁、信号量的等等解决方案。因为介绍这些内容篇幅过长可以自行百度。 死锁 ​ 死锁是指多个线程因竞争资源而造成的一种僵局（互相等待），经典的问题如哲学家就餐问题,因为死锁问题可以另开篇幅，在这里同样不再描述。 协程引入协程的原因 ​ 线程其实并没有提高CPU的运行速率，而只是提高了运行效率，同时会很吃CPU的性能。 涉及到同步、异步、互斥锁。 涉及到线程阻塞状态和可运行状态之间的切换。 涉及到线程上下文的切换。 可见一个进程内多个线程运作的时候进行以上操作会非常消耗性能。 协程性质 如同操作系统拥有多个进程，进程拥有多个线程一样，线程拥有多个协程。 协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。 协程是在一个线程中，每个协程对CPU进行分时处理。 协程即与多线程情况下的线程比较类似：有自己的堆栈，自己的局部变量，有自己的指令指针，但与其它协同程序共享全局变量等很多信息。 协程造成阻塞是，会影响整个线程。 线程和协程的区别 协程 :同一时间只能执行某个协程。开辟多个协程开销不大。协程适合对某任务进行分时处理。 线程: 同一时间可以同时执行多个线程。开辟多条线程开销很大。线程适合多任务同时处理。 线程和协同程序的主要不同在于：在多处理器情况下，从概念上来讲多线程程序同时运行多个线程；而协同程序是通过协作来完成，在任一指定时刻只有一个协同程序在运行，并且这个正在运行的协同程序只在必要时才会被挂起。 协程需要保证是非堵塞的且没有相互依赖，协程基本上不能同步通讯，多采用一步的消息通讯，效率比较高。 Unity3D中的线程、协程创建的线程无法调用UnityAPI ​ Unity是单线程设计的游戏引擎(很多都是，因为游戏大部分都是主循环结构)，它有一个负责主循环的主线程。基于MonoBehavior，因此游戏脚本拥有严格的生命周期。 ​ 尝试在Unity中创建线程后，很容易发现，在我们创建的线程运行函数中，无法调用Unity引擎提供的各种API，以及它提供的特殊对象。例如组件，但是常用的如int、struct类型是允许使用的。 原因 ​ 为了保证逻辑和画面按照严格的顺序更新。 无法使用UnityAPI，那么创建线程还有什么用 ​ 如果不是画面更新，也不是常规的逻辑更新（指包括AI、物理碰撞、角色控制这些），而是一些其他后台任务，比如网络传输： ​ 正如TCP或者UDP协议的传输，在TCP中，我们需要确保长链接，需要一直接受发送端发送过来的数据，如果我们把它写在主线程下，会发生什么。我们在游戏拥有聊天服务这个功能，假设使用阻塞式TCP协议，那么我们打开与某玩家的聊天窗口，向其发送数据，然后就没有然后了，因为我们必须等待对方的回复。 ​ 而我们使用多线程就可以解决了。新增线程专门用于网络通讯，而主线程根据接受到的信息负责更新逻辑以及画面。 可我想对我的游戏进行调用UnityAPI的并发或者异步操作，怎么办——使用协程 ​ 协程，即协作式程序，其思想是一系列互相依赖的协程间依次使用CPU，每次只有一个协程工作，而其他协程处于休眠状态。协程实际上是在一个线程中，只不过每个协程对CUP进行分时，协程可以访问和使用unity的所有方法和component. ​ 协程一般都是在一次Update之后被使用，协程在每次使用后会被挂起，等待下一次的使用。那么它的作用是什么呢。 ​ 比如，我们需要异步加载场景上的所有预置体，比如制作了一款关卡场景中物体比较多的游戏，我们需要在关卡开始前加载所有预置体(为了更能提现协程的作用，在这里先不考虑缓存池优化)，假设预置体真的很多，把加载都放在Start中执行，那么玩家可能会卡顿一段时间才能进入到游戏循环中，而我们使用协程，协程每次加载部分预置体，在Start中开启协程，那么协程会被执行一次，这个时候加载了部分预置体，再进行一次Update循环后，协程又一次被调用，又加载了部分预置体，而一秒中调用的Update次数足够多，所以并不会产生卡顿的感觉。 总结 进程是操作系统拥有资源的单位，一个操作系统可拥有多个进程，拥有独立的栈和堆。通常对应一个运行的程序。 线程是CPU调度和分配的最小单位，一个进程可以拥有多个线程。拥有独立的栈和共享的堆(来自进程)。通常对应一个程序中的主要功能和并发功能。 协程可以说是用户态的轻量级线程，一个线程可以拥有多个协程。拥有用户栈和共享的堆(来自线程)。通常应用于异步中。 参考文献]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图论]]></title>
    <url>%2F2019%2FMyAlgorithm-edge%2F</url>
    <content type="text"><![CDATA[最短路径问题 从文字上理解，就是求哪到哪儿的路径最短，题目会给多个点，点与点之间是否相连，权值是多少。一般来说需要我们计算一个节点到其他所有节点的最短路径。然后输出源点到某点的最短路径。 Dijkstra算法 能解决的问题：无负边的单源最短路 在带权图 G = (V, E) 中，每条边都有一个权值w[i]。路径的长度为路径上所有边权之和。 求源点 s到图中其余各顶点的最短路径。 概述 解决单源最短路径问题常用 Dijkstra 算法，用于计算一个顶点到其他所有顶点的最短路径。Dijkstra 算法的主要特点是以起点为中心，逐层向外扩展，每次都会取一个最近点继续扩展，直到取完所有点为止。 算法流程 我们定义带权图 G所有顶点的集合为V，接着我们再定义已确定从源点出发的最短路径的顶点集合为 U，初始集合 U 为空，记从源点 s 出发到每个顶点 vv 的距离为 dist_v，初始 dist_s=0。接着执行以下操作： 从 V-U 中找出一个距离源点最近的顶点 v，将 v 加入集合 U，并用 dist_v 和顶点 v 连出的边来更新和 v 相邻的、不在集合 U 中的顶点的 dist； 重复第一步操作，直到 V=U或找不出一个从 s出发有路径到达的顶点，算法结束。如果最后V≠U，说明有顶点无法从源点到达；否则每个 dist_i表示从 出发到顶点i 的最短距离。 算法优化 Dijkstra最简单的版本就是使用一个数组当作上述的集合U，每一次遍历，找出目前最新且最短的边权，以它为新的源点，同时更新与它相关的最短路径的值。 我们可以使用一个优先队列去代替数组承担集合U，这样可以保证每次取出队列头部的边权当前最小的。省去了遍历和对比的时间。 例子 如上图 ，源点为左上角，黄色点内的数字代表源点到他们的距离。初始值都是无穷大99。 先push源点，然后开始探索图，取得队列头，即源点，开始遍历，源点到右边的点边权为2，比之前的99要小，那么更新距离，同时把这个点push进去，同理对其他连接的两个点进行操作。更新后的最新距离分别为9和6，当前优先队列的值为：2,6,9。这个时候发现没有连接其他点了，结束当前循环。此时的图为第一行第二列。 因为是优先队列，我们取得的头部是源点距离为2的点，也是除了源点到自身以外当前最短的点。同样进行上述操作。 因为每一次循环，已经确定过最短路径的点不会再被push到优先队列中，所以在优先队列为空的时候，我们已经获得了源点到各点的最短距离。 如果发现到某点的最短距离为99(无穷大)，说明无法到达这个点。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465const int maxn=1e4+1;//存储from点,to点,和权值//pair是std中的一种数据结构，存储两个数据，分别用first、second取得。//可以用结构体代替vector&lt;pair&lt;int,int&gt; &gt;Edge[maxn];//存储路径长度。int s[maxn];//根据节点数初始化。void init(int n)&#123; for(int i=0;i&lt;=n;i++) &#123; Edge[i].clear(); //因为求的是最小，所以初始值应该是无穷大，方便对比 s[i]=1e9; &#125;&#125;void dijkstraByQueue()&#123; //点数目，边数目，源点 int n,e,sourse; cin&gt;&gt;n&gt;&gt;e&gt;&gt;sourse; //初始化 init(n); //from,to,worth int x,y,w; for(int i=0;i&lt;e;i++) &#123; cin&gt;&gt;x&gt;&gt;y&gt;&gt;w; //x-&gt;y=w Edge[x].push_back(make_pair(y,w)); //如果是无向图，那么反过来添加一次。 //Edge[y].push_back(make_pair(x,w)); &#125; //源点到自身的路径肯定为0 s[sourse]=0; //优先队列 ，存储边权，目标点(to)，优先队列会默认按照边权从大到小排序 priority_queue&lt;pair&lt;int,int&gt;&gt; Q; //把源点到自身的距离(0)，以及自己的节点push到优先队列中 Q.push(make_pair(0,sourse)); //开始探索地图 while(!Q.empty()) &#123; //获取当前相对最新点，然后从优先队列中弹出 int cur=Q.top().second; Q.pop(); //遍历当前点所连接的点(to)，判断他们之间的边权 for(int i=0;i&lt;Edge[cur].size();i++) &#123; //取得点 int target=Edge[cur][i].first; //判断当前记录的 源点到目标点的距离s[target] 和当前最新点与目标点的距离Edge[cur][i].second+s[cur]长度关系 if(s[target]&gt;Edge[cur][i].second+s[cur]) &#123; //如果发现当前记录并不是最短距离，那么就更新它 s[target]=Edge[cur][i].second+s[cur]; //把到达这个点的边权和点下标push到优先队列中，因为优先队列默认是按大到小排序，我们的需求是小到大，所以推入-1*边权就可以了。 //如果使用自定义的结构体，可以另写一个cmp。 Q.push(make_pair(-1*s[target],target)); &#125; &#125; &#125; //当上面的队列为空的时候，说明我们以及探索完整个图了，此时我们的s[]储存的就是源点到其他点的最短距离了。 for(int i=1;i&lt;=n;i++) cout&lt;&lt;s[i]&lt;&lt;endl;&#125; SPFA算法 能解决的问题：有负边的单源最短路 概述 其实 SPFA 本质是 Bellman-ford 算法的队列优化。由国内段凡丁教授发表，大家可以自行百度查阅相关信息。 如果没有负权边的情况下还是使用堆/优先队列优化的dijkstra吧。 算法流程 在 SPFA 算法中，使用 d_i表示从源点到顶点 i 的最短路，额外用一个队列来保存即将进行拓展的顶点列表，并用 inq_i 来标识顶点 i是不是在队列中。 初始队列中仅包含源点，且源点 s 的 d_s=0。 取出队列头顶点 u，扫描从顶点 u 出发的每条边，设每条边的另一端为 v，边 &lt;u,v&gt; 权值为 w，若 d_u+w&lt;d_v，则 将 d_v修改为 d_u+w 若 vv不在队列中，则将 v入队 重复步骤 2 直到队列为空最终 dd数组就是从源点出发到每个顶点的最短路距离。如果一个顶点从没有入队，则说明没有从源点到该顶点的路径。 负环判断 在进行 SPFA 时，用一个数组 cnt_i 来标记每个顶点入队次数。如果一个顶点入队次数 cnt_i大于顶点总数 n，则表示该图中包含负环。 代码 在这里贴下最简单的spfa实现，至于lll和slf优化在日后了解后再更新。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273vector&lt;pair&lt;int,int&gt; &gt;Edge[maxn];//多出的inQueue是为了判断某点是否在队列中。int s[maxn],inQueue[maxn];//初始化void init(int n)&#123; for(int i=0;i&lt;=n;i++) &#123; Edge[i].clear(); s[i]=1e9; inQueue[i]=0; &#125;&#125;void spfa()&#123; int n,e,source; int x,y,w; //记录被推入队列的次数，如果超过点数目n，说明有负环。 int pushCount[maxn]; cin&gt;&gt;n&gt;&gt;e&gt;&gt;source; init(n); for(int i=0;i&lt;e;i++) &#123; cin&gt;&gt;x&gt;&gt;y&gt;&gt;w; Edge[x].push_back(make_pair(y,w)); //初始化推入次数为0 pushCount[x]=0; &#125; //在这里使用的是队列不是优先队列，lll和slf优化可以使用deque queue&lt;int&gt; Q; //到自身距离为0 s[source]=0; //推入次数更新 pushCount[source]=1; //推入 Q.push(source); //开始探索 while(!Q.empty()) &#123; //取队头 int cur=Q.front(); Q.pop(); //此时队头对应的点已经不在队列里了。 inQueue[cur]=0; //和上面的dijkstra算法一样进行松弛处理 for(int i=0;i&lt;Edge[cur].size();i++) &#123; int target=Edge[cur][i].first; if(s[target]&gt;Edge[cur][i].second+s[cur]) &#123; //更新最短路径 s[target]=Edge[cur][i].second+s[cur]; //如果这个点依然在队列里，那么就不需要推入 if(inQueue[target]) continue; //如果推入此时大于点的数目n，说明有负环 if(++pushCount[target]&gt;=n) &#123; cout&lt;&lt;"-1"&lt;&lt;endl; return; &#125; //再此将它推入 inQueue[target]=1; Q.push(target); &#125; &#125; &#125; //输出最短距离 for(int i=0;i&lt;n;i++) cout&lt;&lt;s[i]&lt;&lt;endl;&#125; Floyd算法 能解决的问题：多源点最短路径 时间复杂度很高，毕竟要求出所有点到其他点的最短距离。 概述 Floyd 算法是一种利用动态规划的思想、计算给定的带权图中任意两个顶点之间最短路径的算法。相比于重复执行多次单源最短路算法，Floyd 具有高效、代码简短的优势，在解决图论最短路题目时比较常用。 算法流程 Floyd 的基本思想是：对于一个顶点个数为 n 的有向图，并有一个n×n 的E[][]，其中矩阵横列下标相等，代表自身到自身，对应的值应为0对于其余任意两个顶点 i,j若它们之间存在有向边，则以此边权上的权值作为E[i][j]=w；若两个顶点i,j 之间不存在有向边，则E[i][j]=INF。对于循环阶段 ，尝试增加一个中继点 k，如果通过中间顶点使得最短路径变短了，就更新结果。累加 k，重复遍历所有可能成为中继的点下标，直到 k=n。算法结束后，矩阵 E[][]中的元素就代表着图中任意两点之间的最短路径长度。 代码1234567891011121314151617181920212223242526272829303132333435363738394041const int inf = 0x3f3f3f3f;const int maxn=1e4+1;//用矩阵存储距离int g[maxn][maxn]; // 初始化void init() &#123; for (int i = 0; i &lt; n; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; if (i == j) &#123; //到自身的距离为0 g[i][j] = 0; &#125; else &#123; //初始化为无穷大 g[i][j] = inf; &#125; &#125; &#125;&#125;void floyd() &#123; int n,e; int x,y,w; cin&gt;&gt;n&gt;&gt;e; for(int i=0;i&lt;e;i++) &#123; cin&gt;&gt;x&gt;&gt;y&gt;&gt;w; //x到y的边权为w g[x][y]=w; &#125; //三重循环，分别代表中继点k、当前点i(from)，目标点j(to) for (int k = 0; k &lt; n; ++k) &#123; for (int i = 0; i &lt; n; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; //如果i到k+k到j的距离比原来i直接到j的距离还短，就更新 if (g[i][k] + g[k][j] &lt; g[i][j]) &#123; g[i][j] = g[i][k] + g[k][j]; &#125; &#125; &#125; &#125;&#125; 最小生成树问题 一个有 n 个结点的连通图的生成树是原图的极小连通子图，且包含原图中的所有 n 个结点，并且有保持图连通的最少的边。 一般常见题目是求道路如何建设，使得各个位置能够互通，并且花费最少。 prim算法概述 Prim算法求最小生成树的时候和边数无关，和顶点数有关，所以适合求解稠密网的最小生成树。 每一次从已经纳入最小生成树的点出发，找到所连接的未纳入的最短边权点，将其纳入生成树中，直到遍历所有点。 算法流程 将一个图分为两部分，一部分归为点集U，一部分归为点集V，U的初始集合为{V1}，V的初始集合为{ALL-V1}。 针对U开始找U中各节点的所有关联的边的权值最小的那个，然后将关联的节点Vi加入到U中，并且从V中删除（注意不能形成环）。 递归执行步骤2，直到V中的集合为空。 U中所有节点构成的树就是最小生成树。 例子 如上图，我们以点为单位，从V1点出发，找到它连接的点V2、V3、V4，其中最短边权为V1-&gt;V3=1，所以我们将V3纳入最小生成树(算法流程所述的集合U)，此时U为{V1、V3}。 然后从V1、V3这个最小生成树所连接的点继续寻找，找到V3-&gt;V6的边权最小，为4，那么纳入最小生成树，继续以上操作，直到遍历完毕。 如果遍历结束后，发现有些点没被访问，就说明无法构成生成树。 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364const int maxn = 4e+1;//和前面的算法一样使用vector&lt;pair&lt;int,int&gt; &gt;//pair存储to,value//G[i]的i代表fromvector&lt;pair&lt;int,int&gt; &gt;G[maxn];int vis[maxn];void Prim()&#123; int n,e,x,y,z; //最小生成树的权值 int res=0; //输入点、边的数目 cin&gt;&gt;n&gt;&gt;e; for(int i=0;i&lt;e;i++) &#123; cin&gt;&gt;x&gt;&gt;y&gt;&gt;z; //一般都是求无向图的最小生成树，有向图可以使用最小树形图。 //-1*z 是因为优先队列默认从大到小，我们需要从小到大，随意推入取负的值。 //自己实现结构体可以自己另写cmp G[x].push_back(make_pair(y,-1*z)); G[y].push_back(make_pair(x,-1*z)); &#125; //从第一个点开始，下标为0，或者定义为1，后面也要从1开始。 vis[0]=1; priority_queue&lt;pair&lt;int,int&gt; &gt; Q; for(int i=0;i&lt;G[0].size();i++) &#123; //遍历连接到的点，推入优先队列中，会自动按边权值排序。 Q.push(G[0][i]); &#125; //开始探索 while(!Q.empty()) &#123; //取得队头的点的连接目标点to和权值value int to=Q.top().first; int value=Q.top().second; ///弹出 Q.pop(); //如果已经访问过，也就是说，已经在当前的生成树中/集合U中 if(vis[to]) continue; //否则标记以访问/纳入 vis[to]=1; //加入最小生成树的权值，因为之前我们把每条边的权值当作负数推入，这里减到而不是加上，--得+ res-=value; //遍历当前点可以到达的所有点，推入优先队列。 for(int i=0;i&lt;G[to].size();i++) &#123; Q.push(G[to][i]); &#125; &#125; //如果有点没访问，说明无法构成最小生成树 for(int i=0;i&lt;n;i++) if(vis[i]==0) &#123; cout&lt;&lt;-1&lt;&lt;endl; return; &#125; //输出花费 cout&lt;&lt;res&lt;&lt;endl;&#125; Kruskal算法概述 与prim相反，kruskal算法的注重点是边而不是点，它每次取图中相对权值最小的边，然后将边的两端点纳入集合中。而它基于并查集的思想。（什么是并查集) 算法流程 创建一个数组，为每个节点存储自身的父节点，初始化为自身。也就是刚开始，每个人只指向自己。 我们将边权按从小到大的顺序，排序好边权和对应的两端点。 我们取当前最小边权，把其两端点合并，也就是让他们的存储父节点的数组对应的值指向同一个节点，换句话说，这就是一个两个点组合成的子树了。 一直到所有点都纳入那个子树。 注意的是，合并两个点时，不是简单的赋值点下标，而是应该找到点的最终父节点，再把其赋值给另一端点的数组索引中。 例子 下图是kruskal算法，因为和prim算法用的是同一个原图，所以一起展示。 将边权排序得：1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;5-&gt;5-&gt;6-&gt;6 这里采用按秩合并。 我们取1，它的两端点是V1、V3 ，将他们合并 {V1,V3}，他们此时记录父节点的数组f[V1]=f[V3]=V1; 同理取2，它的两端点是V4、V6， 将他们合并{V4，V6},他们此时记录父节点的数组f[V4]=f[V6]=V4; 同理取3，它的两端点是V2、V5， 将他们合并{V2，V5},他们此时记录父节点的数组f[V2]=f[V5]=V2; 同理取4，它的两端点是V3、V6， 将他们合并{V3，V6},注意，这时候，V3的父节点即f[V3]的值为V1，而V6的父节点即f[V6]的值为V4，将其赋值，得f[V3]=f[V4]=V1,而V6的父节点依然为V4，但是V6的祖父节点f[V4]是V1了。合并的集合也成{V1、V3 、V6、V4} 此时树为：V1-&gt;V3 ​ \-&gt;V4-&gt;V6 同理取5，把端点V3的祖父节点赋值给另一个断点的祖父节点f[V2]，最后得树： V1-&gt;V3-&gt;V2-&gt;V5 ​ \-&gt;V4-&gt;V6 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788const int maxn=1e5+1;//记录父亲节点int father[maxn];//因为我们需要对边权排序，并且需要获得两端点的下标，那么之前的vector&lt;pair&lt;,&gt;&gt; 在这里就用处不大了。struct Edge&#123; int from, to; long long value; //重写操作符，让它进入优先队列时自动按从小到大排序 friend bool operator &lt;(const Edge x,const Edge y) &#123; return x.value&gt;y.value; &#125;&#125;;void init(int n)&#123; for(int i=0;i&lt;=n;i++) &#123; //初始化，让所有点的父节点为自身 father[i]=i; &#125;&#125;//查找组父节点int findRoot(int target)&#123;//如果父节点是自身，说明已经到头了，也就是找到祖父了。 return father[target]==target ?target:findRoot(father[target]);&#125;//判断两个点x和y是不是指向同一个父亲节点，也就是是否在同一个集合中bool isUnion(int x,int y)&#123; return findRoot(x)==findRoot(y);&#125;//整合void comeTogeter(int x,int y)&#123; if(isUnion(x,y)) return ; //把x的祖父节点的父节点设置为y的祖父节点。 father[findRoot(x)]=findRoot(y);&#125;void kruskal()&#123; //点、边 int n,e; //to from worth int x,y,w; //花费 int res=0; //临时Edge对象 cin&gt;&gt;n&gt;&gt;e; //初始化 init(n); priority_queue&lt;Edge&gt; Q; for(int i=0;i&lt;e;i++) &#123; cin&gt;&gt;x&gt;&gt;y&gt;&gt;w; Edge temp; temp.from=x; temp.to=y; temp.value=w; Q.push(temp); &#125; Edge temp; while(!Q.empty()) &#123; //取队列头，C++提供浅拷贝，直接赋值就好了 temp=Q.top(); Q.pop(); //判断是否在同个集合里，如果在就跳过 if(isUnion(temp.from,temp.to)) continue; //不在，那么整合 comeTogeter(temp.from,temp.to); //加入边权 res+=temp.value; &#125; //判断是不是所有点都在一个集合/生成树中 for(int i=1;i&lt;n;i++) if(!isUnion(0,i)) &#123; res=-1; break; &#125; cout&lt;&lt;res&lt;&lt;endl;&#125; 最大匹配问题 把所有点分成两个左右集合，左右集合里的点可以与对面集合的多个点有边，但不与同集合的点有边。 那么一般会问你求最大匹配和完美匹配。 什么是最大匹配？ ​ 上面谈到一个点可以与对面多个点有边，所以有可能出现左集合中的两点与对面集合的某点都有一条边，那么怎么分配，才能尽量让左右集合里的点一一对应且不重复呢。 ​ 网上很多都是拿男女生牵手的例子，每个男生都对自己心仪的女生们发出牵手请求，如何安排使得尽量满足每个男生都能牵到心仪女生的手，并且不会出现两个男生抢一个女生的 情况。求能牵手成功的最大数量，就是最大匹配。 ​ 什么时完美匹配？ ​ 基于最大匹配，左右集合的所有点都与对面集合有且只有一条边。 ​ 如图Fig.4 ，1-7；2-5；3-6‘4-8；一一对应且不占用同个右边的点。 匈牙利算法概述 发现概述不起来，直接看算法流程吧0 0 算法流程 假设有集合UX、UY，其中UX有多个点连接UY中的n个点，n&gt;=1 从UX的点xi开始遍历，找到它连接的第一个对面点yj，如果这个对面点yj没有被连接，那么我们将该点xi和对面点yi连接。 如果对面点yj被连接了，这时候并不是直接放弃，我们获取对面点yj所连接的点xk,这时候我们对xk进行上述操作，也就是说，我们要找到xk能连接的下一个对面点(抛开yj) ​ 1.如果找不到，说明xk只能连接yj，那么xi只能找它的下一个可连接点。 ​ 2.如果找得到，那么让xk放弃yj，连接其他的点，让xi与yj连接。 OK，这就是主要流程，我们对所有UX中的点按顺序进行上述操作，直到最后一个点，我们就可以找出最大匹配的数量了。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//邻接矩阵 值为1 代表i和j可以连接int e[maxn][maxn];//记录当前X集合和Y集合里某点连接的点下标int fromX[maxn],fromY[maxn];//是否访问过int vis[maxn];//X集合的数目和Y的int nX,nY;//尝试搜寻连接 //x：尝试连接的点下标bool line(int x)&#123; //从1到nY遍历，也可以从0到ny-1，看输入情况 for(int y=1;y&lt;=nY;y++) &#123; //如果他们可以连接 并且 Y集合的y点没有被访问过(被连接过) if(e[x][y]&amp;&amp;!vis[y]) &#123; //访问y vis[y]=1; //如果y连接的点=-1，-1代表还没和任何点连接 //或者连接了某点 调用line为这个点递归查找是否可以连接其他点 if(fromY[y]==-1||line(fromY[y])) &#123; //让x和y连接，并在fromX/Y中登记连接对象的下标 fromX[x]=y; fromY[y]=x; //返回可以连接 //注意 如果这个点y是第一次被访问，此时返回true代表它第一次被连接 //如果是被递归调用，则代表它以被允许连接的下一个点连接 return true; &#125; &#125; &#125; //返回不可以连接||不可以被下一个点连接 return false;&#125;//最大匹配int maxMatch()&#123; //连接数n x集合数 y集合数 int n,x,y; //最大匹配的数值 int sum=0; memset(fromX,-1,sizeof(fromX)); memset(fromY,-1,sizeof(fromY)); memset(e,0,sizeof(e)); cin&gt;&gt;n; cin&gt;&gt;nX&gt;&gt;xY; for(int i=0;i&lt;n;i++) &#123; cin&gt;&gt;x&gt;&gt;y; //可以连接 为1 e[x][y]=1; &#125; for(int i=1;i&lt;=nX;i++) &#123; //如果x集合中的i还没有和对面连接 if(fromX[i]==-1) &#123; //格式化访问数组vis 这个是精髓 因为每一次调用line，都可能造成第一次连接的那个点的重新连接，所以vis数组是要被格式化的。 memset(vis,0,sizeof(vis)); //如果可以连接 那么数目加1 if(line(i)) sum++;; &#125; &#125; //如果sum=nX||sum=nY （看题目要求，以X集合为主还是Y集合为主） //如果X/Y集合的所有点都成功连接了唯一的对面集合的点 那么就是完美匹配~ cout&lt;&lt;sum&lt;&lt;endl;&#125; 参考文章]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>算法学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大整数字符串的加减乘(含负数)]]></title>
    <url>%2F2019%2FMyAlgorithm-bigNum%2F</url>
    <content type="text"><![CDATA[什么是大数 首先计算机的数据类型所能表示的范围都是有限的。 表数据来源于网络 Type Size 数值范围 无值型void 0 byte 无值域 布尔型bool 1 byte true false 有符号短整型short [int] /signed short [int] 2 byte -32768~32767 无符号短整型unsigned short [int] 2 byte 0~65535 有符号整型int /signed [int] 4 byte -2147483648~2147483647 无符号整型unsigned [int] 4 byte 0~4294967295 有符号长整型long [int]/signed long [int] 4 byte -2147483648~2147483647 无符号长整型unsigned long [int] 4 byte 0~4294967295 long long 8 byte 0~18446744073709552000 有符号字符型char/signed char 1 byte -128~127 无符号字符型unsigned char 1 byte 0~255 宽字符型wchar_t (unsigned short.) 2 byte 0~65535 单精度浮点型float 4 byte -3.4E-38~3.4E+38 双精度浮点型double 8 byte 1.7E-308~1.7E+308 long double 8 byte 而比这些数值范围更大、或者是计算之后超出数值范围的数值都可以成为大数，当我们要对位数达到上百位的大整数进行计算，这些数据类型显然不能满足我们的要求，因此我们需要通过算法来实现这些功能。 正数加法大体思路 思想是采用用字符串表示大数。末尾逐位相加，超十进位。 计算前被加数比加数长度短 为了方便计算，我们在接受到两个需要相加的正整数时，应该将更长位数的大数置上，短的置下。 计算过程1.长度不扩充情况197+13计算 面向下面的大数，从末位开始与上置位的每一位对应数值相加。即表中的下标2。 当前游标 a 1 9 7 b 1 3 ​ a[2]+b[2] =&gt; 7+3=10，发现计算点相加后大于等于10而造成了进位，那么我们应该自身减10，通过为上置位的进位点加1，即9+1=10。至于处理后进位点是否也大于10，我们无需处理，因为我们只需要关心当前位的运算，以及对前一位的影响（即表中的计算点和进位点）。 假设进位点同时也大于10，那么我们在它变成当前点时再进行计算进位就好了。 当前游标 进位点 计算点 a 1 9-&gt;10 7-&gt;10-&gt;0 b 1 3 ​ 计算点计算，10+1=11， 计算点自身减10，发现需要进位，进位点加1。得到结果210。 如果进位时，发现进位点不存在，那么意味着相加后，长度发生了变化，这个时候，如果只是相加运算，我们只需要在上置位字符串a前方加一个’1’就好了，为什么就是’1’呢，因为保证计算点的数值是个数位，无论再怎么大也不会产生进位点进2位的情况。 但是，如果需要被大数相乘的函数调用，就不能简单的加1了，因为相乘后可能出现进位点的数值超过1.当然是为了以防万一，但感觉似乎不会产生进位+2以上的情况。。。 当前游标 进位点 计算点 a 1-&gt;2 10-&gt;11-&gt;1 0 b 1 3 2.长度扩充情况99+1计算 当前游标 进位点 计算点 a 9 9 b 1 a[1]+b[1]=&gt;9+1=10，计算点自身减10，进位点进位，9+1=10，10-10=0 当前游标 进位点 计算点 a 9-&gt;10 9-&gt;10-&gt;0 b 1 计算点a[0]+b[0]=&gt; 10+0=0,，计算点自身减10，10-10=0,进位点进位，发现超出长度，此时在字符串首加’1’，得到结果100。 当前游标 进位点 计算点 a 1 10-&gt;0 0 b 1 代码12345678910111213141516171819202122232425262728293031string bigNumAdd(string a,string b)&#123; //把长的字符串上置位，即换成a if(a.length()&lt;b.length()) &#123; //交换 swap(a,b); &#125; //计算点下标从长度-1开始，取两个i、j变量指向计算点，是为了判断是否结束以及是否超出 for(int i=a.length()-1,j=b.length()-1;i&gt;=0;i--,j--) &#123; //j是字符串b的计算点下标，如果依然大于0，说明还在长度内，可以正常计算 //正常计算的时候利用ascii码性质-'0'获得实际上增加的数值 //如果超出了就加0，即不变 a[i]+=(j&gt;=0?b[j]-'0':0); //发现计算点大于10，需要进位 if(a[i]-'0'&gt;=10) &#123; //如果计算点在a中的位置不是首位，那么进位点正常加上进位数 if(i) a[i-1]+=((a[i]-'0')/10); //如果是首位，也就是说，进位点超出了原本的长度，那么我们在a字符串这里加上进位的值就好了 else a=(char)(((a[i]-'0')/10)+'0')+a; //自身余10 a[i]=((a[i]-'0')%10)+'0'; &#125; &#125; return a;&#125; 减法大体思路 关键思路和加法差别不大，只需要在对应的操作更改以下就好了，当然，在这之前需要对被减数和减数。 计算前1.被减数为负数 由 -a-b = -(a+b) ，其中a&gt;0 得 我们将被减数的负号去掉，然后把被减数和减数当作两个正整数相加，得到的结果加上符号即可。 直接调用上面写的相加函数就好了。 2.被减数是正数 这时候我们要考虑被减数和减数他们的长度关系了,如果被减数长度比减数小，那么结果必然是负数。 由 a-b = –(b-a)，其中a&gt;0 得 我们将被减数和减数交换，让长的减数成为被减数，然后在结果前加上负号。 计算过程100-1计算 当前游标 借位点 计算点 a 1 0 0 b 1 a[2]-b[2]=&gt;0-1=-1,，计算点发现小于0，将自身取绝对值,，借位点借位，借位点减1; 当前游标 借位点 计算点 a 1 0-&gt;-9 0-&gt;-9-&gt;9 b 1 a[1]-b[1]=&gt;9-0=-9,，计算点发现小于0，将自身取绝对值,，借位点借位，借位点减1; 当前游标 借位点 计算点 a 1-&gt;0 -9-&gt;9 9 b 0 这个时候，发现结果的有效长度应该由3变为2，那么我们将第一个字符串元素去掉即可。 当前游标 借位点 计算点 a 9 9 b 0 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354string bigNumDel(string a,string b)&#123; //判断结果是不是负数，根据这个来判断是否在字符串前面加'-' bool isFushu=false; //情况1，被减数是负数，我们将其取正，两数相加，再加上负号 if(a[0]=='-') &#123; a.erase(a.begin()); isFushu=true; return '-'+bigNumAdd(a,b); &#125; //情况2，判断长度，如果被减数短，那么交换，结果必为负数 if(a.length()&lt;b.length()) &#123; isFushu=true; swap(a,b); &#125; //与加法的遍历方法一致 for(int i=a.length()-1,j=b.length()-1;i&gt;=0;i--,j--) &#123; //与加法的运算一致 a[i]-=(j&gt;=0?b[j]-'0':0); //如果小于0 if(a[i]&lt;'0') &#123; //取正数，为什么是加10呢？ 举个例子 //a[i]='0'-1 即 数值结果为-9 取正应该得9 //a[i]+=10 -&gt;'0'-1+10= '0'+9 ='9' a[i]=a[i]+10; //如果还在有效长度内 if(i) &#123; //借位 a[i-1]--; &#125; //否则不在有效长度内 else if(j==0) &#123; //结果为负数 isFushu=true; &#125; &#125; &#125; //开始去首位0操作 if(a[0]=='0') &#123; while(a[0]=='0') &#123; a.erase(a.begin()); &#125; &#125; //判断是否负数来加符号 return isFushu?'-'+a:a;&#125; 乘法大体思路 相信大部分人首算乘法的时候，都习惯从末尾开始乘，然后进位，但是要仔细考虑，进位之后，得到的数据应该缓存起来，最后相加而不是直接在原字符串上改变进位点的数值。也就是说 567 * 3 =21+180+1500 . 上面这种末尾相乘方法其实效率并不高，每个数字之间相乘的结果都要缓存一次，而其实我们只需要首位相乘就可以解决多次缓存的问题了，即从ab 中，对a的首位开始进行乘法运算，因为从前往后运算，计算点影响的值只会是前一位进位点，后面的都不会被影响到，所以只需要新建一个临时字符串c赋值a的元素，然后直接在c上更改就好。 也就是 567 3 =1701 计算过程计算前 乘法运算也需要和前两种运算一样，要求长度更长的置上方。 1.统计两个乘数是否为负数 负负得正，正负得负，将负号统计并且移除，在最后结果上根据情况加负号。 2.非特殊情况 新建一个字符串res，用于存储结果，然后在b的每位数字开始相乘时，新建一个临时字符串，存储这个数值对a乘法后的结果，然后加入res中。 当前游标 res a 4 5 7 b 3 4 temp 4 5 6 为了方便演示，我们从b的首位开始逐个对照a的首位开始算，3*4=12，先把2存储在temp的对应位置中。 在代码中，无论从b的首位还是末位开始遍历，只要从a的首位开始计算就行，只要加’0’的次数正确，结果不变。 当前游标 进位点 计算点 a 4 5 6 b 3 4 temp 4-&gt;2 5 6 然后12是大于10的，这时候我们需要在temp字符串前加入需要进位的数值 ，即 ‘1’。 当前游标 进位点 计算点 a 4 5 7 b 3 4 temp 1 2 5 6 接着对a的下一位进行运算，即3*5=15，对应计算点的temp数值改成5，进位点进位1。 当前游标 进位点 计算点 a 4 5 7 b 3 4 temp 1 2-&gt;3 5-&gt;5 6 同理，对a的下一位继续运算，即3*7=21，对应计算点的temp数值改成1，进位点进位2。 当前游标 进位点 计算点 a 4 5 7 b 3 4 temp 1 3 5-&gt;7 6-&gt;1 此时temp字符串的值应为’1’ ‘3’ ‘7’ ‘1‘，重点来了，我们应该记住在b字符串运算位距离末位的值，随后根据这个值，对temp末位逐个加’0’ 因为例子中b长度为2，当前从首位开始算， 所以相差1位，那么在temp末尾加1个‘0’ temp=”13710”,把他加入res,用上述的大数相加运算。 同理把4和457进行一次运算，得到的新temp也加入到res中 最后根据前面统计的负号个数，对结果进行加负号处理。 3.特殊情况 如果按照首位逐个相乘，如果遇到如699这样，即第一次运算 60 9=540 , 随后运算 9 * 9 =81 ,发现进位点4+8 超过10 这个时候怎么处理呢。 很简单，无视就好，它会在被调用大数相加运算的时候，自动向前进位的。 此时temp=’5’ ‘12’ ‘1’。 我们bigNumAdd(res,temp)。 在内循环中，因为12&gt;10 ，会把1加到5身上。结果为621 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263string bigNumMul(string a,string b)&#123; //统计负数个数 int fushu=0; string resStr; if(a[0]=='-') &#123; fushu++; a.erase(a.begin()); &#125; if(b[0]=='-') &#123; fushu++; b.erase(b.begin()); &#125; if(a.length()&lt;b.length()) &#123; swap(a,b); &#125; //面向b的末尾开始 for(int i=b.length()-1;i&gt;=0;i--) &#123; //新建临时字符串 string tempStr; //复制严肃，这里其实只要长度相等就可以了，不需要元素一致 tempStr.assign(a); //计算当前b的计算位距离末尾的长度，决定加0次数 int zeroB=b.length()-i-1; //从a的首位开始，因为这里复制了a的元素，直接从temp上索引 //如果上面的temp只复制了长度，那么就要从a本身索引 for(int j=0;j&lt;tempStr.length();j++) &#123; //相乘 int res=(tempStr[j]-'0')*(b[i]-'0'); //自身更正 tempStr[j]=res%10+'0'; //相乘结果大于10 if(res&gt;=10) &#123; //计算点在temp/a的首位，也就说进位点会超出范围 if(j==0) &#123; //在temp前加上进位的值的ascii码 tempStr=(char)((res/10)%10+'0')+tempStr; //长度加1，我们的j也要相对后移 ++j; &#125; else &#123; //否则正常进位 tempStr[j-1]+=(res/10)%10; &#125; &#125; &#125; //加'0'操作 for(int k=0;k&lt;zeroB;k++) tempStr+='0'; //与res相加 如果出现了特殊情况，会在其中被进位修正。 resStr=bigNumAdd(resStr,tempStr); &#125; //判断负数情况，加负号 return fushu==1 ? '-'+resStr:resStr;&#125; 总结 加法减法从被加/被减末尾开始算。 减法/乘法需要考虑负数情况。 乘法从被乘数的首位开始算。 加法运算要注意进位操作，减法要记得减0操作，乘法要加0操作。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>算法学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity Anima2D编辑器的轻量骨骼动画和换装使用]]></title>
    <url>%2F2019%2FMyLearn-Anima2D%2F</url>
    <content type="text"><![CDATA[[TOC] &lt;学习记录&gt;Unity Anima2D编辑器的轻量骨骼动画和换装使用前言​ 前不久觉得骨骼动画难弄而选择帧动画，现在发现，一个人制作帧动画的工作量真的大，特别是发现需要换肤功能的时候，目前没有找到可以让同一个帧动画替换特定像素达到换肤效果的简易方法（shader可以简单换色，但是如果要有特别的形状图案就很复杂了），于是乎找到了一些关于Unity5.x版本之后自带的anima2D骨骼动画系统的一些文档，决定弃用帧动画使用骨骼动画。 ​ 这篇来做一个简易演示。 图片准备​ 将精灵图拖到Unity之后设置属性，因为画的时候是以1像素为单位，所以选择了FilterMode为Point。随后通过SpriteEditor将图片切割好，注意这里一定要规定好切割区域的大小，也就是规定如所有头部、身体精灵图的共同切割大小，以便骨骼的绑定不会产生换肤的图片偏移，对碰撞体有要求的同样可以设置得精细一点。 精灵网格和骨骼设置​ 将必要的头、身体、腿的图片拖入视图后，摆好位置，创建父物体Player，对其一一设置精灵网格，右键2D Object-&gt;SpriteMesh ​ 随后可以在父物体Player下创建骨骼，右键2D Object-&gt;Bone ​ 将创建的骨骼与摆好的图片对齐，如果在骨骼下创建骨骼，会生成子骨骼，子骨骼会随着父骨骼移动。 ​ 骨骼绑定​ 设置好骨骼，图片也对应好之后，将网格与骨骼绑定，点击视图中的头，查看监视面板，创建了网格会绑定的两个组件分别是SpriteMeshInstance和SpriteMeshRenderer，本篇只讲解SpriteMeshInstance的用法，SpriteMesh是精灵网格，可以在面板上设置，也可以在代码上设置，这也是本篇换装的重要途径，随后是颜色、材质、层级、Set bones骨骼设置，我们将对应的骨骼拖入这里，注意，拖入带有子骨骼的骨骼，会将子骨骼一起绑定，若子骨骼需要与其他图片绑定，请删除掉，以免冲突。 ​ 拖入以后并没有直接绑定成功，这时候我们需要通过Anima2D编辑器绑定骨骼，菜单栏Winodws-&gt;Anima2D-&gt;SpriteMesh Editor，点击Bind按钮将自动的计算骨骼的权重。点击Apply即可绑定，也可以通过Weight Editor设置影响程度，在此之前也可以在编辑器上通过鼠标来划分你的蒙皮需求。如果一张图片上有多个骨骼，那么你就要设置每个骨骼在某些三角形上的权重，让骨骼动作时图片动作的更逼真。而个人不需要过于精细，因此本篇没有特定设置蒙皮划分。 ​ 绑定骨骼以后，可以在视图界面控制骨骼，查看是否绑定成功。 IK绑定​ 反向力学系统，一般我们是通过骨骼的动作去控制图片，设置IK并绑定骨骼的话，通过操作IK控件，骨骼也会随着移动。这样我们可以更方便的做一些动画了。（展示图没有绑定武器，所以效果并不明显，但是骨骼效果随着IK的移动而移动很直白） ​ IK动画分两种:IK CCD、IK Limb。​ IK Limb适合肢体骨骼动画。IK CCD适合更长的骨骼。本篇使用Limb，在父物体Player下创建IK，右键2D Object-&gt;IK Limb ，在视图将IK部件移动到合适的位置之后，监视面板绑定骨骼，在这里，我们可以想像IK为关节，我们人体控制关节，骨骼也会随之移动，所以将IK绑定到对应的骨骼就好了。 骨骼动画和换装​ 利用Animation编辑器，新建anim动画，对骨骼进行操作录制即可，然后播放的时候，通过改变对应SpriteMeshInstance的精灵网格即可。 ​ 注意，你要对所有提供换装的精灵网格对它对应骨骼进行单独的绑定！ ​ 以下为本篇的换装样例代码 1234567891011121314151617181920212223242526using Anima2D;using System.Collections;using System.Collections.Generic;using UnityEngine;public class DebugBone : MonoBehaviour &#123; private SpriteMeshInstance body; private Object[] clothesMesh; int key = 0; // Use this for initialization void Start () &#123; body = GameObject.Find(&quot;身体&quot;).GetComponent&lt;SpriteMeshInstance&gt;(); clothesMesh = Resources.LoadAll(&quot;SpriteMesh/clothes&quot;); &#125; // Update is called once per frame void Update () &#123; if (Input.GetKeyDown(KeyCode.A)) &#123; key++; key = key % 6; body.spriteMesh = (SpriteMesh)clothesMesh[key]; &#125; &#125;&#125; 参考文章和视频​ 视频： 【游戏美术难于上青天】 系列 ​ 文章： Anima2D官方中文使用手册（对应Anima2D1.1.4）]]></content>
      <categories>
        <category>Unity3D</category>
      </categories>
      <tags>
        <tag>问题以及解决方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Unity3D引用某些DLL发布之后可能出现的错误]]></title>
    <url>%2F2018%2FMyIssue-Solution-DLL%2F</url>
    <content type="text"><![CDATA[[TOC] 目的：在肝专业课设的时候，需要用的EPPLSUE.DLL写表格文件时，以及想用IRONPYTHON调用pyhton脚本时遇到了这些问题，在这里总结一下 主要问题：1.引用第三方类库之后，无法发布。提示引用的类库不支持。 2.发布之后，使用到对应第三方类库内容时，发生错误，但是在编辑器里却没错误。 问题可能原因和解决方法：问题1：可能原因：目前遇到的大部分是都是因为Unity的NET版本和要使用的类库不一致导致的，虽然目前Unity的设置中支持3.5和4.X，但实际上使用那些4.0以上NET支持的类库，大部分就会出现VS编译器里无报错，但Unity编辑器里报错的问题，或者如问题1那样，无法发布。 解决方法：1.尽量使用非4.XNET支持的第三方类库，总能找到课替代的或者低版本(最后我还是没用上iron Python ,选择把python写成web后端了= =)。 2.在发布页面的Player Setting中设置使用的NET版本，更改Unity为.NET 4.X ，但大部分第三方库依然不支持 3.老老实实使用.NET3.5，并选择API为.NET2.0而不是它的子集2.0 Subset 据说后面4.X会支持的更好，3.5也会被移除，希望能完全支持这些类库吧。 问题2：可能原因：我遇到的是在Unity编辑器里生成表格是可以的,但是发布之后，却失败了，通过异常捕获发现出现不支持IBM347编码，其实是缺少Unity编辑器里自带的一些文件。 解决方法：把Unity\Editor\Data\Mono\lib\mono\unity下的L18N相关的所有.dll赋值到当前项目的Assets文件夹下，保存再发布就可以解决了。 以上大部分分析来源于自己，因此可能不是百分百正确，勿在意。]]></content>
      <categories>
        <category>Unity3D</category>
      </categories>
      <tags>
        <tag>问题以及解决方案</tag>
      </tags>
  </entry>
</search>
